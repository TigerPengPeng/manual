<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xml:lang=
"en-US">
<head>
<title>Chapter 1: Introduction to the Java Sound API</title><link rel="stylesheet" href="../../../../technotes/css/guide.css" />
</head>
<body>
<!-- STATIC HEADER -->

<!-- header start -->
<div id="javaseheader">
<div id="javaseheaderlogo">
<img src="../../../../images/javalogo.gif"
alt="Java logo" />
</div>
<div id="javaseheaderindex">

<a href=
"../../../../index.html">Documentation Contents</a>
</div>
<div class="clear"></div>
</div>

<!-- header end -->


<p><small><a href="contents.html">&lt; Contents</a></small></p>
<h1>Chapter 1: Introduction to the Java Sound API</h1>
<h2><a name="design" id="design"></a>Design Goals</h2>
<p><a name="111812"></a> The Java Sound API is a low-level API for
effecting and controlling the input and output of sound media,
including both audio and Musical Instrument Digital Interface
(MIDI) data. The Java Sound API provides explicit control over the
capabilities normally required for sound input and output, in a
framework that promotes extensibility and flexibility.</p>
<a name="111814"></a>
<h3>Who is the Java Sound API For?</h3>
<p><a name="111816"></a> Because sound is so fundamental, the Java
Sound API fulfills the needs of a wide range of application
developers. Potential application areas include:</p>
<ul>
<li style="list-style: none"><a name="111817"></a></li>
<li>Communication frameworks, such as conferencing and telephony
<a name="111818"></a></li>
<li>End-user content delivery systems, such as media players and
music using streamed content <a name="111819"></a></li>
<li>Interactive application programs, such as games and Web sites
that use dynamic content <a name="111820"></a></li>
<li>Content creation and editing <a name="111821"></a></li>
<li>Tools, toolkits, and utilities</li>
</ul>
<a name="111823"></a>
<h3>How Does the Java Sound API Relate to Other Interfaces?</h3>
<p><a name="111825"></a> The Java Sound API provides the lowest
level of sound support on the Java platform. It provides
application programs with a great amount of control over sound
operations, and it is extensible. For example, the Java Sound API
supplies mechanisms for installing, accessing, and manipulating
system resources such as audio mixers, MIDI synthesizers, other
audio or MIDI devices, file readers and writers, and sound format
converters. The Java Sound API does not include sophisticated sound
editors or graphical tools, but it provides capabilities upon which
such programs can be built. It emphasizes low-level control beyond
that commonly expected by the end user.</p>
<p><a name="111827"></a> There are other Java platform APIs that
have sound-related elements. The Java Media Framework (JMF) is a
higher-level API that is currently available as a Standard
Extension to the Java platform. JMF specifies a unified
architecture, messaging protocol, and programming interface for
capturing and playing back time-based media. JMF provides a simpler
solution for basic media-player application programs, and it
enables synchronization between different media types, such as
audio and video. On the other hand, programs that focus on sound
can benefit from the Java Sound API, especially if they require
more advanced features, such as the ability to carefully control
buffered audio playback or directly manipulate a MIDI synthesizer.
Other Java APIs with sound aspects include Java 3D and APIs for
telephony and speech. An implementation of any of these APIs might
use an implementation of the Java Sound API internally, but is not
required to do so.</p>
<a name="111831"></a>
<h2>Packages</h2>
<p><a name="111832"></a> The Java Sound API includes support for
both digital audio and MIDI data. These two major modules of
functionality are provided in separate packages:</p>
<ul>
<li style="list-style: none"><a name="111834"></a></li>
<li><code>javax.sound.sampled</code> <a name="111835"></a> This
package specifies interfaces for capture, mixing, and playback of
digital (sampled) audio. <a name="111837"></a></li>
<li><code>javax.sound.midi</code> <a name="111838"></a> This
package provides interfaces for MIDI synthesis, sequencing, and
event transport.
<p><a name="111840"></a></p>
</li>
</ul>
Two other packages permit service providers (as opposed to
application developers) to create custom software components that
extend the capabilities of an implementation of the Java Sound API:
<a name="111842"></a>
<ul>
<li><code>javax.sound.sampled.spi</code> <a name="111843"></a></li>
<li><code>javax.sound.midi.spi</code>
<p><a name="111845"></a></p>
</li>
</ul>
The rest of this chapter briefly discusses the sampled-audio
system, the MIDI system, and the SPI packages. Each of these is
then discussed in detail in a subsequent part of the guide.
<a name="111847"></a>
<h2>Sampled Audio</h2>
<a name="111849"></a>
<h3>What Is Sampled Audio?</h3>
<p><a name="112308"></a> The <code>javax.sound.sampled</code>
package handles digital audio data, which the Java Sound API refers
to as sampled audio. <em>Samples</em> are successive snapshots of a
signal. In the case of audio, the signal is a sound wave. A
microphone converts the acoustic signal into a corresponding analog
electrical signal, and an analog-to-digital converter transforms
that analog signal into a sampled digital form. The following
figure shows a brief moment in a sound recording.</p>
<i><img src="images/chapter1.anc.gif" alt="A sampled sound wave"
width="268" height="239" /></i> <i>A Sampled Sound Wave</i>
<p><a name="111861"></a> This graph plots sound pressure
(amplitude) on the vertical axis, and time on the horizontal axis.
The amplitude of the analog sound wave is measured periodically at
a certain rate, resulting in the discrete samples (the red data
points in the figure) that comprise the digital audio signal. The
center horizontal line indicates zero amplitude; points above the
line are positive-valued samples, and points below are negative.
The accuracy of the digital approximation of the analog signal
depends on its resolution in time (the <em>sampling rate</em>) and
its <em>quantization</em>, or resolution in amplitude (the number
of bits used to represent each sample). As a point of reference,
the audio recorded for storage on compact discs is sampled 44,100
times per second and represented with 16 bits per sample.</p>
<p><a name="115938"></a> The term "sampled audio" is used here
slightly loosely. A sound wave could be sampled at discrete
intervals while being left in an analog form. For purposes of the
Java Sound API, however, "sampled audio" is equivalent to "digital
audio."</p>
<p><a name="115936"></a> Typically, sampled audio on a computer
comes from a sound recording, but the sound could instead be
synthetically generated (for example, to create the sounds of a
touch-tone telephone). The term "sampled audio" refers to the type
of data, not its origin.</p>
<p><a name="112752"></a> Further information about the structure of
digital audio data is given under "<a href=
"chapter2.html#112348">What Is Formatted Audio Data?</a>" in
Chapter 2, "<a href="chapter2.html">Overview of the Sampled
Package</a>."</p>
<a name="112759"></a>
<h3>Audio Configurations</h3>
<p><a name="111869"></a> The Java Sound API does not assume a
specific audio hardware configuration; it is designed to allow
different sorts of audio components to be installed on a system and
accessed by the API. The Java Sound API supports common
functionality such as input and output from a sound card (for
example, for recording and playback of sound files) as well as
mixing of multiple streams of audio. Here is one example of a
typical audio architecture:</p>
<p><a name="112280"></a> <img src="images/chapter1.anc1.gif" alt=
"The following context describes this graphic" width="413" height=
"251" /></p>
<i>A Typical Audio Architecture</i>
<p><a name="111874"></a> In this example, a device such as a sound
card has various input and output ports, and mixing is provided in
the software. The mixer might receive data that has been read from
a file, streamed from a network, generated on the fly by an
application program, or produced by a MIDI synthesizer. (The
<code>javax.sound.midi</code> package, discussed next, supplies a
Java language interface for synthesizers.) The mixer combines all
its audio inputs into a single stream, which can be sent to an
output device for rendering.</p>
<a name="111877"></a>
<h2>MIDI</h2>
<p><a name="111878"></a> The <code>javax.sound.midi</code> package
contains APIs for transporting and sequencing MIDI events, and for
synthesizing sound from those events.</p>
<a name="111880"></a>
<h3>What Is MIDI?</h3>
<p><a name="112123"></a> Whereas sampled audio is a direct
representation of a sound itself, MIDI data can be thought of as a
recipe for creating a sound, especially a musical sound. MIDI data,
unlike audio data, does not describe sound directly. Instead, it
describes events that affect the sound a synthesizer is making.
MIDI data is analogous to a graphical user interface's keyboard and
mouse events. In the case of MIDI, the events can be thought of as
actions upon a musical keyboard, along with actions on various
pedals, sliders, switches, and knobs on that musical instrument.
These events need not actually originate with a hardware musical
instrument; they can be simulated in software, and they can be
stored in MIDI files. A program that can create, edit, and perform
these files is called a sequencer. Many computer sound cards
include MIDI-controllable music synthesizer chips to which
sequencers can send their MIDI events. Synthesizers can also be
implemented entirely in software. The synthesizers interpret the
MIDI events that they receive and produce audio output. Usually the
sound synthesized from MIDI data is musical sound (as opposed to
speech, for example). MIDI synthesizers are also capable of
generating various kinds of sound effects.</p>
<p><a name="111884"></a> Some sound cards include MIDI input and
output ports to which external MIDI hardware devices (such as
keyboard synthesizers or other instruments) can be connected. From
a MIDI input port, an application program can receive events
generated by an external MIDI-equipped musical instrument. The
program might play the musical performance using the computer's
internal synthesizer, save it to disk as a MIDI file, or render it
into musical notation. A program might use a MIDI output port to
play an external instrument, or to control other external devices
such as recording equipment.</p>
<p><a name="112482"></a> More information about MIDI data is given
in Chapter 8, "<a href="chapter8.html">Overview of the MIDI
Package</a>," particularly in the section "A MIDI Refresher: Wires
and Files."</p>
<a name="112483"></a>
<h3>MIDI Configurations</h3>
<p><a name="112765"></a> The diagram below illustrates the
functional relationships between the major components in a possible
MIDI configuration based on the Java Sound API. (As with audio, the
Java Sound API permits a variety of MIDI software devices to be
installed and interconnected. The system shown here is one
potential scenario.) The flow of data between components is
indicated by arrows. The data can be in a standard file format, or
(as indicated by the key in the lower right corner of the diagram),
it can be audio, raw MIDI bytes, or time-tagged MIDI messages.</p>
<p><a name="112766"></a> <img src="images/chapter1.anc2.gif" alt=
"The following context describes this graphic" width="520" height=
"360" /></p>
<i>A Possible MIDI Configuration</i>
<p><a name="111896"></a> In this example, the application program
prepares a musical performance by loading a musical score that's
stored as a standard MIDI file on a disk (left side of the
diagram). Standard MIDI files contain tracks, each of which is a
list of time-tagged MIDI events. Most of the events represent
musical notes (pitches and rhythms). This MIDI file is read and
then "performed" by a software sequencer. A sequencer performs its
music by sending MIDI messages to some other device, such as an
internal or external synthesizer. The synthesizer itself may read a
soundbank file containing instructions for emulating the sounds of
certain musical instruments. If not, the synthesizer will play the
notes stored in the MIDI file using whatever instrument sounds are
already loaded into the synthesizer.</p>
<p><a name="111898"></a> As illustrated, the MIDI events must be
translated into raw (non-time-tagged) MIDI before being sent
through a MIDI output port to an external synthesizer. Similarly,
raw MIDI data coming into the computer from an external MIDI source
(a keyboard instrument, in the diagram) is translated into
time-tagged MIDI messages that can control a synthesizer, or that a
sequencer can store for later use. All these aspects of MIDI data
flow are explained in detail in the subsequent chapters on MIDI
(see Part II of this guide).</p>
<a name="111901"></a>
<h2>Service Provider Interfaces</h2>
<p><a name="111902"></a> The <code>javax.sound.sampled.spi</code>
and <code>javax.sound.midi.spi</code> packages contain APIs that
let software developers create new audio or MIDI resources that can
be provided separately to the user and "plugged in" to an existing
implementation of the Java Sound API. Here are some examples of
services (resources) that can be added in this way:</p>
<ul>
<li style="list-style: none"><a name="111903"></a></li>
<li>An audio mixer <a name="112110"></a></li>
<li>A MIDI synthesizer <a name="111906"></a></li>
<li>A file parser that can read or write a new type of audio or
MIDI file <a name="111907"></a></li>
<li>A converter that translates between different sound data
formats
<p><a name="111910"></a></p>
</li>
</ul>
In some cases, services are software interfaces to the capabilities
of hardware devices, such as sound cards, and the service provider
might be the same as the vendor of the hardware. In other cases,
the services exist purely in software. For example, a synthesizer
or a mixer could be an interface to a chip on a sound card, or it
could be implemented without any hardware support at all.
<p><a name="111912"></a> An implementation of the Java Sound API
contains a basic set of services, but the service provider
interface (SPI) packages allow third parties to create new
services. These third-party services are integrated into the system
in the same way as the built-in services. The
<code>AudioSystem</code> class in the <code>sampled</code> package
and the <code>MidiSystem</code> class in the <code>midi</code>
package act as coordinators that let application programs access
the services explicitly or implicitly. Often the existence of a
service is completely transparent to an application program that
uses it. The service-provider mechanism benefits users of
application programs based on the Java Sound API, because new sound
features can be added to a program without requiring a new release
of the Java SDK or runtime environment, and, in many cases, without
even requiring a new release of the application program itself.</p>
<p>&nbsp;</p>

<!--  footer start -->
<div id="javasefooter">
<div class="hr">
<hr /></div>
<div id="javasecopyright">
<img id="oraclelogofooter" src=
"../../../../images/oraclelogo.gif" alt="Oracle and/or its affiliates"
border="0" width="100" height="29" name=
"oraclelogofooter" />

<a href="../../../../legal/cpyr.html">Copyright
&#169;</a> 1993, 2014, Oracle and/or its affiliates. All rights
reserved.</div>
<div id="javasecontactus">
<a href=
"http://docs.oracle.com/javase/feedback.html">Contact
Us</a>
</div>
</div>
<!-- footer end -->

<!-- STATIC FOOTER -->

</body>
</html>
