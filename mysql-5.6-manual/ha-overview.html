<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Chapter 16 High Availability and Scalability</title>
<link rel="stylesheet" href="mvl.css" type="text/css" />
<meta name="generator" content="DocBook XSL Stylesheets + chunker.py v1.9.2" />
<link rel="start" href="index.html" title="{book-title}" />
<link rel="up" href="" title="" />
<link rel="prev" href="storage-engines.html" title="Chapter 15 Alternative Storage Engines" />
<link rel="next" href="replication.html" title="Chapter 17 Replication" />
<script language="javascript" type="text/javascript">
  function addOnload(theFunc)
  {
    var previous = window.onload;
    if (typeof window.onload != 'function')
    {
      window.onload = theFunc;
    }
    else
    {
      window.onload = function()
      {
        previous();
        theFunc();
      }
    }
  }

  addOnload(function()
  {
    var base = new Date(1438557954*1000);
    var now = new Date();
    var diff = ((now-base)/1000)/(24*3600);

    if (diff > 90) {
      var nodes = document.getElementsByClassName('titlepage');
      nodes[0].innerHTML = '<p style="border: 5px #ff0000 solid; padding: 5px; margin 5px">' +
        'This copy of the manual is more than 90 days old. We encourage you to download a ' +
        'new version from <a href="http://dev.mysql.com">dev.mysql.com/doc</a>.</p>' + nodes[0].innerHTML;
    }
  });
</script>
<noscript></noscript>
</head>
<body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF">
<div class="navheader">
<table width="100%" summary="Navigation header">
<tr>
<th colspan="3" align="center">Chapter 16 High Availability and Scalability</th>
</tr>
<tr>
<td width="20%" align="left"><a accesskey="p" href="storage-engines.html">Prev</a> </td>
<th width="60%" align="center"></th>
<td width="20%" align="right"> <a accesskey="n" href="replication.html">Next</a></td>
</tr>
</table>
<hr>
</div>
<div class="chapter">
<div class="titlepage">
<div>
<div>
<h1 class="title"><a name="ha-overview"></a>Chapter 16 High Availability and Scalability</h1>

</div>

</div>

</div>
<div class="toc">
<p><b>Table of Contents</b></p><dl class="toc"><dt><span class="section"><a href="ha-overview.html#ha-ovm-template">16.1 Oracle VM Template for MySQL Enterprise Edition</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd">16.2 Overview of MySQL with DRBD/Pacemaker/Corosync/Oracle Linux</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-wfc">16.3 Overview of MySQL with Windows Failover Clustering</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm">16.4 Using MySQL within an Amazon EC2 Instance</a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-setup">16.4.1 Setting Up MySQL on an EC2 AMI</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-instance">16.4.2 EC2 Instance Limitations</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-deploy">16.4.3 Deploying a MySQL Database Using EC2</a></span></dt></dl></dd><dt><span class="section"><a href="ha-overview.html#ha-zfs-replication">16.5 Using ZFS Replication</a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-zfs-config">16.5.1 Using ZFS for File System Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql">16.5.2 Configuring MySQL for ZFS Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql-recovery">16.5.3 Handling MySQL Recovery with ZFS</a></span></dt></dl></dd><dt><span class="section"><a href="ha-overview.html#ha-memcached">16.6 Using MySQL with <span class="command"><strong>memcached</strong></span></a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-install">16.6.1 Installing <span class="command"><strong>memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using">16.6.2 Using <span class="command"><strong>memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces">16.6.3 Developing a <span class="command"><strong>memcached</strong></span> Application</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats">16.6.4 Getting <span class="command"><strong>memcached</strong></span> Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-faq">16.6.5 <span class="command"><strong>memcached</strong></span> FAQ</a></span></dt></dl></dd></dl>
</div>
<p>
    Data is the currency of today's web, mobile, social, enterprise and
    cloud applications. Ensuring data is always available is a top
    priority for any organization. Minutes of downtime can result in
    significant loss of revenue and reputation.
  </p><p>
    There is no <span class="quote">“<span class="quote">one size fits all</span>”</span> approach to delivering
    High Availability (HA). Unique application attributes, business
    requirements, operational capabilities and legacy infrastructure can
    all influence HA technology selection. And technology is only one
    element in delivering HA: people and processes are just as critical
    as the technology itself.
  </p><p>
    MySQL is deployed into many applications demanding availability and
    scalability. <span class="bold"><strong>Availability</strong></span> refers to
    the ability to cope with, and if necessary recover from, failures on
    the host, including failures of MySQL, the operating system, or the
    hardware and maintenance activity that may otherwise cause downtime.
    <a class="link" href="glossary.html#glos_scalability" title="scalability">Scalability</a> refers to the
    ability to spread both the database and the load of your application
    queries across multiple MySQL servers.
  </p><p>
    Because each application has different operational and availability
    requirements, MySQL offers a range of certified and supported
    solutions, delivering the appropriate levels of High Availability
    (HA) and scalability to meet service level requirements. Such
    solutions extend from replication, through virtualization and
    geographically redundant, multi-data center solutions delivering
    99.999% uptime.
  </p><p>
    Selecting the right high availability solution for an application
    largely depends on:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
        The level of availability required.
      </p></li><li class="listitem"><p>
        The type of application being deployed.
      </p></li><li class="listitem"><p>
        Accepted best practices within your own environment.
</p></li></ul>
</div>
<p>
    The primary solutions supported by MySQL include:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
        MySQL Replication. Learn more: <a class="xref" href="replication.html" title="Chapter 17 Replication">Chapter 17, <i>Replication</i></a>
      </p></li><li class="listitem"><p>
        MySQL Cluster. Learn more: <a class="xref" href="mysql-cluster.html" title="Chapter 18 MySQL Cluster NDB 7.3 and MySQL Cluster NDB 7.4">Chapter 18, <i>MySQL Cluster NDB 7.3 and MySQL Cluster NDB 7.4</i></a>
      </p></li><li class="listitem"><p>
        Oracle VM Template for MySQL. Learn more:
        <a class="xref" href="ha-overview.html#ha-ovm-template" title="16.1 Oracle VM Template for MySQL Enterprise Edition">Section 16.1, “Oracle VM Template for MySQL Enterprise Edition”</a>.
      </p></li><li class="listitem"><p>
        MySQL with DRBD with Corosync and Pacemaker. Learn more:
        <a class="xref" href="ha-overview.html#ha-drbd" title="16.2 Overview of MySQL with DRBD/Pacemaker/Corosync/Oracle Linux">Section 16.2, “Overview of MySQL with DRBD/Pacemaker/Corosync/Oracle Linux”</a>.
      </p></li><li class="listitem"><p>
        MySQL with Windows Failover Clustering. Learn more:
        <a class="xref" href="ha-overview.html#ha-wfc" title="16.3 Overview of MySQL with Windows Failover Clustering">Section 16.3, “Overview of MySQL with Windows Failover Clustering”</a>.
      </p></li><li class="listitem"><p>
        MySQL with Solaris Cluster.
        <a class="ulink" href="http://www.oracle.com/technetwork/server-storage/solaris-cluster/overview/index.html" target="_top">Learn
        more about Solaris Cluster.</a>
</p></li></ul>
</div>
<p>
    Further options are available using third-party solutions.
  </p><p>
    Each architecture used to achieve highly available database services
    is differentiated by the levels of uptime it offers. These
    architectures can be grouped into three main categories:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
        Data Replication.
      </p></li><li class="listitem"><p>
        Clustered &amp; Virtualized Systems.
      </p></li><li class="listitem"><p>
        Shared-Nothing, Geographically-Replicated Clusters.
</p></li></ul>
</div>
<p>
    As illustrated in the following figure, each of these architectures
    offers progressively higher levels of uptime, which must be balanced
    against potentially greater levels of cost and complexity that each
    can incur. Simply deploying a high availability architecture is not
    a guarantee of actually delivering HA. In fact, a poorly implemented
    and maintained shared-nothing cluster could easily deliver lower
    levels of availability than a simple data replication solution.
</p>
<div class="figure">
<a name="figure_ha-cost-vs-nines"></a><p class="title"><b>Figure 16.1 Tradeoffs: Cost and Complexity versus Availability</b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/ha-cost-vs-nines.png" width="555" height="467" alt="As the number of “nines” in the uptime percentage increases, so does the cost and complexity, progressing from basic replication, to a clustered and virtualized configuration, to shared-nothing clusters replicated across geographic regions. Different kinds of organizations require different “nines” of availability, from Internet service providers and mainstream businesses at 3 nines, online services at 4 nines, and eCommerce, telecom, and military applications at 5 nines.">
</div>

</div>

</div>
<br class="figure-break"><p>
    The following table compares the HA and Scalability capabilities of
    the various MySQL solutions:
</p>
<div class="table">
<a name="ha-availability-comparison"></a><p class="title"><b>Table 16.1 Feature Comparison of MySQL HA Solutions</b></p>
<div class="table-contents">
<table summary="Feature Comparison of MySQL HA Solutions" border="1"><colgroup><col><col><col><col><col></colgroup><thead><tr><th scope="col">Requirement</th><th scope="col">MySQL Replication</th><th scope="col">DRBD</th><th scope="col">Oracle VM Template</th><th scope="col">MySQL Cluster</th></tr></thead><tbody><tr><td scope="row"><span class="bold"><strong>Availability</strong></span></td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td></tr><tr><td scope="row">Platform Support</td><td>All Supported by MySQL Server
            (<a class="ulink" href="http://www.mysql.com/support/supportedplatforms/database.html" target="_top">http://www.mysql.com/support/supportedplatforms/database.html</a>)</td><td>Linux</td><td>Oracle Linux</td><td>All Supported by MySQL Cluster
(<a class="ulink" href="http://www.mysql.com/support/supportedplatforms/cluster.html" target="_top">http://www.mysql.com/support/supportedplatforms/cluster.html</a>)</td></tr><tr><td scope="row">Automated IP Failover</td><td>No</td><td>Yes</td><td>Yes</td><td>Depends on Connector and Configuration</td></tr><tr><td scope="row">Automated Database Failover</td><td>No</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td scope="row">Automatic Data Resynchronization</td><td>No</td><td>Yes</td><td>N/A - Shared Storage</td><td>Yes</td></tr><tr><td scope="row">Typical Failover Time</td><td>User / Script Dependent</td><td>Configuration Dependent, 60 seconds and Above</td><td>Configuration Dependent, 60 seconds and Above</td><td>1 Second and Less</td></tr><tr><td scope="row">Synchronous Replication</td><td>No, Asynchronous and Semisynchronous</td><td>Yes</td><td>N/A - Shared Storage</td><td>Yes</td></tr><tr><td scope="row">Shared Storage</td><td>No, Distributed</td><td>No, Distributed</td><td>Yes</td><td>No, Distributed</td></tr><tr><td scope="row">Geographic redundancy support</td><td>Yes</td><td>Yes, via MySQL Replication</td><td>Yes, via MySQL Replication</td><td>Yes, via MySQL Replication</td></tr><tr><td scope="row">Update Schema On-Line</td><td>No</td><td>No</td><td>No</td><td>Yes</td></tr><tr><td scope="row"><span class="bold"><strong>Scalability</strong></span></td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td></tr><tr><td scope="row">Number of Nodes</td><td>One Master, Multiple Slaves</td><td>One Active (primary), one Passive (secondary) Node</td><td>One Active (primary), one Passive (secondary) Node</td><td>255</td></tr><tr><td scope="row">Built-in Load Balancing</td><td>Reads, via MySQL Replication</td><td>Reads, via MySQL Replication</td><td>Reads, via MySQL Replication &amp; During Failover</td><td>Yes, Reads and Writes</td></tr><tr><td scope="row">Supports Read-Intensive Workloads</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td scope="row">Supports Write-Intensive Workloads</td><td>Yes, via Application-Level Sharding</td><td>Yes, via Application-Level Sharding to Multiple Active/Passive Pairs</td><td>Yes, via Application-Level Sharding to Multiple Active/Passive Pairs</td><td>Yes, via Auto-Sharding</td></tr><tr><td scope="row">Scale On-Line (add nodes, repartition, etc.)</td><td>No</td><td>No</td><td>No</td><td>Yes</td></tr></tbody></table>
</div>

</div>
<br class="table-break">
<div class="section">

<div class="titlepage">
<div>
<div>
<h2 class="title" style="clear: both"><a name="ha-ovm-template"></a>16.1 Oracle VM Template for MySQL Enterprise Edition</h2>

</div>

</div>

</div>
<p>
      Virtualization is a key technology to enable data center
      efficiency and high availability while providing the foundation
      for cloud computing. Integrating MySQL Enterprise Edition with
      Oracle Linux, the Oracle VM Template is the fastest, easiest, and
      most reliable way to provision virtualized MySQL instances,
      enabling users to meet the explosive demand for highly available
      services.
    </p><p>
      The Oracle VM Template enables rapid deployment and eliminates
      manual configuration efforts. It provides a preinstalled and
      pre-configured virtualized MySQL 5.5 Enterprise Edition software
      image running on Oracle Linux and Oracle VM, certified for
      production use. The MySQL software image has undergone extensive
      integration and quality assurance testing as part of the
      development process.
    </p><p>
      In addition to rapid provisioning, MySQL users also benefit from
      the integrated high availability features of Oracle VM which are
      designed to enable organizations to meet stringent SLA (Service
      Level Agreement) demands through a combination of:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          <span class="bold"><strong>Automatic recovery from
          failures</strong></span>, with Oracle VM automatically restarting
          failed instances on available servers in the server pool after
          outages of the physical server, VM or MySQL database.
        </p></li><li class="listitem"><p>
          <span class="bold"><strong>Live Migration</strong></span>, enabling
          operations staff to move running instances of MySQL to
          alternative hosts within a server pool during maintenance
          operations.
</p></li></ul>
</div>
<p>
      Instructions for the creation, deployment and use of the Oracle VM
      Template for MySQL Enterprise Edition are available from:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          The Oracle VM Template for MySQL Enterprise Edition
          whitepaper:
          <a class="ulink" href="http://www.mysql.com/why-mysql/white-papers/mysql_wp_oracle-vm-template-for-mee.php" target="_top">http://www.mysql.com/why-mysql/white-papers/mysql_wp_oracle-vm-template-for-mee.php</a>.
        </p></li><li class="listitem"><p>
          The README file accompanying the download of the Template.
</p></li></ul>
</div>
<p>
      To download the Oracle VM Template for MySQL Enterprise, go to
      <a class="ulink" href="https://edelivery.oracle.com/oraclevm" target="_top">https://edelivery.oracle.com/oraclevm</a> and follow
      these instructions:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          Complete your registration information (Name, Company Name,
          Email Address and Country) and click on the download
          agreement.
        </p></li><li class="listitem"><p>
          Select "Oracle VM Templates" from the "Select a Product Pack"
          pull-down menu and click "Go".
        </p></li><li class="listitem"><p>
          Select MySQL Enterprise from the list of Oracle VM Templates.
        </p></li><li class="listitem"><p>
          Download and unzip the files and refer to the README for
          further instructions.
</p></li></ul>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h2 class="title" style="clear: both"><a name="ha-drbd"></a>16.2 Overview of MySQL with DRBD/Pacemaker/Corosync/Oracle Linux</h2>

</div>

</div>

</div>
<p>
    DRBD (Distributed Replication Block Device) is one of the leading
    solutions for MySQL HA (High Availability). When combined with
    Pacemaker and Corosync, users have:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
        An end-to-end, integrated stack of mature and proven open source
        technologies, fully supported by Oracle (as part of MySQL
        Enterprise Edition).
      </p></li><li class="listitem"><p>
        Automatic failover and recovery for service continuity.
      </p></li><li class="listitem"><p>
        Mirroring, via synchronous replication, to ensure failover
        between nodes without the risk of losing committed transactions.
      </p></li><li class="listitem"><p>
        Building of HA clusters from commodity hardware, without the
        requirement for shared-storage.
</p></li></ul>
</div>
<p>
    The following figure illustrates the stack that can be used to
    deliver a level of High Availability for the MySQL service.
  </p><p>
    At the lowest level, 2 hosts are required in order to provide
    physical redundancy; if using a virtual environment, those 2 hosts
    should be on different physical machines. It is an important feature
    that no shared storage is required. At any point in time, the
    services will be active on one host and in standby mode on the
    other.
  </p><p>
    Pacemaker and Corosync combine to provide the clustering layer that
    sits between the services and the underlying hosts and operating
    systems. Pacemaker is responsible for starting and stopping
    services, ensuring that they are running on exactly one host, thus
    delivering high availability and avoiding data corruption. Corosync
    provides the underlying messaging infrastructure between the nodes
    that enables Pacemaker to do its job; it also handles the nodes
    membership within the cluster and informs Pacemaker of any changes.
</p>
<div class="figure">
<a name="ha-drbd-overview"></a><p class="title"><b>Figure 16.2 MySQL, DRBD, Pacemaker, and Corosync Stack</b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/drbd-main.png" width="564" height="592" alt="MySQL, DRBD, Pacemaker, and Corosync Stack">
</div>

</div>

</div>
<br class="figure-break"><p>
    The core Pacemaker process does not have built-in knowledge of the
    specific services to be managed; instead, it uses agents that
    provide a wrapper for the service-specific actions. For example, in
    this solution we use agents for Virtual IP Addresses, MySQL and
    DRBD: these are all existing agents and come packaged with
    Pacemaker.
  </p><p>
    The essential services managed by Pacemaker in this configuration
    are DRBD, MySQL and the Virtual IP Address that applications use to
    connect to the active MySQL service.
  </p><p>
    DRBD synchronizes data at the block device (typically a spinning or
    solid state disk) – transparent to the application, database and
    even the file system. DRBD requires the use of a journaling file
    system such as <code class="literal">ext3</code> or <code class="literal">ext4</code>.
    For this solution, it acts in an active-standby mode: at any point
    in time, the directories being managed by DRBD are accessible for
    reads and writes on exactly one of the two hosts and inaccessible
    (even for reads) on the other. Any changes made on the active host
    are synchronously replicated to the standby host by DRBD.
  </p><p>
    Download the following guide for detailed instructions on
    installing, configuring, provisioning and testing the complete MySQL
    and DRBD stack, including:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
        MySQL Database.
      </p></li><li class="listitem"><p>
        DRBD kernel module and userland utilities.
      </p></li><li class="listitem"><p>
        Pacemaker and Corosync cluster messaging and management
        processes.
      </p></li><li class="listitem"><p>
        Oracle Linux operating system.
</p></li></ul>
</div>
<p>
    Download the guide at:
    <a class="ulink" href="http://www.mysql.com/why-mysql/white-papers/mysql-high-availability-drbd-configuration-deployment-guide/" target="_top">http://www.mysql.com/why-mysql/white-papers/mysql-high-availability-drbd-configuration-deployment-guide/</a>.
</p>
<h3><a name="idm139737122909744"></a>Support for DRBD</h3>
<p>
    The complete DRBD stack for MySQL has been certified by Oracle.
    Commercial support, which provides a single point of contact for the
    entire stack, whether issues relate to the operating system, DRBD,
    clustering software or MySQL, is available to those who have both
    <a class="ulink" href="http://www.mysql.com/products/enterprise/" target="_top">MySQL
    Enterprise Edition</a> and
    <a class="ulink" href="http://www.oracle.com/us/technologies/linux/support/overview/index.html" target="_top">Oracle
    Linux Premier Support</a> contracts.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h2 class="title" style="clear: both"><a name="ha-wfc"></a>16.3 Overview of MySQL with Windows Failover Clustering</h2>

</div>

</div>

</div>
<a class="indexterm" name="idm139737122905520"></a><a class="indexterm" name="idm139737122904464"></a><p>
    Microsoft Windows is consistently ranked as the top development
    platform for MySQL, based on surveys of the MySQL user community.
  </p><p>
    MySQL Enterprise Edition is certified and supported with Windows
    Server 2008 R2 Failover Clustering (WSFC), enabling organizations to
    safely deploy business-critical applications demanding high levels
    of availability using Microsoft's native Windows clustering
    services.
  </p><p>
    The following figure illustrates the integration of MySQL with
    Windows Server Failover Clustering to provide a highly available
    service:
</p>
<div class="figure">
<a name="ha-wfc-overview"></a><p class="title"><b>Figure 16.3 Typical MySQL HA Configuration with Windows Server Failover Clustering</b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/wfc-architecture.jpg" width="522" height="744" alt="MySQL with Windows Failover Clustering">
</div>

</div>

</div>
<br class="figure-break"><p>
    In this architecture, MySQL is deployed in an Active / Passive
    configuration. Failures of either MySQL or the underlying server are
    automatically detected and the MySQL instance is restarted on the
    Passive node. Applications accessing the database, as well as any
    MySQL replication slaves, can automatically reconnect to the new
    MySQL process using the same Virtual IP address once MySQL recovery
    has completed and it starts accepting connections.
  </p><p>
    MySQL with Windows Failover Clustering requires at least 2 servers
    within the cluster together with shared storage (for example, FC-AL
    SAN or iSCSI disks).
  </p><p>
    The MySQL binaries and data files are stored in the shared storage
    and Windows Failover Clustering ensures that only one of the cluster
    nodes will access those files at any point in time.
  </p><p>
    Clients connect to the MySQL service through a Virtual IP Address
    (VIP). In the event of failover they experience a brief loss of
    connection, but otherwise do not need to be aware that the failover
    has happened, other than to handle the failure of any transactions
    that were active when the failover occurred.
  </p><p>
    You can learn more about configuring MySQL with Windows Server
    Failover Clustering from the whitepaper posted here:
    <a class="ulink" href="http://www.mysql.com/why-mysql/white-papers/mysql_wp_windows_failover_clustering.php" target="_top">http://www.mysql.com/why-mysql/white-papers/mysql_wp_windows_failover_clustering.php</a>
  </p><p>
    For background and usage information about Windows Server Failover
    Clustering, see these pages on the Microsoft Technet site:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
        <a class="ulink" href="http://technet.microsoft.com/en-us/library/cc725923(v=ws.10).aspx" target="_top">Failover
        Clustering</a>
      </p></li><li class="listitem"><p>
        <a class="ulink" href="http://technet.microsoft.com/en-us/library/ff182338(v=ws.10).aspx" target="_top">Failover
        Clusters in Windows Server 2008 R2</a>
</p></li></ul>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h2 class="title" style="clear: both"><a name="ha-vm"></a>16.4 Using MySQL within an Amazon EC2 Instance</h2>

</div>

</div>

</div>
<div class="toc">
<dl class="toc"><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-setup">16.4.1 Setting Up MySQL on an EC2 AMI</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-instance">16.4.2 EC2 Instance Limitations</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-deploy">16.4.3 Deploying a MySQL Database Using EC2</a></span></dt></dl>
</div>
<p>
    The Amazon Elastic Compute Cloud (EC2) service provides virtual
    servers that you can build and deploy to run a variety of different
    applications and services, including MySQL. The EC2 service is based
    around the Xen framework, supporting x86, Linux based, platforms
    with individual instances of a virtual machine referred to as an
    Amazon Machine Image (AMI). You have complete (root) access to the
    AMI instance that you create, enabling you to configure and install
    your AMI in any way you choose.
  </p><p>
    To use EC2, you create an AMI based on the configuration and
    applications that you intend to use, and upload the AMI to the
    Amazon Simple Storage Service (S3). From the S3 resource, you can
    deploy one or more copies of the AMI to run as an instance within
    the EC2 environment. The EC2 environment provides management and
    control of the instance and contextual information about the
    instance while it is running.
  </p><p>
    Because you can create and control the AMI, the configuration, and
    the applications, you can deploy and create any environment you
    choose. This includes a basic MySQL server in addition to more
    extensive replication, HA and scalability scenarios that enable you
    to take advantage of the EC2 environment, and the ability to deploy
    additional instances as the demand for your MySQL services and
    applications grow.
  </p><p>
    To aid the deployment and distribution of work, three different
    Amazon EC2 instances are available, small (identified as
    <code class="literal">m1.small</code>), large (<code class="literal">m1.large</code>)
    and extra large (<code class="literal">m1.xlarge</code>). The different types
    provide different levels of computing power measured in EC2 computer
    units (ECU). A summary of the different instance configurations is
    shown in the following table.
</p>
<div class="informaltable">
<table summary="This table lists EC2 instance attributes and outlines
      attribute configuration settings for Small, Large, and Extra Large
EC2 instances." border="1"><colgroup><col><col><col><col></colgroup><thead><tr><th scope="col">EC2 Attribute</th><th scope="col">Small</th><th scope="col">Large</th><th scope="col">Extra Large</th></tr></thead><tbody><tr><td scope="row">Platform</td><td>32-bit</td><td>64-bit</td><td>64-bit</td></tr><tr><td scope="row">CPU cores</td><td>1</td><td>2</td><td>4</td></tr><tr><td scope="row">ECUs</td><td>1</td><td>4</td><td>8</td></tr><tr><td scope="row">RAM</td><td>1.7GB</td><td>7.5GB</td><td>15GB</td></tr><tr><td scope="row">Storage</td><td>150GB</td><td>840GB</td><td>1680GB</td></tr><tr><td scope="row">I/O Performance</td><td>Medium</td><td>High</td><td>High</td></tr></tbody></table>
</div>
<p>
    The typical model for deploying and using MySQL within the EC2
    environment is to create a basic AMI that you can use to hold your
    database data and application. Once the basic environment for your
    database and application has been created you can then choose to
    deploy the AMI to a suitable instance. Here the flexibility of
    having an AMI that can be re-deployed from the small to the large or
    extra large EC2 instance makes it easy to upgrade the hardware
    environment without rebuilding your application or database stack.
  </p><p>
    To get started with MySQL on EC2, including information on how to
    set up and install MySQL within an EC2 installation and how to port
    and migrate your data to the running instance, see
    <a class="xref" href="ha-overview.html#ha-vm-aws-setup" title="16.4.1 Setting Up MySQL on an EC2 AMI">Section 16.4.1, “Setting Up MySQL on an EC2 AMI”</a>.
  </p><p>
    For tips and advice on how to create a scalable EC2 environment
    using MySQL, including guides on setting up replication, see
    <a class="xref" href="ha-overview.html#ha-vm-aws-deploy" title="16.4.3 Deploying a MySQL Database Using EC2">Section 16.4.3, “Deploying a MySQL Database Using EC2”</a>.
</p>
<div class="section">

<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-vm-aws-setup"></a>16.4.1 Setting Up MySQL on an EC2 AMI</h3>
</div>
</div>
</div>
<p>
      There are many different ways of setting up an EC2 AMI with MySQL,
      including using any of the pre-configured AMIs supplied by Amazon.
    </p><p>
      The default <span class="emphasis"><em>Getting Started</em></span> AMI provided by
      Amazon uses Fedora Core 4, and you can install MySQL by using
      <span class="command"><strong>yum</strong></span>:
    </p><pre class="programlisting">
shell&gt; <strong class="userinput"><code>yum install mysql</code></strong>
</pre><p>
      This installs both the MySQL server and the Perl DBD::mysql driver
      for the Perl DBI API.
    </p><p>
      Alternatively, you can use one of the AMIs that include MySQL
      within the standard installation.
    </p><p>
      Finally, you can also install a standard version of MySQL
      downloaded from the MySQL Web site. The installation process and
      instructions are identical to any other installation of MySQL on
      Linux. See <a class="xref" href="installing.html" title="Chapter 2 Installing and Upgrading MySQL">Chapter 2, <i>Installing and Upgrading MySQL</i></a>.
    </p><p>
      The standard configuration for MySQL places the data files in the
      default location, <code class="filename">/var/lib/mysql</code>. The default
      data directory on an EC2 instance is <code class="filename">/mnt</code>
      (although on the large and extra large instance you can alter this
      configuration). You must edit <code class="filename">/etc/my.cnf</code> to
      set the <a class="link" href="server-administration.html#option_mysqld_datadir"><code class="option">datadir</code></a> option to point to
      the larger storage area.
</p>
<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Important
</div>
<p>
        The first time you use the main storage location within an EC2
        instance it needs to be initialized. The initialization process
        starts automatically the first time you write to the device. You
        can start using the device right away, but the write performance
        of the new device is significantly lower on the initial writes
        until the initialization process has finished.
      </p><p>
        To avoid this problem when setting up a new instance, you should
        start the initialization process before populating your MySQL
        database. One way to do this is to use <span class="command"><strong>dd</strong></span> to
        write to the file system:
      </p><pre class="programlisting">
root-shell&gt; <strong class="userinput"><code>dd if=/dev/zero of=initialize bs=1024M count=50</code></strong>
</pre><p>
        The preceding creates a 50GB on the file system and starts the
        initialization process. Delete the file once the process has
        finished.
      </p><p>
        The initialization process can be time-consuming. On the small
        instance, initialization takes between two and three hours. For
        the large and extra large drives, the initialization can be 10
        or 20 hours, respectively.
</p>
</div>
<p>
      In addition to configuring the correct storage location for your
      MySQL data files, also consider setting the following other
      settings in your instance before you save the instance
      configuration for deployment:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          Set the MySQL server ID, so that when you use it for
          replication, the ID information is set correctly.
        </p></li><li class="listitem"><p>
          Enabling binary logging, so that replication can be
          initialized without starting and stopping the server.
        </p></li><li class="listitem"><p>
          Set the caching and memory parameters for your storage
          engines. There are no limitations or restrictions on what
          storage engines you use in your EC2 environment. Choose a
          configuration, possibly using one of the standard
          configurations provided with MySQL appropriate for the
          instance on which you expect to deploy. The large and extra
          large instances have RAM that can be dedicated to caching. Be
          aware that if you choose to install
          <span class="command"><strong>memcached</strong></span> on the servers as part of your
          application stack you must ensure there is enough memory for
          both MySQL and <span class="command"><strong>memcached</strong></span>.
</p></li></ul>
</div>
<p>
      Once you have configured your AMI with MySQL and the rest of your
      application stack, save the AMI so that you can deploy and reuse
      the instance.
    </p><p>
      Once you have your application stack configured in an AMI,
      populating your MySQL database with data should be performed by
      creating a dump of your database using
      <code class="literal">mysqldump</code>, transferring the dump to the EC2
      instance, and then reloading the information into the EC2 instance
      database.
    </p><p>
      Before using your instance with your application in a production
      situation, be aware of the limitations of the EC2 instance
      environment. See <a class="xref" href="ha-overview.html#ha-vm-aws-instance" title="16.4.2 EC2 Instance Limitations">Section 16.4.2, “EC2 Instance Limitations”</a>. To begin
      using your MySQL AMI, consult the notes on deployment. See
      <a class="xref" href="ha-overview.html#ha-vm-aws-deploy" title="16.4.3 Deploying a MySQL Database Using EC2">Section 16.4.3, “Deploying a MySQL Database Using EC2”</a>.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-vm-aws-instance"></a>16.4.2 EC2 Instance Limitations</h3>

</div>

</div>

</div>
<p>
      Be aware of the following limitations of the EC2 instances before
      deploying your applications. Although these shouldn't affect your
      ability to deploy within the Amazon EC2 environment, they may
      alter the way you setup and configure your environment to support
      your application.
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          Data stored within instances is not persistent. If you create
          an instance and populate the instance with data, then the data
          only remains in place while the machine is running, and does
          not survive a reboot. If you shut down the instance, any data
          it contained is lost.
        </p><p>
          To ensure that you do not lose information, take regular
          backups using <a class="link" href="programs.html#mysqldump" title="4.5.4 mysqldump — A Database Backup Program"><span class="command"><strong>mysqldump</strong></span></a>. If the data being
          stored is critical, consider using replication to keep a
          <span class="quote">“<span class="quote">live</span>”</span> backup of your data in the event of a
          failure. When creating a backup, write the data to the Amazon
          S3 service to avoid the transfer charges applied when copying
          data offsite.
        </p></li><li class="listitem"><p>
          EC2 instances are not persistent. If the hardware on which an
          instance is running fails, the instance is shut down. This can
          lead to loss of data or service.
        </p><p>
          However, if you use EBS, you can attach an EBS storage volume
          to an EC2 instance, and that EBS volume is persistent. Like a
          disk, an EBS volume can fail, but it is possible to create
          point-in-time snapshots of the volume. Snapshots are persisted
          to Amazon S3 and can be used to restore data in the event of
          volume failure.
        </p></li><li class="listitem"><p>
          To replicate your EC2 instances to a non-EC2 environment, be
          aware of the transfer costs to and from the EC2 service. Data
          transfer between different EC2 instances is free, so using
          replication within the EC2 environment does not incur
          additional charges.
        </p></li><li class="listitem"><p>
          Certain HA features are either not directly supported, or have
          limiting factors or problems that could reduce their utility.
          For example, using DRBD or MySQL Cluster might not work. The
          default storage configuration is also not redundant. You can
          use software-based RAID to improve redundancy, but this
          implies a further performance hit.
</p></li></ul>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-vm-aws-deploy"></a>16.4.3 Deploying a MySQL Database Using EC2</h3>

</div>

</div>

</div>
<p>
      Because you cannot guarantee the uptime and availability of your
      EC2 instances, when deploying MySQL within the EC2 environment,
      use an approach that enables you to easily distribute work among
      your EC2 instances. There are a number of ways of doing this.
      Using sharding techniques, where you split the application across
      multiple servers dedicating specific blocks of your dataset and
      users to different servers is an effective way of doing this. As a
      general rule, it is easier to create more EC2 instances to support
      more users than to upgrade the instance to a larger machine.
    </p><p>
      The EC2 architecture works best when you treat the EC2 instances
      as temporary, cache-based solutions, rather than as a long-term,
      high availability solution. In addition to using multiple
      machines, take advantage of other services, such as
      <span class="command"><strong>memcached</strong></span> to provide additional caching for
      your application to help reduce the load on the MySQL server so
      that it can concentrate on writes. On the large and extra large
      instances within EC2, the RAM available can provide a large memory
      cache for data.
    </p><p>
      Most types of scale-out topology that you would use with your own
      hardware can be used and applied within the EC2 environment.
      However, use the limitations and advice already given to ensure
      that any potential failures do not lose you any data. Also,
      because the relative power of each EC2 instance is so low, be
      prepared to alter your application to use sharding and add further
      EC2 instances to improve the performance of your application.
    </p><p>
      For example, take the typical scale-out environment shown
      following, where a single master replicates to one or more slaves
      (three in this example), with a web server running on each
      replication slave.
</p>
<div class="mediaobject">
<img src="images/ec2fig1.png" width="493" height="167" alt="Typical standard scale-out structure">
</div>
<p>
      You can reproduce this structure completely within the EC2
      environment, using an EC2 instance for the master, and one
      instance for each of the web and MySQL slave servers.
</p>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
        Within the EC2 environment, internal (private) IP addresses used
        by the EC2 instances are constant. Always use these internal
        addresses and names when communicating between instances. Only
        use public IP addresses when communicating with the outside
        world - for example, when publicizing your application.
</p>
</div>
<p>
      To ensure reliability of your database, add at least one
      replication slave dedicated to providing an active backup and
      storage to the Amazon S3 facility. You can see an example of this
      in the following topology.
</p>
<div class="mediaobject">
<img src="images/ec2fig2.png" width="493" height="433" alt="Typical standard scale-out structure with backup using EC2">
</div>
<p>
      <span class="bold"><strong>Using
      <span class="command"><strong>memcached</strong></span></strong></span> within your EC2 instances
      should provide better performance. The large and extra large
      instances have a significant amount of RAM. To use
      <span class="command"><strong>memcached</strong></span> in your application, when loading
      information from the database, first check whether the item exists
      in the cache. If the data you are looking for exists in the cache,
      use it. If not, reload the data from the database and populate the
      cache.
    </p><p>
      <span class="bold"><strong>Sharding</strong></span> divides up data in your
      entire database by allocating individual machines or machine
      groups to provide a unique set of data according to an appropriate
      group. For example, you might put all users with a surname ending
      in the letters A-D onto a single server. When a user connects to
      the application and their surname is known, queries can be
      redirected to the appropriate MySQL server.
    </p><p>
      When using sharding with EC2, separate the web server and MySQL
      server into separate EC2 instances, and then apply the sharding
      decision logic into your application. Once you know which MySQL
      server you should be using for accessing the data you then
      distribute queries to the appropriate server. You can see a sample
      of this in the following illustration.
</p>
<div class="mediaobject">
<img src="images/ec2fig3.png" width="493" height="333" alt="Using sharding in EC2 to spread the load">
</div>

<div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Warning
</div>
<p>
        With sharding and EC2, be careful that the potential for failure
        of an instance does not affect your application. If the EC2
        instance that provides the MySQL server for a particular shard
        fails, then all of the data on that shard becomes unavailable.
</p>
</div>

</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h2 class="title" style="clear: both"><a name="ha-zfs-replication"></a>16.5 Using ZFS Replication</h2>

</div>

</div>

</div>
<div class="toc">
<dl class="toc"><dt><span class="section"><a href="ha-overview.html#ha-zfs-config">16.5.1 Using ZFS for File System Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql">16.5.2 Configuring MySQL for ZFS Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql-recovery">16.5.3 Handling MySQL Recovery with ZFS</a></span></dt></dl>
</div>
<a class="indexterm" name="idm139737122796512"></a><a class="indexterm" name="idm139737122795424"></a><p>
    To support high availability environments, providing an instant copy
    of the information on both the currently active machine and the hot
    backup is a critical part of the HA solution. There are many
    solutions to this problem, including <a class="xref" href="replication.html" title="Chapter 17 Replication">Chapter 17, <i>Replication</i></a>
    and <a class="xref" href="ha-overview.html#ha-drbd" title="16.2 Overview of MySQL with DRBD/Pacemaker/Corosync/Oracle Linux">Section 16.2, “Overview of MySQL with DRBD/Pacemaker/Corosync/Oracle Linux”</a>.
  </p><p>
    The ZFS file system provides functionality to create a snapshot of
    the file system contents, transfer the snapshot to another machine,
    and extract the snapshot to recreate the file system. You can create
    a snapshot at any time, and you can create as many snapshots as you
    like. By continually creating, transferring, and restoring
    snapshots, you can provide synchronization between one or more
    machines in a fashion similar to DRBD.
  </p><p>
    The following example shows a simple Solaris system running with a
    single ZFS pool, mounted at <code class="literal">/scratchpool</code>:
  </p><pre class="programlisting">
Filesystem             size   used  avail capacity  Mounted on
/dev/dsk/c0d0s0        4.6G   3.7G   886M    82%    /
/devices                 0K     0K     0K     0%    /devices
ctfs                     0K     0K     0K     0%    /system/contract
proc                     0K     0K     0K     0%    /proc
mnttab                   0K     0K     0K     0%    /etc/mnttab
swap                   1.4G   892K   1.4G     1%    /etc/svc/volatile
objfs                    0K     0K     0K     0%    /system/object
/usr/lib/libc/libc_hwcap1.so.1
                       4.6G   3.7G   886M    82%    /lib/libc.so.1
fd                       0K     0K     0K     0%    /dev/fd
swap                   1.4G    40K   1.4G     1%    /tmp
swap                   1.4G    28K   1.4G     1%    /var/run
/dev/dsk/c0d0s7         26G   913M    25G     4%    /export/home
scratchpool             16G    24K    16G     1%    /scratchpool
</pre><p>
    The MySQL data is stored in a directory on
    <code class="literal">/scratchpool</code>. To help demonstrate some of the
    basic replication functionality, there are also other items stored
    in <code class="literal">/scratchpool</code> as well:
  </p><pre class="programlisting">
total 17
drwxr-xr-x  31 root     bin           50 Jul 21 07:32 DTT/
drwxr-xr-x   4 root     bin            5 Jul 21 07:32 SUNWmlib/
drwxr-xr-x  14 root     sys           16 Nov  5 09:56 SUNWspro/
drwxrwxrwx  19 1000     1000          40 Nov  6 19:16 emacs-22.1/
</pre><p>
    To create a snapshot of the file system, you use <code class="literal">zfs
    snapshot</code>, specifying the pool and the snapshot name:
  </p><pre class="programlisting">
root-shell&gt; zfs snapshot scratchpool@snap1
</pre><p>
    To list the snapshots already taken:
  </p><pre class="programlisting">
root-shell&gt; zfs list -t snapshot
NAME                USED  AVAIL  REFER  MOUNTPOINT
scratchpool@snap1      0      -  24.5K  -
scratchpool@snap2      0      -  24.5K  -
</pre><p>
    The snapshots themselves are stored within the file system metadata,
    and the space required to keep them varies as time goes on because
    of the way the snapshots are created. The initial creation of a
    snapshot is very quick, because instead of taking an entire copy of
    the data and metadata required to hold the entire snapshot, ZFS
    records only the point in time and metadata of when the snapshot was
    created.
  </p><p>
    As more changes to the original file system are made, the size of
    the snapshot increases because more space is required to keep the
    record of the old blocks. If you create lots of snapshots, say one
    per day, and then delete the snapshots from earlier in the week, the
    size of the newer snapshots might also increase, as the changes that
    make up the newer state have to be included in the more recent
    snapshots, rather than being spread over the seven snapshots that
    make up the week.
  </p><p>
    You cannot directly back up the snapshots because they exist within
    the file system metadata rather than as regular files. To get the
    snapshot into a format that you can copy to another file system,
    tape, and so on, you use the <code class="literal">zfs send</code> command to
    create a stream version of the snapshot.
  </p><p>
    For example, to write the snapshot out to a file:
  </p><pre class="programlisting">
root-shell&gt; zfs send scratchpool@snap1 &gt;/backup/scratchpool-snap1
</pre><p>
    Or tape:
  </p><pre class="programlisting">
root-shell&gt; zfs send scratchpool@snap1 &gt;/dev/rmt/0
</pre><p>
    You can also write out the incremental changes between two snapshots
    using <code class="literal">zfs send</code>:
  </p><pre class="programlisting">
root-shell&gt; zfs send scratchpool@snap1 scratchpool@snap2 &gt;/backup/scratchpool-changes
</pre><p>
    To recover a snapshot, you use <code class="literal">zfs recv</code>, which
    applies the snapshot information either to a new file system, or to
    an existing one.
</p>
<div class="section">

<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-zfs-config"></a>16.5.1 Using ZFS for File System Replication</h3>
</div>
</div>
</div>
<p>
      Because <code class="literal">zfs send</code> and <code class="literal">zfs
      recv</code> use streams to exchange data, you can use them to
      replicate information from one system to another by combining
      <code class="literal">zfs send</code>, <code class="literal">ssh</code>, and
      <code class="literal">zfs recv</code>.
    </p><p>
      For example, to copy a snapshot of the
      <code class="literal">scratchpool</code> file system to a new file system
      called <code class="literal">slavepool</code> on a new server, you would use
      the following command. This sequence combines the snapshot of
      <code class="literal">scratchpool</code>, the transmission to the slave
      machine (using <span class="command"><strong>ssh</strong></span> with login credentials), and
      the recovery of the snapshot on the slave using <span class="command"><strong>zfs
      recv</strong></span>:
    </p><pre class="programlisting">
root-shell&gt; zfs send scratchpool@snap1 |ssh <em class="replaceable"><code>id</code></em>@<em class="replaceable"><code>host</code></em> pfexec zfs recv -F slavepool
</pre><p>
      The first part of the pipeline, <code class="literal">zfs send
      scratchpool@snap1</code>, streams the snapshot. The
      <code class="literal">ssh</code> command, and the command that it executes
      on the other server, <code class="literal">pfexec zfs recv -F
      slavepool</code>, receives the streamed snapshot data and
      writes it to slavepool. In this instance, I've specified the
      <code class="literal">-F</code> option which forces the snapshot data to be
      applied, and is therefore destructive. This is fine, as I'm
      creating the first version of my replicated file system.
    </p><p>
      On the slave machine, the replicated file system contains the
      exact same content:
    </p><pre class="programlisting">
root-shell&gt; ls -al /slavepool/
total 23
drwxr-xr-x   6 root     root           7 Nov  8 09:13 ./
drwxr-xr-x  29 root     root          34 Nov  9 07:06 ../
drwxr-xr-x  31 root     bin           50 Jul 21 07:32 DTT/
drwxr-xr-x   4 root     bin            5 Jul 21 07:32 SUNWmlib/
drwxr-xr-x  14 root     sys           16 Nov  5 09:56 SUNWspro/
drwxrwxrwx  19 1000     1000          40 Nov  6 19:16 emacs-22.1/
</pre><p>
      Once a snapshot has been created, to synchronize the file system
      again, you create a new snapshot and then use the incremental
      snapshot feature of <code class="literal">zfs send</code> to send the
      changes between the two snapshots to the slave machine again:
    </p><pre class="programlisting">
root-shell&gt; zfs send -i scratchpool@snapshot1 scratchpool@snapshot2 |ssh <em class="replaceable"><code>id</code></em>@<em class="replaceable"><code>host</code></em> pfexec zfs recv slavepool
</pre><p>
      This operation only succeeds if the file system on the slave
      machine has not been modified at all. You cannot apply the
      incremental changes to a destination file system that has changed.
      In the example above, the <code class="literal">ls</code> command would
      cause problems by changing the metadata, such as the last access
      time for files or directories.
    </p><p>
      To prevent changes on the slave file system, set the file system
      on the slave to be read-only:
    </p><pre class="programlisting">
root-shell&gt; zfs set readonly=on slavepool
</pre><p>
      Setting <code class="literal">readonly</code> means that you cannot change
      the file system on the slave by normal means, including the file
      system metadata. Operations that would normally update metadata
      (like our <code class="literal">ls</code>) silently perform their function
      without attempting to update the file system state.
    </p><p>
      In essence, the slave file system is nothing but a static copy of
      the original file system. However, even when configured to be
      read-only, a file system can have snapshots applied to it. With
      the file system set to read only, re-run the initial copy:
    </p><pre class="programlisting">
root-shell&gt; zfs send scratchpool@snap1 |ssh <em class="replaceable"><code>id</code></em>@<em class="replaceable"><code>host</code></em> pfexec zfs recv -F slavepool
</pre><p>
      Now you can make changes to the original file system and replicate
      them to the slave.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-zfs-mysql"></a>16.5.2 Configuring MySQL for ZFS Replication</h3>

</div>

</div>

</div>
<p>
      Configuring MySQL on the source file system is a case of creating
      the data on the file system that you intend to replicate. The
      configuration file in the example below has been updated to use
      <code class="literal">/scratchpool/mysql-data</code> as the data directory,
      and now you can initialize the tables:
    </p><pre class="programlisting">
root-shell&gt; mysql_install_db --defaults-file=/etc/mysql/5.5/my.cnf --user=mysql
</pre><p>
      To synchronize the initial information, perform a new snapshot and
      then send an incremental snapshot to the slave using <code class="literal">zfs
      send</code>:
    </p><pre class="programlisting">
root-shell&gt; zfs snapshot scratchpool@snap2
root-shell&gt; zfs send -i scratchpool@snap1 scratchpool@snap2|ssh <em class="replaceable"><code>id</code></em>@<em class="replaceable"><code>host</code></em> pfexec zfs recv slavepool
</pre><p>
      Doublecheck that the slave has the data by looking at the MySQL
      data directory on the <code class="literal">slavepool</code>:
    </p><pre class="programlisting">
root-shell&gt; ls -al /slavepool/mysql-data/
</pre><p>
      Now you can start up MySQL, create some data, and then replicate
      the changes using <code class="literal">zfs send</code>/<code class="literal"> zfs
      recv</code> to the slave to synchronize the changes.
    </p><p>
      The rate at which you perform the synchronization depends on your
      application and environment. The limitation is the speed required
      to perform the snapshot and then to send the changes over the
      network.
    </p><p>
      To automate the process, create a script that performs the
      snapshot, send, and receive operation, and use
      <code class="literal">cron</code> to synchronize the changes at set times or
      intervals.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-zfs-mysql-recovery"></a>16.5.3 Handling MySQL Recovery with ZFS</h3>

</div>

</div>

</div>
<p>
      When using ZFS replication to provide a constant copy of your
      data, ensure that you can recover your tables, either manually or
      automatically, in the event of a failure of the original system.
    </p><p>
      In the event of a failure, follow this sequence:
</p>
<div class="orderedlist">
<ol class="orderedlist" type="1"><li class="listitem"><p>
          Stop the script on the master, if it is still up and running.
        </p></li><li class="listitem"><p>
          Set the slave file system to be read/write:

</p><pre class="programlisting">
root-shell&gt; zfs set readonly=off slavepool
</pre><p>
        </p></li><li class="listitem"><p>
          Start up <a class="link" href="programs.html#mysqld" title="4.3.1 mysqld — The MySQL Server"><span class="command"><strong>mysqld</strong></span></a> on the slave. If you are
          using <code class="literal">InnoDB</code>, you get auto-recovery, if it
          is needed, to make sure the table data is correct, as shown
          here when I started up from our mid-INSERT snapshot:

</p><pre class="programlisting">
InnoDB: The log sequence number in ibdata files does not match
InnoDB: the log sequence number in the ib_logfiles!
081109 15:59:59  InnoDB: Database was not shut down normally!
InnoDB: Starting crash recovery.
InnoDB: Reading tablespace information from the .ibd files...
InnoDB: Restoring possible half-written data pages from the doublewrite
InnoDB: buffer...
081109 16:00:03  InnoDB: Started; log sequence number 0 1142807951
081109 16:00:03 [Note] /slavepool/mysql-5.0.67-solaris10-i386/bin/mysqld: ready for connections.
Version: '5.0.67'  socket: '/tmp/mysql.sock'  port: 3306  MySQL Community Server (GPL)
</pre><p>
</p></li></ol>
</div>
<p>
      Use <a class="link" href="innodb-storage-engine.html" title="Chapter 14 The InnoDB Storage Engine"><code class="literal">InnoDB</code></a> tables and a regular
      synchronization schedule to reduce the risk for significant data
      loss. On MyISAM tables, you might need to run
      <a class="link" href="sql-syntax.html#repair-table" title="13.7.2.5 REPAIR TABLE Syntax"><code class="literal">REPAIR TABLE</code></a>, and you might even
      have lost some information.
</p>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h2 class="title" style="clear: both"><a name="ha-memcached"></a>16.6 Using MySQL with <span class="command"><strong>memcached</strong></span></h2>

</div>

</div>

</div>
<div class="toc">
<dl class="toc"><dt><span class="section"><a href="ha-overview.html#ha-memcached-install">16.6.1 Installing <span class="command"><strong>memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using">16.6.2 Using <span class="command"><strong>memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces">16.6.3 Developing a <span class="command"><strong>memcached</strong></span> Application</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats">16.6.4 Getting <span class="command"><strong>memcached</strong></span> Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-faq">16.6.5 <span class="command"><strong>memcached</strong></span> FAQ</a></span></dt></dl>
</div>
<p>
    <span class="command"><strong>memcached</strong></span> is a simple, highly scalable key-based
    cache that stores data and objects wherever dedicated or spare RAM
    is available for quick access by applications, without going through
    layers of parsing or disk I/O. To use, you run the
    <span class="command"><strong>memcached</strong></span> command on one or more hosts and then
    use the shared cache to store objects. For more usage instructions,
    see <a class="xref" href="ha-overview.html#ha-memcached-using" title="16.6.2 Using memcached">Section 16.6.2, “Using <span class="command"><strong>memcached</strong></span>”</a>
  </p><p>
    Benefits of using <span class="command"><strong>memcached</strong></span> include:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
        Because all information is stored in RAM, the access speed is
        faster than loading the information each time from disk.
      </p></li><li class="listitem"><p>
        Because the <span class="quote">“<span class="quote">value</span>”</span> portion of the key-value pair
        does not have any data type restrictions, you can cache data
        such as complex structures, documents, images, or a mixture of
        such things.
      </p></li><li class="listitem"><p>
        If you use the in-memory cache to hold transient information, or
        as a read-only cache for information also stored in a database,
        the failure of any <span class="command"><strong>memcached</strong></span> server is not
        critical. For persistent data, you can fall back to an
        alternative lookup method using database queries, and reload the
        data into RAM on a different server.
</p></li></ul>
</div>
<p>
    The typical usage environment is to modify your application so that
    information is read from the cache provided by
    <span class="command"><strong>memcached</strong></span>. If the information is not in
    <span class="command"><strong>memcached</strong></span>, then the data is loaded from the MySQL
    database and written into the cache so that future requests for the
    same object benefit from the cached data.
  </p><p>
    For a typical deployment layout, see
    <a class="xref" href="ha-overview.html#ha-memcached-fig-overview" title="Figure 16.4 memcached Architecture Overview">Figure 16.4, “<span class="command">memcached</span> Architecture Overview”</a>.
</p>
<div class="figure">
<a name="ha-memcached-fig-overview"></a><p class="title"><b>Figure 16.4 <span class="command">memcached</span> Architecture Overview</b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/memcached-overview.png" width="540" height="296" alt="memcached Architecture Overview">
</div>

</div>

</div>
<br class="figure-break"><p>
    In the example structure, any of the clients can contact one of the
    <span class="command"><strong>memcached</strong></span> servers to request a given key. Each
    client is configured to talk to all of the servers shown in the
    illustration. Within the client, when the request is made to store
    the information, the key used to reference the data is hashed and
    this hash is then used to select one of the
    <span class="command"><strong>memcached</strong></span> servers. The selection of the
    <span class="command"><strong>memcached</strong></span> server takes place on the client before
    the server is contacted, keeping the process lightweight.
  </p><p>
    The same algorithm is used again when a client requests the same
    key. The same key generates the same hash, and the same
    <span class="command"><strong>memcached</strong></span> server is selected as the source for
    the data. Using this method, the cached data is spread among all of
    the <span class="command"><strong>memcached</strong></span> servers, and the cached information
    is accessible from any client. The result is a distributed,
    memory-based, cache that can return information, particularly
    complex data and structures, much faster than natively reading the
    information from the database.
  </p><p>
    The data held within a traditional <span class="command"><strong>memcached</strong></span>
    server is never stored on disk (only in RAM, which means there is no
    persistence of data), and the RAM cache is always populated from the
    backing store (a MySQL database). If a <span class="command"><strong>memcached</strong></span>
    server fails, the data can always be recovered from the MySQL
    database.
</p>
<div class="section">

<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-memcached-install"></a>16.6.1 Installing <span class="command"><strong>memcached</strong></span></h3>
</div>
</div>
</div>
<p>
      You can build and install <span class="command"><strong>memcached</strong></span> from the
      source code directly, or you can use an existing operating system
      package or installation.
    </p><p>
      <span class="bold"><strong>Installing <span class="command"><strong>memcached</strong></span> from
      a Binary Distribution</strong></span>
    </p><p>
      To install <span class="command"><strong>memcached</strong></span> on a Red Hat, or Fedora
      host, use <span class="command"><strong>yum</strong></span>:
    </p><pre class="programlisting">
root-shell&gt; yum install memcached
</pre>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
        On CentOS, you may be able to obtain a suitable RPM from another
        source, or use the source tarball.
</p>
</div>
<p>
      To install <span class="command"><strong>memcached</strong></span> on a Debian or Ubuntu
      host, use <span class="command"><strong>apt-get</strong></span>:
    </p><pre class="programlisting">
root-shell&gt; apt-get install memcached
</pre><p>
      To install <span class="command"><strong>memcached</strong></span> on a Gentoo host, use
      <span class="command"><strong>emerge</strong></span>:
    </p><pre class="programlisting">
root-shell&gt; emerge install memcached
</pre><p>
      <span class="bold"><strong>Building <span class="command"><strong>memcached</strong></span> from
      Source</strong></span>
    </p><p>
      On other Unix-based platforms, including Solaris, AIX, HP-UX and
      OS X, and Linux distributions not mentioned already, you must
      install from source. For Linux, make sure you have a 2.6-based
      kernel, which includes the improved <code class="literal">epoll</code>
      interface. For all platforms, ensure that you have
      <code class="literal">libevent</code> 1.1 or higher installed. You can
      obtain <code class="literal">libevent</code> from
      <a class="ulink" href="http://www.monkey.org/~provos/libevent/" target="_top"><code class="literal">libevent</code>
      web page</a>.
    </p><p>
      You can obtain the source for <span class="command"><strong>memcached</strong></span> from
      <a class="ulink" href="http://www.danga.com/memcached" target="_top"><span class="command"><strong>memcached</strong></span>
      Web site</a>.
    </p><p>
      To build <span class="command"><strong>memcached</strong></span>, follow these steps:
</p>
<div class="orderedlist">
<ol class="orderedlist" type="1"><li class="listitem"><p>
          Extract the <span class="command"><strong>memcached</strong></span> source package:
        </p><pre class="programlisting">
shell&gt; gunzip -c memcached-<em class="replaceable"><code>1.2.5</code></em>.tar.gz | tar xf - 
</pre></li><li class="listitem"><p>
          Change to the
          <span class="command"><strong>memcached-<em class="replaceable"><code>1.2.5</code></em>
          directory:</strong></span>
        </p><pre class="programlisting">
shell&gt; cd memcached-<em class="replaceable"><code>1.2.5</code></em>
</pre></li><li class="listitem"><p>
          Run <span class="command"><strong>configure</strong></span>
        </p><pre class="programlisting">
shell&gt; ./configure
</pre><p>
          Some additional options you might specify to the
          <span class="command"><strong>configure</strong></span>:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
              <code class="option">--prefix</code>
            </p><p>
              To specify a different installation directory, use the
              <code class="option">--prefix</code> option:
            </p><pre class="programlisting">
shell&gt; ./configure --prefix=/opt
</pre><p>
              The default is to use the <code class="filename">/usr/local</code>
              directory.
            </p></li><li class="listitem"><p>
              <code class="option">--with-libevent</code>
            </p><p>
              If you have installed <code class="filename">libevent</code> and
              <span class="command"><strong>configure</strong></span> cannot find the library, use
              the <code class="option">--with-libevent</code> option to specify the
              location of the installed library.
            </p></li><li class="listitem"><p>
              <code class="option">--enable-64bit</code>
            </p><p>
              To build a 64-bit version of <span class="command"><strong>memcached</strong></span>
              (which enables you to use a single instance with a large
              RAM allocation), use <code class="option">--enable-64bit</code>.
            </p></li><li class="listitem"><p>
              <code class="option">--enable-threads</code>
            </p><p>
              To enable multi-threading support in
              <span class="command"><strong>memcached</strong></span>, which improves the response
              times on servers with a heavy load, use
              <code class="option">--enable-threads</code>. You must have support
              for the POSIX threads within your operating system to
              enable thread support. For more information on the
              threading support, see
              <a class="xref" href="ha-overview.html#ha-memcached-using-threads" title="16.6.2.7 memcached Thread Support">Section 16.6.2.7, “<span class="command"><strong>memcached</strong></span> Thread Support”</a>.
            </p></li><li class="listitem"><p>
              <code class="option">--enable-dtrace</code>
            </p><p>
              <span class="command"><strong>memcached</strong></span> includes a range of DTrace
              threads that can be used to monitor and benchmark a
              <span class="command"><strong>memcached</strong></span> instance. For more
              information, see
              <a class="xref" href="ha-overview.html#ha-memcached-using-dtrace" title="16.6.2.5 Using memcached and DTrace">Section 16.6.2.5, “Using <span class="command"><strong>memcached</strong></span> and DTrace”</a>.
</p></li></ul>
</div>
</li><li class="listitem"><p>
          Run <span class="command"><strong>make</strong></span> to build
          <span class="command"><strong>memcached</strong></span>:
        </p><pre class="programlisting">
shell&gt; make
</pre></li><li class="listitem"><p>
          Run <span class="command"><strong>make install</strong></span> to install
          <span class="command"><strong>memcached</strong></span>:
        </p><pre class="programlisting">
shell&gt; make install
</pre></li></ol>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-memcached-using"></a>16.6.2 Using <span class="command"><strong>memcached</strong></span></h3>

</div>

</div>

</div>
<div class="toc">
<dl class="toc"><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-deployment">16.6.2.1 <span class="command"><strong>memcached</strong></span> Deployment</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-namespaces">16.6.2.2 Using Namespaces</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-expiry">16.6.2.3 Data Expiry</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-hashtypes">16.6.2.4 <span class="command"><strong>memcached</strong></span> Hashing/Distribution Types</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-dtrace">16.6.2.5 Using <span class="command"><strong>memcached</strong></span> and DTrace</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-memory">16.6.2.6 Memory Allocation within <span class="command"><strong>memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-threads">16.6.2.7 <span class="command"><strong>memcached</strong></span> Thread Support</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-logs">16.6.2.8 <span class="command"><strong>memcached</strong></span> Logs</a></span></dt></dl>
</div>
<p>
      To start using <span class="command"><strong>memcached</strong></span>, start the
      <span class="command"><strong>memcached</strong></span> service on one or more servers.
      Running <span class="command"><strong>memcached</strong></span> sets up the server, allocates
      the memory and starts listening for connections from clients.
</p>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
        You do not need to be a privileged user
        (<code class="literal">root</code>) to run <span class="command"><strong>memcached</strong></span>
        except to listen on one of the privileged TCP/IP ports (below
        1024). You must, however, use a user that has not had their
        memory limits restricted using <span class="command"><strong>setrlimit</strong></span> or
        similar.
</p>
</div>
<p>
      To start the server, run <span class="command"><strong>memcached</strong></span> as a
      nonprivileged (that is, non-<code class="literal">root</code>) user:
    </p><pre class="programlisting">
shell&gt; memcached
</pre><p>
      By default, <span class="command"><strong>memcached</strong></span> uses the following
      settings:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          Memory allocation of 64MB
        </p></li><li class="listitem"><p>
          Listens for connections on all network interfaces, using port
          11211
        </p></li><li class="listitem"><p>
          Supports a maximum of 1024 simultaneous connections
</p></li></ul>
</div>
<p>
      Typically, you would specify the full combination of options that
      you want when starting <span class="command"><strong>memcached</strong></span>, and normally
      provide a startup script to handle the initialization of
      <span class="command"><strong>memcached</strong></span>. For example, the following line
      starts <span class="command"><strong>memcached</strong></span> with a maximum of 1024MB RAM
      for the cache, listening on port 11211 on the IP address
      192.168.0.110, running as a background daemon:
    </p><pre class="programlisting">
shell&gt; memcached -d -m 1024 -p 11211 -l 192.168.0.110
</pre><p>
      To ensure that <span class="command"><strong>memcached</strong></span> is started up on boot,
      check the init script and configuration parameters.
    </p><p>
      <span class="command"><strong>memcached</strong></span> supports the following options:
</p>
<div class="itemizedlist">
<a name="ha-memcached-cmdline-options"></a><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          <code class="option">-u user</code>
        </p><p>
          If you start <span class="command"><strong>memcached</strong></span> as
          <code class="literal">root</code>, use the <code class="option">-u</code> option to
          specify the user for executing <span class="command"><strong>memcached</strong></span>:
        </p><pre class="programlisting">
shell&gt; memcached -u memcache
</pre></li><li class="listitem"><p>
          <code class="option">-m memory</code>
        </p><p>
          Set the amount of memory allocated to
          <span class="command"><strong>memcached</strong></span> for object storage. Default is
          64MB.
        </p><p>
          To increase the amount of memory allocated for the cache, use
          the <code class="option">-m</code> option to specify the amount of RAM to
          be allocated (in megabytes). The more RAM you allocate, the
          more data you can store and therefore the more effective your
          cache is.
</p>
<div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Warning
</div>
<p>
            Do not specify a memory allocation larger than your
            available RAM. If you specify too large a value, then some
            RAM allocated for <span class="command"><strong>memcached</strong></span> uses swap
            space, and not physical RAM. This may lead to delays when
            storing and retrieving values, because data is swapped to
            disk, instead of storing the data directly in RAM.
          </p><p>
            You can use the output of the <span class="command"><strong>vmstat</strong></span>
            command to get the free memory, as shown in
            <code class="literal">free</code> column:
          </p><pre class="programlisting">
shell&gt; vmstat
kthr      memory            page            disk          faults      cpu
r b w   swap  free  re  mf pi po fr de sr s1 s2 -- --   in   sy   cs us sy id
0 0 0 5170504 3450392 2  7  2  0  0  0  4  0  0  0  0  296   54  199  0  0 100
</pre>
</div>
<p>
          For example, to allocate 3GB of RAM:
        </p><pre class="programlisting">
shell&gt; memcached -m 3072
</pre><p>
          On 32-bit x86 systems where you are using PAE to access memory
          above the 4GB limit, you cannot allocate RAM beyond the
          maximum process size. You can get around this by running
          multiple instances of <span class="command"><strong>memcached</strong></span>, each
          listening on a different port:
        </p><pre class="programlisting">
shell&gt; memcached -m 1024 -p11211
shell&gt; memcached -m 1024 -p11212
shell&gt; memcached -m 1024 -p11213
</pre>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
            On all systems, particularly 32-bit, ensure that you leave
            enough room for both <span class="command"><strong>memcached</strong></span>
            application in addition to the memory setting. For example,
            if you have a dedicated <span class="command"><strong>memcached</strong></span> host
            with 4GB of RAM, do not set the memory size above 3500MB.
            Failure to do this may cause either a crash or severe
            performance issues.
</p>
</div>
</li><li class="listitem"><p>
          <code class="option">-l interface</code>
        </p><p>
          Specify a network interface/address to listen for connections.
          The default is to listen on all available address
          (<code class="literal">INADDR_ANY</code>).
        </p><pre class="programlisting">
shell&gt; memcached -l 192.168.0.110
</pre><p>
          Support for IPv6 address support was added in
          <span class="command"><strong>memcached</strong></span> 1.2.5.
        </p></li><li class="listitem"><p>
          <code class="option">-p port</code>
        </p><p>
          Specify the TCP port to use for connections. Default is 18080.
        </p><pre class="programlisting">
shell&gt; memcached -p 18080
</pre></li><li class="listitem"><p>
          <code class="option">-U port</code>
        </p><p>
          Specify the UDP port to use for connections. Default is 11211,
          0 switches UDP off.
        </p><pre class="programlisting">
shell&gt; memcached -U 18080
</pre></li><li class="listitem"><p>
          <code class="option">-s socket</code>
        </p><p>
          Specify a Unix socket to listen on.
        </p><p>
          If you are running <span class="command"><strong>memcached</strong></span> on the same
          server as the clients, you can disable the network interface
          and use a local Unix socket using the <code class="option">-s</code>
          option:
        </p><pre class="programlisting">
shell&gt; memcached -s /tmp/memcached
</pre><p>
          Using a Unix socket automatically disables network support,
          and saves network ports (allowing more ports to be used by
          your web server or other process).
        </p></li><li class="listitem"><p>
          <code class="option">-a mask</code>
        </p><p>
          Specify the access mask to be used for the Unix socket, in
          octal. Default is 0700.
        </p></li><li class="listitem"><p>
          <code class="option">-c connections</code>
        </p><p>
          Specify the maximum number of simultaneous connections to the
          <span class="command"><strong>memcached</strong></span> service. The default is 1024.
        </p><pre class="programlisting">
shell&gt; memcached -c 2048
</pre><p>
          Use this option, either to reduce the number of connections
          (to prevent overloading <span class="command"><strong>memcached</strong></span> service)
          or to increase the number to make more effective use of the
          server running <span class="command"><strong>memcached</strong></span> server.
        </p></li><li class="listitem"><p>
          <code class="option">-t threads</code>
        </p><p>
          Specify the number of threads to use when processing incoming
          requests.
        </p><p>
          By default, <span class="command"><strong>memcached</strong></span> is configured to use
          4 concurrent threads. The threading improves the performance
          of storing and retrieving data in the cache, using a locking
          system to prevent different threads overwriting or updating
          the same values. To increase or decrease the number of
          threads, use the <code class="literal">-t</code> option:
        </p><pre class="programlisting">
shell&gt; memcached -t 8
</pre></li><li class="listitem"><p>
          <code class="option">-d</code>
        </p><p>
          Run <span class="command"><strong>memcached</strong></span> as a daemon (background)
          process:
        </p><pre class="programlisting">
shell&gt; memcached -d
</pre></li><li class="listitem"><p>
          <code class="option">-r</code>
        </p><p>
          Maximize the size of the core file limit. In the event of a
          failure, this attempts to dump the entire memory space to disk
          as a core file, up to any limits imposed by
          <span class="command"><strong>setrlimit</strong></span>.
        </p></li><li class="listitem"><p>
          <code class="option">-M</code>
        </p><p>
          Return an error to the client when the memory has been
          exhausted. This replaces the normal behavior of removing older
          items from the cache to make way for new items.
        </p></li><li class="listitem"><p>
          <code class="option">-k</code>
        </p><p>
          Lock down all paged memory. This reserves the memory before
          use, instead of allocating new slabs of memory as new items
          are stored in the cache.
</p>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
            There is a user-level limit on how much memory you can lock.
            Trying to allocate more than the available memory fails. You
            can set the limit for the user you started the daemon with
            (not for the <code class="option">-u user</code> user) within the shell
            by using <span class="command"><strong>ulimit -S -l NUM_KB</strong></span>
</p>
</div>
</li><li class="listitem"><p>
          <code class="option">-v</code>
        </p><p>
          Verbose mode. Prints errors and warnings while executing the
          main event loop.
        </p></li><li class="listitem"><p>
          <code class="option">-vv</code>
        </p><p>
          Very verbose mode. In addition to information printed by
          <code class="option">-v</code>, also prints each client command and the
          response.
        </p></li><li class="listitem"><p>
          <code class="option">-vvv</code>
        </p><p>
          Extremely verbose mode. In addition to information printed by
          <code class="option">-vv</code>, also show the internal state
          transitions.
        </p></li><li class="listitem"><p>
          <code class="option">-h</code>
        </p><p>
          Print the help message and exit.
        </p></li><li class="listitem"><p>
          <code class="option">-i</code>
        </p><p>
          Print the <span class="command"><strong>memcached</strong></span> and
          <code class="literal">libevent</code> license.
        </p></li><li class="listitem"><p>
          <code class="option">-I mem</code>
        </p><p>
          Specify the maximum size permitted for storing an object
          within the <span class="command"><strong>memcached</strong></span> instance. The size
          supports a unit postfix (<code class="literal">k</code> for kilobytes,
          <code class="literal">m</code> for megabytes). For example, to increase
          the maximum supported object size to 32MB:
        </p><pre class="programlisting">
shell&gt; memcached -I 32m
</pre><p>
          The maximum object size you can specify is 128MB, the default
          remains at 1MB.
        </p><p>
          This option was added in 1.4.2.
        </p></li><li class="listitem"><p>
          <code class="option">-b</code>
        </p><p>
          Set the backlog queue limit. The backlog queue configures how
          many network connections can be waiting to be processed by
          <span class="command"><strong>memcached</strong></span>. Increasing this limit may reduce
          errors received by the client that it is not able to connect
          to the <span class="command"><strong>memcached</strong></span> instance, but does not
          improve the performance of the server. The default is 1024.
        </p></li><li class="listitem"><p>
          <code class="option">-P pidfile</code>
        </p><p>
          Save the process ID of the <span class="command"><strong>memcached</strong></span>
          instance into <code class="literal">file</code>.
        </p></li><li class="listitem"><p>
          <code class="option">-f</code>
        </p><p>
          Set the chunk size growth factor. When allocating new memory
          chunks, the allocated size of new chunks is determined by
          multiplying the default slab size by this factor.
        </p><p>
          To see the effects of this option without extensive testing,
          use the <code class="option">-vv</code> command-line option to show the
          calculated slab sizes. For more information, see
          <a class="xref" href="ha-overview.html#ha-memcached-using-logs" title="16.6.2.8 memcached Logs">Section 16.6.2.8, “<span class="command"><strong>memcached</strong></span> Logs”</a>.
        </p></li><li class="listitem"><p>
          <code class="option">-n bytes</code>
        </p><p>
          The minimum space allocated for the key+value+flags
          information. The default is 48 bytes.
        </p></li><li class="listitem"><p>
          <code class="option">-L</code>
        </p><p>
          On systems that support large memory pages, enables large
          memory page use. Using large memory pages enables
          <span class="command"><strong>memcached</strong></span> to allocate the item cache in one
          large chunk, which can improve the performance by reducing the
          number misses when accessing memory.
        </p></li><li class="listitem"><p>
          <code class="option">-C</code>
        </p><p>
          Disable the use of compare and swap (CAS) operations.
        </p><p>
          This option was added in <span class="command"><strong>memcached</strong></span> 1.3.x.
        </p></li><li class="listitem"><p>
          <code class="option">-D char</code>
        </p><p>
          Set the default character to be used as a delimiter between
          the key prefixes and IDs. This is used for the per-prefix
          statistics reporting (see
          <a class="xref" href="ha-overview.html#ha-memcached-stats" title="16.6.4 Getting memcached Statistics">Section 16.6.4, “Getting <span class="command"><strong>memcached</strong></span> Statistics”</a>). The default is the
          colon (<code class="literal">:</code>). If this option is used,
          statistics collection is turned on automatically. If not used,
          you can enable stats collection by sending the <code class="literal">stats
          detail on</code> command to the server.
        </p><p>
          This option was added in <span class="command"><strong>memcached</strong></span> 1.3.x.
        </p></li><li class="listitem"><p>
          <code class="option">-R num</code>
        </p><p>
          Sets the maximum number of requests per event process. The
          default is 20.
        </p></li><li class="listitem"><p>
          <code class="option">-B protocol</code>
        </p><p>
          Set the binding protocol, that is, the default
          <span class="command"><strong>memcached</strong></span> protocol support for client
          connections. Options are <code class="literal">ascii</code>,
          <code class="literal">binary</code> or <code class="literal">auto</code>.
          Automatic (<code class="literal">auto</code>) is the default.
        </p><p>
          This option was added in <span class="command"><strong>memcached</strong></span> 1.4.0.
</p></li></ul>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-deployment"></a>16.6.2.1 <span class="command"><strong>memcached</strong></span> Deployment</h4>

</div>

</div>

</div>
<p>
        When using <span class="command"><strong>memcached</strong></span> you can use a number of
        different potential deployment strategies and topologies. The
        exact strategy to use depends on your application and
        environment. When developing a system for deploying
        <span class="command"><strong>memcached</strong></span> within your system, keep in mind
        the following points:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <span class="command"><strong>memcached</strong></span> is only a caching mechanism. It
            shouldn't be used to store information that you cannot
            otherwise afford to lose and then load from a different
            location.
          </p></li><li class="listitem"><p>
            There is no security built into the
            <span class="command"><strong>memcached</strong></span> protocol. At a minimum, make
            sure that the servers running <span class="command"><strong>memcached</strong></span>
            are only accessible from inside your network, and that the
            network ports being used are blocked (using a firewall or
            similar). If the information on the
            <span class="command"><strong>memcached</strong></span> servers that is being stored is
            any sensitive, then encrypt the information before storing
            it in <span class="command"><strong>memcached</strong></span>.
          </p></li><li class="listitem"><p>
            <span class="command"><strong>memcached</strong></span> does not provide any sort of
            failover. Because there is no communication between
            different <span class="command"><strong>memcached</strong></span> instances. If an
            instance fails, your application must capable of removing it
            from the list, reloading the data and then writing data to
            another <span class="command"><strong>memcached</strong></span> instance.
          </p></li><li class="listitem"><p>
            Latency between the clients and the
            <span class="command"><strong>memcached</strong></span> can be a problem if you are
            using different physical machines for these tasks. If you
            find that the latency is a problem, move the
            <span class="command"><strong>memcached</strong></span> instances to be on the clients.
          </p></li><li class="listitem"><p>
            Key length is determined by the <span class="command"><strong>memcached</strong></span>
            server. The default maximum key size is 250 bytes.
          </p></li><li class="listitem"><p>
            Try to use at least two <span class="command"><strong>memcached</strong></span>
            instances, especially for multiple clients, to avoid having
            a single point of failure. Ideally, create as many
            <span class="command"><strong>memcached</strong></span> nodes as possible. When adding
            and removing <span class="command"><strong>memcached</strong></span> instances from a
            pool, the hashing and distribution of key/value pairs may be
            affected. For information on how to avoid problems, see
            <a class="xref" href="ha-overview.html#ha-memcached-using-hashtypes" title="16.6.2.4 memcached Hashing/Distribution Types">Section 16.6.2.4, “<span class="command"><strong>memcached</strong></span> Hashing/Distribution Types”</a>.
</p></li></ul>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-namespaces"></a>16.6.2.2 Using Namespaces</h4>

</div>

</div>

</div>
<p>
        The <span class="command"><strong>memcached</strong></span> cache is a very simple massive
        key/value storage system, and as such there is no way of
        compartmentalizing data automatically into different sections.
        For example, if you are storing information by the unique ID
        returned from a MySQL database, then storing the data from two
        different tables could run into issues because the same ID might
        be valid in both tables.
      </p><p>
        Some interfaces provide an automated mechanism for creating
        <span class="emphasis"><em>namespaces</em></span> when storing information into
        the cache. In practice, these namespaces are merely a prefix
        before a given ID that is applied every time a value is stored
        or retrieve from the cache.
      </p><p>
        You can implement the same basic principle by using keys that
        describe the object and the unique identifier within the key
        that you supply when the object is stored. For example, when
        storing user data, prefix the ID of the user with
        <code class="literal">user:</code> or <code class="literal">user-</code>.
</p>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
          Using namespaces or prefixes only controls the keys
          stored/retrieved. There is no security within
          <span class="command"><strong>memcached</strong></span>, and therefore no way to enforce
          that a particular client only accesses keys with a particular
          namespace. Namespaces are only useful as a method of
          identifying data and preventing corruption of key/value pairs.
</p>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-expiry"></a>16.6.2.3 Data Expiry</h4>

</div>

</div>

</div>
<p>
        There are two types of data expiry within a
        <span class="command"><strong>memcached</strong></span> instance. The first type is applied
        at the point when you store a new key/value pair into the
        <span class="command"><strong>memcached</strong></span> instance. If there is not enough
        space within a suitable slab to store the value, then an
        existing least recently used (LRU) object is removed (evicted)
        from the cache to make room for the new item.
      </p><p>
        The LRU algorithm ensures that the object that is removed is one
        that is either no longer in active use or that was used so long
        ago that its data is potentially out of date or of little value.
        However, in a system where the memory allocated to
        <span class="command"><strong>memcached</strong></span> is smaller than the number of
        regularly used objects required in the cache, a lot of expired
        items could be removed from the cache even though they are in
        active use. You use the statistics mechanism to get a better
        idea of the level of evictions (expired objects). For more
        information, see <a class="xref" href="ha-overview.html#ha-memcached-stats" title="16.6.4 Getting memcached Statistics">Section 16.6.4, “Getting <span class="command"><strong>memcached</strong></span> Statistics”</a>.
      </p><p>
        You can change this eviction behavior by setting the
        <code class="literal">-M</code> command-line option when starting
        <span class="command"><strong>memcached</strong></span>. This option forces an error to be
        returned when the memory has been exhausted, instead of
        automatically evicting older data.
      </p><p>
        The second type of expiry system is an explicit mechanism that
        you can set when a key/value pair is inserted into the cache, or
        when deleting an item from the cache. Using an expiration time
        can be a useful way of ensuring that the data in the cache is up
        to date and in line with your application needs and
        requirements.
      </p><p>
        A typical scenario for explicitly setting the expiry time might
        include caching session data for a user when accessing a Web
        site. <span class="command"><strong>memcached</strong></span> uses a lazy expiry mechanism
        where the explicit expiry time that has been set is compared
        with the current time when the object is requested. Only objects
        that have not expired are returned.
      </p><p>
        You can also set the expiry time when explicitly deleting an
        object from the cache. In this case, the expiry time is really a
        timeout and indicates the period when any attempts to set the
        value for a given key are rejected.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-hashtypes"></a>16.6.2.4 <span class="command"><strong>memcached</strong></span> Hashing/Distribution Types</h4>

</div>

</div>

</div>
<p>
        The <span class="command"><strong>memcached</strong></span> client interface supports a
        number of different distribution algorithms that are used in
        multi-server configurations to determine which host should be
        used when setting or getting data from a given
        <span class="command"><strong>memcached</strong></span> instance. When you get or set a
        value, a hash is constructed from the supplied key and then used
        to select a host from the list of configured servers. Because
        the hashing mechanism uses the supplied key as the basis for the
        hash, the same server is selected during both set and get
        operations.
      </p><p>
        You can think of this process as follows. Given an array of
        servers (a, b, and c), the client uses a hashing algorithm that
        returns an integer based on the key being stored or retrieved.
        The resulting value is then used to select a server from the
        list of servers configured in the client. Most standard client
        hashing within <span class="command"><strong>memcache</strong></span> clients uses a simple
        modulus calculation on the value against the number of
        configured <span class="command"><strong>memcached</strong></span> servers. You can
        summarize the process in pseudocode as:
      </p><pre class="programlisting">
@memcservers = ['a.memc','b.memc','c.memc'];
$value = hash($key);
$chosen = $value % length(@memcservers);
</pre><p>
        Replacing the above with values:
      </p><pre class="programlisting">
@memcservers = ['a.memc','b.memc','c.memc'];
$value = hash('myid');
$chosen = 7009 % 3;
</pre><p>
        In the above example, the client hashing algorithm chooses the
        server at index 1 (<code class="literal">7009 % 3 = 1</code>), and store
        or retrieve the key and value with that server.
</p>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
          This selection and hashing process is handled automatically by
          the <span class="command"><strong>memcached</strong></span> client you are using; you
          need only provide the list of <span class="command"><strong>memcached</strong></span>
          servers to use.
</p>
</div>
<p>
        You can see a graphical representation of this below in
        <a class="xref" href="ha-overview.html#ha-memcached-using-hashtypes-fig-selection" title="Figure 16.5 memcached Hash Selection">Figure 16.5, “<span class="command">memcached</span> Hash Selection”</a>.
</p>
<div class="figure">
<a name="ha-memcached-using-hashtypes-fig-selection"></a><p class="title"><b>Figure 16.5 <span class="command">memcached</span> Hash Selection</b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/memcached-selection.png" width="513" height="228" alt="memcached Hash Selection">
</div>

</div>

</div>
<br class="figure-break"><p>
        The same hashing and selection process takes place during any
        operation on the specified key within the
        <span class="command"><strong>memcached</strong></span> client.
      </p><p>
        Using this method provides a number of advantages:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            The hashing and selection of the server to contact is
            handled entirely within the client. This eliminates the need
            to perform network communication to determine the right
            machine to contact.
          </p></li><li class="listitem"><p>
            Because the determination of the
            <span class="command"><strong>memcached</strong></span> server occurs entirely within
            the client, the server can be selected automatically
            regardless of the operation being executed (set, get,
            increment, etc.).
          </p></li><li class="listitem"><p>
            Because the determination is handled within the client, the
            hashing algorithm returns the same value for a given key;
            values are not affected or reset by differences in the
            server environment.
          </p></li><li class="listitem"><p>
            Selection is very fast. The hashing algorithm on the key
            value is quick and the resulting selection of the server is
            from a simple array of available machines.
          </p></li><li class="listitem"><p>
            Using client-side hashing simplifies the distribution of
            data over each <span class="command"><strong>memcached</strong></span> server. Natural
            distribution of the values returned by the hashing algorithm
            means that keys are automatically spread over the available
            servers.
</p></li></ul>
</div>
<p>
        Providing that the list of servers configured within the client
        remains the same, the same stored key returns the same value,
        and therefore selects the same server.
      </p><p>
        However, if you do not use the same hashing mechanism then the
        same data may be recorded on different servers by different
        interfaces, both wasting space on your
        <span class="command"><strong>memcached</strong></span> and leading to potential
        differences in the information.
</p>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
          One way to use a multi-interface compatible hashing mechanism
          is to use the <code class="literal">libmemcached</code> library and the
          associated interfaces. Because the interfaces for the
          different languages (including C, Ruby, Perl and Python) use
          the same client library interface, they always generate the
          same hash code from the ID.
</p>
</div>
<p>
        The problem with client-side selection of the server is that the
        list of the servers (including their sequential order)
        <span class="emphasis"><em>must</em></span> remain consistent on each client using
        the <span class="command"><strong>memcached</strong></span> servers, and the servers must
        be available. If you try to perform an operation on a key when:

</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
              A new <span class="command"><strong>memcached</strong></span> instance has been added
              to the list of available instances
            </p></li><li class="listitem"><p>
              A <span class="command"><strong>memcached</strong></span> instance has been removed
              from the list of available instances
            </p></li><li class="listitem"><p>
              The order of the <span class="command"><strong>memcached</strong></span> instances
              has changed
</p></li></ul>
</div>
<p>

        When the hashing algorithm is used on the given key, but with a
        different list of servers, the hash calculation may choose a
        different server from the list.
      </p><p>
        If a new <span class="command"><strong>memcached</strong></span> instance is added into the
        list of servers, as <code class="literal">new.memc</code> is in the
        example below, then a GET operation using the same key,
        <code class="literal">myid</code>, can result in a cache-miss. This is
        because the same value is computed from the key, which selects
        the same index from the array of servers, but index 2 now points
        to the new server, not the server <code class="literal">c.memc</code>
        where the data was originally stored. This would result in a
        cache miss, even though the key exists within the cache on
        another <span class="command"><strong>memcached</strong></span> instance.
</p>
<div class="figure">
<a name="ha-memcached-using-hashtypes-fig-addselect"></a><p class="title"><b>Figure 16.6 <span class="command">memcached</span> Hash Selection with New
<span class="command">memcached</span> instance</b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/memcached-addselect.png" width="626" height="228" alt="memcached Hash Selection with New memcached instance">
</div>

</div>

</div>
<br class="figure-break"><p>
        This means that servers <code class="literal">c.memc</code> and
        <code class="literal">new.memc </code> both contain the information for
        key <code class="literal">myid</code>, but the information stored against
        the key in eachs server may be different in each instance. A
        more significant problem is a much higher number of cache-misses
        when retrieving data, as the addition of a new server changes
        the distribution of keys, and this in turn requires rebuilding
        the cached data on the <span class="command"><strong>memcached</strong></span> instances,
        causing an increase in database reads.
      </p><p>
        The same effect can occur if you actively manage the list of
        servers configured in your clients, adding and removing the
        configured <span class="command"><strong>memcached</strong></span> instances as each
        instance is identified as being available. For example, removing
        a <span class="command"><strong>memcached</strong></span> instance when the client notices
        that the instance can no longer be contacted can cause the
        server selection to fail as described here.
      </p><p>
        To prevent this causing significant problems and invalidating
        your cache, you can select the hashing algorithm used to select
        the server. There are two common types of hashing algorithm,
        <span class="emphasis"><em>consistent</em></span> and <span class="emphasis"><em>modula</em></span>.
      </p><p>
        With <span class="emphasis"><em>consistent</em></span> hashing algorithms, the
        same key when applied to a list of servers always uses the same
        server to store or retrieve the keys, even if the list of
        configured servers changes. This means that you can add and
        remove servers from the configure list and always use the same
        server for a given key. There are two types of consistent
        hashing algorithms available, Ketama and Wheel. Both types are
        supported by <code class="literal">libmemcached</code>, and
        implementations are available for PHP and Java.
      </p><p>
        Any consistent hashing algorithm has some limitations. When you
        add servers to an existing list of configured servers, keys are
        distributed to the new servers as part of the normal
        distribution. When you remove servers from the list, the keys
        are re-allocated to another server within the list, meaning that
        the cache needs to be re-populated with the information. Also, a
        consistent hashing algorithm does not resolve the issue where
        you want consistent selection of a server across multiple
        clients, but where each client contains a different list of
        servers. The consistency is enforced only within a single
        client.
      </p><p>
        With a <span class="emphasis"><em>modula</em></span> hashing algorithm, the client
        selects a server by first computing the hash and then choosing a
        server from the list of configured servers. As the list of
        servers changes, so the server selected when using a modula
        hashing algorithm also changes. The result is the behavior
        described above; changes to the list of servers mean that
        different servers are selected when retrieving data, leading to
        cache misses and increase in database load as the cache is
        re-seeded with information.
      </p><p>
        If you use only a single <span class="command"><strong>memcached</strong></span> instance
        for each client, or your list of <span class="command"><strong>memcached</strong></span>
        servers configured for a client never changes, then the
        selection of a hashing algorithm is irrelevant, as it has no
        noticeable effect.
      </p><p>
        If you change your servers regularly, or you use a common set of
        servers that are shared among a large number of clients, then
        using a consistent hashing algorithm should help to ensure that
        your cache data is not duplicated and the data is evenly
        distributed.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-dtrace"></a>16.6.2.5 Using <span class="command"><strong>memcached</strong></span> and DTrace</h4>

</div>

</div>

</div>
<a class="indexterm" name="idm139737122395728"></a><p>
        <span class="command"><strong>memcached</strong></span> includes a number of different
        DTrace probes that can be used to monitor the operation of the
        server. The probes included can monitor individual connections,
        slab allocations, and modifications to the hash table when a
        key/value pair is added, updated, or removed.
      </p><p>
        For more information on DTrace and writing DTrace scripts, read
        the
        <a class="ulink" href="http://docs.oracle.com/cd/E19253-01/819-5488/" target="_top">DTrace
        User Guide</a>.
      </p><p>
        Support for DTrace probes was added to
        <span class="command"><strong>memcached</strong></span> 1.2.6 includes a number of DTrace
        probes that can be used to help monitor your application. DTrace
        is supported on Solaris 10, OpenSolaris, OS X 10.5 and FreeBSD.
        To enable the DTrace probes in <span class="command"><strong>memcached</strong></span>,
        build from source and use the <code class="option">--enable-dtrace</code>
        option. For more information, see
        <a class="xref" href="ha-overview.html#ha-memcached-install" title="16.6.1 Installing memcached">Section 16.6.1, “Installing <span class="command"><strong>memcached</strong></span>”</a>.
      </p><p>
        The probes supported by <span class="command"><strong>memcached</strong></span> are:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <code class="literal">conn-allocate(connid)</code>
          </p><p>
            Fired when a connection object is allocated from the
            connection pool.
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">conn-release(connid)</code>
          </p><p>
            Fired when a connection object is released back to the
            connection pool.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">conn-create(ptr)</code>
          </p><p>
            Fired when a new connection object is being created (that
            is, there are no free connection objects in the connection
            pool).
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">ptr</code>: A pointer to the connection.
                object
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">conn-destroy(ptr)</code>
          </p><p>
            Fired when a connection object is being destroyed.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">ptr</code>: A pointer to the connection
                object.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">conn-dispatch(connid, threadid)</code>
          </p><p>
            Fired when a connection is dispatched from the main or
            connection-management thread to a worker thread.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">threadid</code>: The thread ID.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">slabs-allocate(size, slabclass, slabsize,
            ptr)</code>
          </p><p>
            Allocate memory from the slab allocator.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">size</code>: The requested size.
              </p></li><li class="listitem"><p>
                <code class="literal">slabclass</code>: The allocation is
                fulfilled in this class.
              </p></li><li class="listitem"><p>
                <code class="literal">slabsize</code>: The size of each item in
                this class.
              </p></li><li class="listitem"><p>
                <code class="literal">ptr</code>: A pointer to allocated memory.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">slabs-allocate-failed(size, slabclass)</code>
          </p><p>
            Failed to allocate memory (out of memory).
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">size</code>: The requested size.
              </p></li><li class="listitem"><p>
                <code class="literal">slabclass</code>: The class that failed to
                fulfill the request.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">slabs-slabclass-allocate(slabclass)</code>
          </p><p>
            Fired when a slab class needs more space.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">slabclass</code>: The class that needs more
                memory.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">slabs-slabclass-allocate-failed(slabclass)</code>
          </p><p>
            Failed to allocate memory (out of memory).
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">slabclass</code>: The class that failed to
                grab more memory.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">slabs-free(size, slabclass, ptr)</code>
          </p><p>
            Release memory.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">size</code>: The amount of memory to
                release, in bytes.
              </p></li><li class="listitem"><p>
                <code class="literal">slabclass</code>: The class the memory
                belongs to.
              </p></li><li class="listitem"><p>
                <code class="literal">ptr</code>: A pointer to the memory to
                release.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">assoc-find(key, depth)</code>
          </p><p>
            Fired when we have searched the hash table for a named key.
            These two elements provide an insight into how well the hash
            function operates. Traversals are a sign of a less optimal
            function, wasting CPU capacity.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The key searched for.
              </p></li><li class="listitem"><p>
                <code class="literal">depth</code>: The depth in the list of hash
                table.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">assoc-insert(key, nokeys)</code>
          </p><p>
            Fired when a new item has been inserted.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The key just inserted.
              </p></li><li class="listitem"><p>
                <code class="literal">nokeys</code>: The total number of keys
                currently being stored, including the key for which
                insert was called.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">assoc-delete(key, nokeys)</code>
          </p><p>
            Fired when a new item has been removed.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The key just deleted.
              </p></li><li class="listitem"><p>
                <code class="literal">nokeys</code>: The total number of keys
                currently being stored, excluding the key for which
                delete was called.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">item-link(key, size)</code>
          </p><p>
            Fired when an item is being linked in the cache.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The items key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the data.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">item-unlink(key, size)</code>
          </p><p>
            Fired when an item is being deleted.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The items key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the data.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">item-remove(key, size)</code>
          </p><p>
            Fired when the refcount for an item is reduced.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The item's key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the data.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">item-update(key, size)</code>
          </p><p>
            Fired when the "last referenced" time is updated.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The item's key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the data.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">item-replace(oldkey, oldsize, newkey,
            newsize)</code>
          </p><p>
            Fired when an item is being replaced with another item.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">oldkey</code>: The key of the item to
                replace.
              </p></li><li class="listitem"><p>
                <code class="literal">oldsize</code>: The size of the old item.
              </p></li><li class="listitem"><p>
                <code class="literal">newkey</code>: The key of the new item.
              </p></li><li class="listitem"><p>
                <code class="literal">newsize</code>: The size of the new item.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">process-command-start(connid, request,
            size)</code>
          </p><p>
            Fired when the processing of a command starts.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">request</code>: The incoming request.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the request.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">process-command-end(connid, response,
            size)</code>
          </p><p>
            Fired when the processing of a command is done.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">response</code>: The response to send back
                to the client.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the response.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-get(connid, key, size)</code>
          </p><p>
            Fired for a <code class="literal">get</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the key's data (or
                -1 if not found).
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-gets(connid, key, size, casid)</code>
          </p><p>
            Fired for a <code class="literal">gets</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the key's data (or
                -1 if not found).
              </p></li><li class="listitem"><p>
                <code class="literal">casid</code>: The casid for the item.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-add(connid, key, size)</code>
          </p><p>
            Fired for a <code class="literal">add</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The new size of the key's data
                (or -1 if not found).
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-set(connid, key, size)</code>
          </p><p>
            Fired for a <code class="literal">set</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The new size of the key's data
                (or -1 if not found).
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-replace(connid, key, size)</code>
          </p><p>
            Fired for a <code class="literal">replace</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The new size of the key's data
                (or -1 if not found).
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-prepend(connid, key, size)</code>
          </p><p>
            Fired for a <code class="literal">prepend</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The new size of the key's data
                (or -1 if not found).
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-append(connid, key, size)</code>
          </p><p>
            Fired for a <code class="literal">append</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The new size of the key's data
                (or -1 if not found).
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-cas(connid, key, size, casid)</code>
          </p><p>
            Fired for a <code class="literal">cas</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">size</code>: The size of the key's data (or
                -1 if not found).
              </p></li><li class="listitem"><p>
                <code class="literal">casid</code>: The cas ID requested.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-incr(connid, key, val)</code>
          </p><p>
            Fired for <code class="literal">incr</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">val</code>: The new value.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-decr(connid, key, val)</code>
          </p><p>
            Fired for <code class="literal">decr</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">val</code>: The new value.
</p></li></ul>
</div>
</li><li class="listitem"><p>
            <code class="literal">command-delete(connid, key, exptime)</code>
          </p><p>
            Fired for a <code class="literal">delete</code> command.
          </p><p>
            Arguments:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">connid</code>: The connection ID.
              </p></li><li class="listitem"><p>
                <code class="literal">key</code>: The requested key.
              </p></li><li class="listitem"><p>
                <code class="literal">exptime</code>: The expiry time.
</p></li></ul>
</div>
</li></ul>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-memory"></a>16.6.2.6 Memory Allocation within <span class="command"><strong>memcached</strong></span></h4>

</div>

</div>

</div>
<p>
        When you first start <span class="command"><strong>memcached</strong></span>, the memory
        that you have configured is not automatically allocated.
        Instead, <span class="command"><strong>memcached</strong></span> only starts allocating and
        reserving physical memory once you start saving information into
        the cache.
      </p><p>
        When you start to store data into the cache,
        <span class="command"><strong>memcached</strong></span> does not allocate the memory for
        the data on an item by item basis. Instead, a slab allocation is
        used to optimize memory usage and prevent memory fragmentation
        when information expires from the cache.
      </p><p>
        With slab allocation, memory is reserved in blocks of 1MB. The
        slab is divided up into a number of blocks of equal size. When
        you try to store a value into the cache,
        <span class="command"><strong>memcached</strong></span> checks the size of the value that
        you are adding to the cache and determines which slab contains
        the right size allocation for the item. If a slab with the item
        size already exists, the item is written to the block within the
        slab.
      </p><p>
        If the new item is bigger than the size of any existing blocks,
        then a new slab is created, divided up into blocks of a suitable
        size. If an existing slab with the right block size already
        exists, but there are no free blocks, a new slab is created. If
        you update an existing item with data that is larger than the
        existing block allocation for that key, then the key is
        re-allocated into a suitable slab.
      </p><p>
        For example, the default size for the smallest block is 88 bytes
        (40 bytes of value, and the default 48 bytes for the key and
        flag data). If the size of the first item you store into the
        cache is less than 40 bytes, then a slab with a block size of 88
        bytes is created and the value stored.
      </p><p>
        If the size of the data that you intend to store is larger than
        this value, then the block size is increased by the chunk size
        factor until a block size large enough to hold the value is
        determined. The block size is always a function of the scale
        factor, rounded up to a block size which is exactly divisible
        into the chunk size.
      </p><p>
        For a sample of the structure, see
        <a class="xref" href="ha-overview.html#ha-memcached-fig-slabs" title="Figure 16.7 Memory Allocation in memcached">Figure 16.7, “Memory Allocation in <span class="command">memcached</span>”</a>.
</p>
<div class="figure">
<a name="ha-memcached-fig-slabs"></a><p class="title"><b>Figure 16.7 Memory Allocation in <span class="command">memcached</span></b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/memcached-memalloc.png" width="406" height="232" alt="Memory Allocation in memcached">
</div>

</div>

</div>
<br class="figure-break"><p>
        The result is that you have multiple pages allocated within the
        range of memory allocated to <span class="command"><strong>memcached</strong></span>. Each
        page is 1MB in size (by default), and is split into a different
        number of chunks, according to the chunk size required to store
        the key/value pairs. Each instance has multiple pages allocated,
        and a page is always created when a new item needs to be created
        requiring a chunk of a particular size. A slab may consist of
        multiple pages, and each page within a slab contains an equal
        number of chunks.
      </p><p>
        The chunk size of a new slab is determined by the base chunk
        size combined with the chunk size growth factor. For example, if
        the initial chunks are 104 bytes in size, and the default chunk
        size growth factor is used (1.25), then the next chunk size
        allocated would be the best power of 2 fit for 104*1.25, or 136
        bytes.
      </p><p>
        Allocating the pages in this way ensures that memory does not
        get fragmented. However, depending on the distribution of the
        objects that you store, it may lead to an inefficient
        distribution of the slabs and chunks if you have significantly
        different sized items. For example, having a relatively small
        number of items within each chunk size may waste a lot of memory
        with just few chunks in each allocated page.
      </p><p>
        You can tune the growth factor to reduce this effect by using
        the <code class="literal">-f</code> command line option, which adapts the
        growth factor applied to make more effective use of the chunks
        and slabs allocated. For information on how to determine the
        current slab allocation statistics, see
        <a class="xref" href="ha-overview.html#ha-memcached-stats-slabs" title="16.6.4.2 memcached Slabs Statistics">Section 16.6.4.2, “<span class="command"><strong>memcached</strong></span> Slabs Statistics”</a>.
      </p><p>
        If your operating system supports it, you can also start
        <span class="command"><strong>memcached</strong></span> with the <code class="literal">-L</code>
        command line option. This option preallocates all the memory
        during startup using large memory pages. This can improve
        performance by reducing the number of misses in the CPU memory
        cache.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-threads"></a>16.6.2.7 <span class="command"><strong>memcached</strong></span> Thread Support</h4>

</div>

</div>

</div>
<p>
        If you enable the thread implementation within when building
        <span class="command"><strong>memcached</strong></span> from source, then
        <span class="command"><strong>memcached</strong></span> uses multiple threads in addition
        to the <code class="literal">libevent</code> system to handle requests.
      </p><p>
        When enabled, the threading implementation operates as follows:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            Threading is handled by wrapping functions within the code
            to provide basic protection from updating the same global
            structures at the same time.
          </p></li><li class="listitem"><p>
            Each thread uses its own instance of the
            <code class="literal">libevent</code> to help improve performance.
          </p></li><li class="listitem"><p>
            TCP/IP connections are handled with a single thread
            listening on the TCP/IP socket. Each connection is then
            distributed to one of the active threads on a simple
            round-robin basis. Each connection then operates solely
            within this thread while the connection remains open.
          </p></li><li class="listitem"><p>
            For UDP connections, all the threads listen to a single UDP
            socket for incoming requests. Threads that are not currently
            dealing with another request ignore the incoming packet. One
            of the remaining, nonbusy, threads reads the request and
            sends the response. This implementation can lead to
            increased CPU load as threads wake from sleep to potentially
            process the request.
</p></li></ul>
</div>
<p>
        Using threads can increase the performance on servers that have
        multiple CPU cores available, as the requests to update the hash
        table can be spread between the individual threads. To minimize
        overhead from the locking mechanism employed, experiment with
        different thread values to achieve the best performance based on
        the number and type of requests within your given workload.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-using-logs"></a>16.6.2.8 <span class="command"><strong>memcached</strong></span> Logs</h4>

</div>

</div>

</div>
<p>
        If you enable verbose mode, using the <code class="option">-v</code>,
        <code class="option">-vv</code>, or <code class="option">-vvv</code> options, then the
        information output by <span class="command"><strong>memcached</strong></span> includes
        details of the operations being performed.
      </p><p>
        Without the verbose options, <span class="command"><strong>memcached</strong></span>
        normally produces no output during normal operating.
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <span class="bold"><strong>Output when using
            <code class="literal">-v</code></strong></span>
          </p><p>
            The lowest verbosity level shows you:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                Errors and warnings
              </p></li><li class="listitem"><p>
                Transient errors
              </p></li><li class="listitem"><p>
                Protocol and socket errors, including exhausting
                available connections
              </p></li><li class="listitem"><p>
                Each registered client connection, including the socket
                descriptor number and the protocol used.
              </p><p>
                For example:
              </p><pre class="programlisting">
32: Client using the ascii protocol
33: Client using the ascii protocol
</pre><p>
                The socket descriptor is only valid while the client
                remains connected. Non-persistent connections may not be
                effectively represented.
</p></li></ul>
</div>
<p>
            Examples of the error messages output at this level include:
          </p><pre class="programlisting">
&lt;%d send buffer was %d, now %d
Can't listen for events on fd %d
Can't read from libevent pipe
Catastrophic: event fd doesn't match conn fd!
Couldn't build response
Couldn't realloc input buffer
Couldn't update event
Failed to build UDP headers
Failed to read, and not due to blocking
Too many open connections
Unexpected state %d
</pre></li><li class="listitem"><p>
            <span class="bold"><strong>Output when using
            <code class="literal">-vv</code></strong></span>
          </p><p>
            When using the second level of verbosity, you get more
            detailed information about protocol operations, keys
            updated, chunk and network operatings and details.
          </p><p>
            During the initial start-up of <span class="command"><strong>memcached</strong></span>
            with this level of verbosity, you are shown the sizes of the
            individual slab classes, the chunk sizes, and the number of
            entries per slab. These do not show the allocation of the
            slabs, just the slabs that would be created when data is
            added. You are also given information about the listen
            queues and buffers used to send information. A sample of the
            output generated for a TCP/IP based system with the default
            memory and growth factors is given below:
          </p><pre class="programlisting">
shell&gt; memcached -vv
slab class   1: chunk size     80 perslab 13107
slab class   2: chunk size    104 perslab 10082
slab class   3: chunk size    136 perslab  7710
slab class   4: chunk size    176 perslab  5957
slab class   5: chunk size    224 perslab  4681
slab class   6: chunk size    280 perslab  3744
slab class   7: chunk size    352 perslab  2978
slab class   8: chunk size    440 perslab  2383
slab class   9: chunk size    552 perslab  1899
slab class  10: chunk size    696 perslab  1506
slab class  11: chunk size    872 perslab  1202
slab class  12: chunk size   1096 perslab   956
slab class  13: chunk size   1376 perslab   762
slab class  14: chunk size   1720 perslab   609
slab class  15: chunk size   2152 perslab   487
slab class  16: chunk size   2696 perslab   388
slab class  17: chunk size   3376 perslab   310
slab class  18: chunk size   4224 perslab   248
slab class  19: chunk size   5280 perslab   198
slab class  20: chunk size   6600 perslab   158
slab class  21: chunk size   8256 perslab   127
slab class  22: chunk size  10320 perslab   101
slab class  23: chunk size  12904 perslab    81
slab class  24: chunk size  16136 perslab    64
slab class  25: chunk size  20176 perslab    51
slab class  26: chunk size  25224 perslab    41
slab class  27: chunk size  31536 perslab    33
slab class  28: chunk size  39424 perslab    26
slab class  29: chunk size  49280 perslab    21
slab class  30: chunk size  61600 perslab    17
slab class  31: chunk size  77000 perslab    13
slab class  32: chunk size  96256 perslab    10
slab class  33: chunk size 120320 perslab     8
slab class  34: chunk size 150400 perslab     6
slab class  35: chunk size 188000 perslab     5
slab class  36: chunk size 235000 perslab     4
slab class  37: chunk size 293752 perslab     3
slab class  38: chunk size 367192 perslab     2
slab class  39: chunk size 458992 perslab     2
&lt;26 server listening (auto-negotiate)
&lt;29 server listening (auto-negotiate)
&lt;30 send buffer was 57344, now 2097152
&lt;31 send buffer was 57344, now 2097152
&lt;30 server listening (udp)
&lt;30 server listening (udp)
&lt;31 server listening (udp)
&lt;30 server listening (udp)
&lt;30 server listening (udp)
&lt;31 server listening (udp)
&lt;31 server listening (udp)
&lt;31 server listening (udp)
</pre><p>
            Using this verbosity level can be a useful way to check the
            effects of the growth factor used on slabs with different
            memory allocations, which in turn can be used to better tune
            the growth factor to suit the data you are storing in the
            cache. For example, if you set the growth factor to 4
            (quadrupling the size of each slab):
          </p><pre class="programlisting">
shell&gt; memcached -f 4 -m 1g -vv
slab class   1: chunk size     80 perslab 13107
slab class   2: chunk size    320 perslab  3276
slab class   3: chunk size   1280 perslab   819
slab class   4: chunk size   5120 perslab   204
slab class   5: chunk size  20480 perslab    51
slab class   6: chunk size  81920 perslab    12
slab class   7: chunk size 327680 perslab     3
...
</pre><p>
            During use of the cache, this verbosity level also prints
            out detailed information on the storage and recovery of keys
            and other information. An example of the output during a
            typical set/get and increment/decrement operation is shown
            below.
          </p><pre class="programlisting">
32: Client using the ascii protocol
&lt;32 set my_key 0 0 10
&gt;32 STORED
&lt;32 set object_key 1 0 36
&gt;32 STORED
&lt;32 get my_key 
&gt;32 sending key my_key
&gt;32 END
&lt;32 get object_key 
&gt;32 sending key object_key
&gt;32 END
&lt;32 set key 0 0 6
&gt;32 STORED
&lt;32 incr key 1
&gt;32 789544
&lt;32 decr key 1
&gt;32 789543
&lt;32 incr key 2
&gt;32 789545
&lt;32 set my_key 0 0 10
&gt;32 STORED
&lt;32 set object_key 1 0 36
&gt;32 STORED
&lt;32 get my_key 
&gt;32 sending key my_key
&gt;32 END
&lt;32 get object_key 
&gt;32 sending key object_key1 1 36

&gt;32 END
&lt;32 set key 0 0 6
&gt;32 STORED
&lt;32 incr key 1
&gt;32 789544
&lt;32 decr key 1
&gt;32 789543
&lt;32 incr key 2
&gt;32 789545
</pre><p>
            During client communication, for each line, the initial
            character shows the direction of flow of the information.
            The &lt; for communication from the client to the
            <span class="command"><strong>memcached</strong></span> server and &gt; for
            communication back to the client. The number is the numeric
            socket descriptor for the connection.
          </p></li><li class="listitem"><p>
            <span class="bold"><strong>Output when using
            <code class="literal">-vvv</code></strong></span>
          </p><p>
            This level of verbosity includes the transitions of
            connections between different states in the event library
            while reading and writing content to/from the clients. It
            should be used to diagnose and identify issues in client
            communication. For example, you can use this information to
            determine if <span class="command"><strong>memcached</strong></span> is taking a long
            time to return information to the client, during the read of
            the client operation or before returning and completing the
            operation. An example of the typical sequence for a set
            operation is provided below:
          </p><pre class="programlisting">
&lt;32 new auto-negotiating client connection
32: going from conn_new_cmd to conn_waiting
32: going from conn_waiting to conn_read
32: going from conn_read to conn_parse_cmd
32: Client using the ascii protocol
&lt;32 set my_key 0 0 10
32: going from conn_parse_cmd to conn_nread
&gt; NOT FOUND my_key
&gt;32 STORED
32: going from conn_nread to conn_write
32: going from conn_write to conn_new_cmd
32: going from conn_new_cmd to conn_waiting
32: going from conn_waiting to conn_read
32: going from conn_read to conn_closing
&lt;32 connection closed.
</pre></li></ul>
</div>
<p>
        All of the verbosity levels in <span class="command"><strong>memcached</strong></span> are
        designed to be used during debugging or examination of issues.
        The quantity of information generated, particularly when using
        <code class="option">-vvv</code>, is significant, particularly on a busy
        server. Also be aware that writing the error information out,
        especially to disk, may negate some of the performance gains you
        achieve by using <span class="command"><strong>memcached</strong></span>. Therefore, use in
        production or deployment environments is not recommended.
</p>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-memcached-interfaces"></a>16.6.3 Developing a <span class="command"><strong>memcached</strong></span> Application</h3>

</div>

</div>

</div>
<div class="toc">
<dl class="toc"><dt><span class="section"><a href="ha-overview.html#ha-memcached-operations">16.6.3.1 Basic <span class="command"><strong>memcached</strong></span> Operations</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-mysql-frontend">16.6.3.2 Using <span class="command"><strong>memcached</strong></span> as a MySQL Caching Layer</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached">16.6.3.3 Using <code class="literal">libmemcached</code> with C and C++</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-perl">16.6.3.4 Using MySQL and <span class="command"><strong>memcached</strong></span> with Perl</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-python">16.6.3.5 Using MySQL and <span class="command"><strong>memcached</strong></span> with Python</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-php">16.6.3.6 Using MySQL and <span class="command"><strong>memcached</strong></span> with PHP</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-ruby">16.6.3.7 Using MySQL and <span class="command"><strong>memcached</strong></span> with Ruby</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-java">16.6.3.8 Using MySQL and <span class="command"><strong>memcached</strong></span> with Java</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-protocol">16.6.3.9 Using the <span class="command"><strong>memcached</strong></span> TCP Text Protocol</a></span></dt></dl>
</div>
<p>
      A number of language interfaces let applications store and
      retrieve information with <span class="command"><strong>memcached</strong></span> servers.
      You can write <span class="command"><strong>memcached</strong></span> applications in popular
      languages such as Perl, PHP, Python, Ruby, C, and Java.
    </p><p>
      Data stored into a <span class="command"><strong>memcached</strong></span> server is referred
      to by a single string (the key), with storage into the cache and
      retrieval from the cache using the key as the reference. The cache
      therefore operates like a large associative array or hash table.
      It is not possible to structure or otherwise organize the
      information stored in the cache. To emulate database notions such
      as multiple tables or composite key values, you must encode the
      extra information into the strings used as keys. For example, to
      store or look up the address corresponding to a specific latitude
      and longitude, you might turn those two numeric values into a
      single comma-separated string to use as a key.
</p>
<div class="section">

<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-operations"></a>16.6.3.1 Basic <span class="command"><strong>memcached</strong></span> Operations</h4>
</div>
</div>
</div>
<p>
        The interface to <span class="command"><strong>memcached</strong></span> supports the
        following methods for storing and retrieving information in the
        cache, and these are consistent across all the different APIs,
        although the language specific mechanics might be different:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <code class="function">get(<em class="replaceable"><code>key</code></em>)</code>:
            Retrieves information from the cache. Returns the value
            associated with the key if the specified key exists. Returns
            <code class="literal">NULL</code>, <code class="literal">nil</code>,
            <code class="literal">undefined</code>, or the closest equivalent in
            the corresponding language, if the specified key does not
            exist.
          </p></li><li class="listitem"><p>
            <code class="function">set(<em class="replaceable"><code>key</code></em>,
            <em class="replaceable"><code>value</code></em> [,
            <em class="replaceable"><code>expiry</code></em>])</code>: Sets the
            item associated with a key in the cache to the specified
            value. This either updates an existing item if the key
            already exists, or adds a new key/value pair if the key
            doesn't exist. If the expiry time is specified, then the
            item expires (and is deleted) when the expiry time is
            reached. The time is specified in seconds, and is taken as a
            relative time if the value is less than 30 days
            (30*24*60*60), or an absolute time (epoch) if larger than
            this value.
          </p></li><li class="listitem"><p>
            <code class="function">add(<em class="replaceable"><code>key</code></em>,
            <em class="replaceable"><code>value</code></em> [,
            <em class="replaceable"><code>expiry</code></em>])</code>: Adds the key
            and associated value to the cache, if the specified key does
            not already exist.
          </p></li><li class="listitem"><p>
            <code class="function">replace(<em class="replaceable"><code>key</code></em>,
            <em class="replaceable"><code>value</code></em> [,
            <em class="replaceable"><code>expiry</code></em>])</code>: Replaces the
            item associated with the specified <code class="literal">key</code>,
            only if the key already exists. The new value is given by
            the <code class="literal">value</code> parameter.
          </p></li><li class="listitem"><p>
            <code class="function">delete(<em class="replaceable"><code>key</code></em> [,
            <em class="replaceable"><code>time</code></em>])</code>: Deletes the
            <code class="literal">key</code> and its associated item from the
            cache. If you supply a <code class="literal">time</code>, then adding
            another item with the specified <code class="literal">key</code> is
            blocked for the specified period.
          </p></li><li class="listitem"><p>
            <code class="function">incr(<em class="replaceable"><code>key</code></em> ,
            <em class="replaceable"><code>value</code></em>)</code>: Increments the
            item associated with the <code class="literal">key</code> by the
            specified <code class="literal">value</code>.
          </p></li><li class="listitem"><p>
            <code class="function">decr(<em class="replaceable"><code>key</code></em> ,
            <em class="replaceable"><code>value</code></em>)</code>: Decrements the
            item associated with the <code class="literal">key</code> by the
            specified <code class="literal">value</code>.
          </p></li><li class="listitem"><p>
            <code class="function">flush_all</code>: Invalidates (or expires) all
            the current items in the cache. Technically they still exist
            (they are not deleted), but they are silently destroyed the
            next time you try to access them.
</p></li></ul>
</div>
<p>
        In all implementations, most or all of these functions are
        duplicated through the corresponding native language interface.
      </p><p>
        When practical, use <span class="command"><strong>memcached</strong></span> to store full
        items, rather than caching a single column value from the
        database. For example, when displaying a record about an object
        (invoice, user history, or blog post), load all the data for the
        associated entry from the database, and compile it into the
        internal structure that would normally be required by the
        application. Save the complete object in the cache.
      </p><p>
        Complex data structures cannot be stored directly. Most
        interfaces serialize the data for you, that is, put it in a
        textual form that can reconstruct the original pointers and
        nesting. Perl uses <code class="literal">Storable</code>, PHP uses
        <code class="literal">serialize</code>, Python uses
        <code class="literal">cPickle</code> (or <code class="literal">Pickle</code>) and
        Java uses the <code class="literal">Serializable</code> interface. In most
        cases, the serialization interface used is customizable. To
        share data stored in <span class="command"><strong>memcached</strong></span> instances
        between different language interfaces, consider using a common
        serialization solution such as JSON (Javascript Object
        Notation).
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-mysql-frontend"></a>16.6.3.2 Using <span class="command"><strong>memcached</strong></span> as a MySQL Caching Layer</h4>

</div>

</div>

</div>
<p>
        When using <span class="command"><strong>memcached</strong></span> to cache MySQL data,
        your application must retrieve data from the database and load
        the appropriate key-value pairs into the cache. Then, subsequent
        lookups can be done directly from the cache.
      </p><p>
        Because MySQL has its own in-memory caching mechanisms for
        queried data, such as the <code class="literal">InnoDB</code>
        <a class="link" href="glossary.html#glos_buffer_pool" title="buffer pool">buffer pool</a> and the
        MySQL query cache, look for opportunities beyond loading
        individual column values or rows into the cache. Prefer to cache
        composite values, such as those retrieved from multiple tables
        through a join query, or result sets assembled from multiple
        rows.
</p>
<div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Caution
</div>
<p>
          Limit the information in the cache to non-sensitive data,
          because there is no security required to access or update the
          information within a <span class="command"><strong>memcached</strong></span> instance.
          Anybody with access to the machine has the ability to read,
          view and potentially update the information. To keep the data
          secure, encrypt the information before caching it. To restrict
          the users capable of connecting to the server, either disable
          network access, or use IPTables or similar techniques to
          restrict access to the <span class="command"><strong>memcached</strong></span> ports to a
          select set of hosts.
</p>
</div>
<p>
        You can introduce <code class="literal">memcached</code> to an existing
        application, even if caching was not part of the original
        design. In many languages and environments the changes to the
        application will be just a few lines, first to attempt to read
        from the cache when loading data, fall back to the old method if
        the information is not cached, and to update the cache with
        information once the data has been read.
      </p><p>
        The general sequence for using <span class="command"><strong>memcached</strong></span> in
        any language as a caching solution for MySQL is as follows:
</p>
<div class="orderedlist">
<ol class="orderedlist" type="1"><li class="listitem"><p>
            Request the item from the cache.
          </p></li><li class="listitem"><p>
            If the item exists, use the item data.
          </p></li><li class="listitem"><p>
            If the item does not exist, load the data from MySQL, and
            store the value into the cache. This means the value is
            available to the next client that requests it from the
            cache.
</p></li></ol>
</div>
<p>
        For a flow diagram of this sequence, see
        <a class="xref" href="ha-overview.html#ha-memcached-fig-basicflow" title="Figure 16.8 Typical memcached Application Flowchart">Figure 16.8, “Typical <span class="command">memcached</span> Application Flowchart”</a>.
</p>
<div class="figure">
<a name="ha-memcached-fig-basicflow"></a><p class="title"><b>Figure 16.8 Typical <span class="command">memcached</span> Application Flowchart</b></p>
<div class="figure-contents">

<div class="mediaobject">
<img src="images/memcached-flow.png" width="288" height="437" alt="Typical memcached Application Flowchart">
</div>

</div>

</div>
<br class="figure-break">
<h5><a name="idm139737122031776"></a>Adapting Database Best Practices to <span class="command"><strong>memcached</strong></span>
Applications</h5>
<p>
        The most direct way to cache MySQL data is to use a 2-column
        table, where the first column is a
        <a class="link" href="glossary.html#glos_primary_key" title="primary key">primary key</a>. Because of
        the uniqueness requirements for <span class="command"><strong>memcached</strong></span>
        keys, make sure your database schema makes appropriate use of
        primary keys and <a class="link" href="glossary.html#glos_unique_constraint" title="unique constraint">unique
        constraints</a>.
      </p><p>
        If you combine multiple column values into a single
        <span class="command"><strong>memcached</strong></span> item value, choose data types to
        make it easy to parse the value back into its components, for
        example by using a separator character between numeric values.
      </p><p>
        The queries that map most easily to <span class="command"><strong>memcached</strong></span>
        lookups are those with a single <code class="literal">WHERE</code> clause,
        using an <code class="literal">=</code> or <code class="literal">IN</code> operator.
        For complicated <code class="literal">WHERE</code> clauses, or those using
        operators such as <code class="literal">&lt;</code>,
        <code class="literal">&gt;</code>, <code class="literal">BETWEEN</code>, or
        <code class="literal">LIKE</code>, <span class="command"><strong>memcached</strong></span> does not
        provide a simple or efficient way to scan through or filter the
        keys or associated values, so typically you perform those
        operations as SQL queries on the underlying database.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-interfaces-libmemcached"></a>16.6.3.3 Using <code class="literal">libmemcached</code> with C and C++</h4>

</div>

</div>

</div>
<p>
        The <code class="literal">libmemcached</code> library provides both C and
        C++ interfaces to <span class="command"><strong>memcached</strong></span> and is also the
        basis for a number of different additional API implementations,
        including Perl, Python and Ruby. Understanding the core
        <code class="literal">libmemcached</code> functions can help when using
        these other interfaces.
      </p><p>
        The C library is the most comprehensive interface library for
        <span class="command"><strong>memcached</strong></span> and provides functions and
        operational systems not always exposed in interfaces not based
        on the <code class="literal">libmemcached</code> library.
      </p><p>
        The different functions can be divided up according to their
        basic operation. In addition to functions that interface to the
        core API, a number of utility functions provide extended
        functionality, such as appending and prepending data.
      </p><p>
        To build and install <code class="literal">libmemcached</code>, download
        the <code class="literal">libmemcached</code> package, run
        <span class="command"><strong>configure</strong></span>, and then build and install:
      </p><pre class="programlisting">
shell&gt; tar xjf libmemcached-0.21.tar.gz
shell&gt; cd libmemcached-0.21
shell&gt; ./configure
shell&gt; make
shell&gt; make install
</pre><p>
        On many Linux operating systems, you can install the
        corresponding <code class="literal">libmemcached</code> package through
        the usual <span class="command"><strong>yum</strong></span>, <span class="command"><strong>apt-get</strong></span>, or
        similar commands.
      </p><p>
        To build an application that uses the library, first set the
        list of servers. Either directly manipulate the servers
        configured within the main <code class="literal">memcached_st</code>
        structure, or separately populate a list of servers, and then
        add this list to the <code class="literal">memcached_st</code> structure.
        The latter method is used in the following example. Once the
        server list has been set, you can call the functions to store or
        retrieve data. A simple application for setting a preset value
        to <code class="literal">localhost</code> is provided here:
      </p><pre class="programlisting">
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;
#include &lt;libmemcached/memcached.h&gt;

int main(int argc, char *argv[])
{
  memcached_server_st *servers = NULL;
  memcached_st *memc;
  memcached_return rc;
  char *key= "keystring";
  char *value= "keyvalue";

  memcached_server_st *memcached_servers_parse (char *server_strings);
  memc= memcached_create(NULL);

  servers= memcached_server_list_append(servers, "localhost", 11211, &amp;rc);
  rc= memcached_server_push(memc, servers);

  if (rc == MEMCACHED_SUCCESS)
    fprintf(stderr,"Added server successfully\n");
  else
    fprintf(stderr,"Couldn't add server: %s\n",memcached_strerror(memc, rc));

  rc= memcached_set(memc, key, strlen(key), value, strlen(value), (time_t)0, (uint32_t)0);

  if (rc == MEMCACHED_SUCCESS)
    fprintf(stderr,"Key stored successfully\n");
  else
    fprintf(stderr,"Couldn't store key: %s\n",memcached_strerror(memc, rc));

  return 0;
}
</pre><p>
        To test the success of an operation, use the return value, or
        populated result code, for a given function. The value is always
        set to <code class="literal">MEMCACHED_SUCCESS</code> if the operation
        succeeded. In the event of a failure, use the
        <code class="literal">memcached_strerror()</code> function to translate
        the result code into a printable string.
      </p><p>
        To build the application, specify the
        <code class="literal">memcached</code> library:
      </p><pre class="programlisting">
shell&gt; gcc -o memc_basic memc_basic.c -lmemcached
</pre><p>
        Running the above sample application, after starting a
        <span class="command"><strong>memcached</strong></span> server, should return a success
        message:
      </p><pre class="programlisting">
shell&gt; memc_basic
Added server successfully
Key stored successfully
</pre>
<div class="section">

<div class="titlepage">
<div>
<div>
<h5 class="title"><a name="ha-memcached-interfaces-libmemcached-base"></a>16.6.3.3.1 <code class="literal">libmemcached</code> Base Functions</h5>
</div>
</div>
</div>
<p>
          The base <code class="literal">libmemcached</code> functions let you
          create, destroy and clone the main
          <code class="literal">memcached_st</code> structure that is used to
          interface with the <code class="literal">memcached</code> servers. The
          main functions are defined below:
        </p><pre class="programlisting">
memcached_st *memcached_create (memcached_st *ptr);
</pre><p>
          Creates a new <code class="literal">memcached_st</code> structure for
          use with the other <code class="literal">libmemcached</code> API
          functions. You can supply an existing, static,
          <code class="literal">memcached_st</code> structure, or
          <code class="literal">NULL</code> to have a new structured allocated.
          Returns a pointer to the created structure, or
          <code class="literal">NULL</code> on failure.
        </p><pre class="programlisting">
void memcached_free (memcached_st *ptr);
</pre><p>
          Frees the structure and memory allocated to a previously
          created <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">
memcached_st *memcached_clone(memcached_st *clone, memcached_st *source);
</pre><p>
          Clones an existing <code class="literal">memcached</code> structure from
          the specified <code class="literal">source</code>, copying the defaults
          and list of servers defined in the structure.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h5 class="title"><a name="ha-memcached-interfaces-libmemcached-servers"></a>16.6.3.3.2 <code class="literal">libmemcached</code> Server Functions</h5>

</div>

</div>

</div>
<p>
          The <code class="literal">libmemcached</code> API uses a list of
          servers, stored within the
          <code class="literal">memcached_server_st</code> structure, to act as
          the list of servers used by the rest of the functions. To use
          <code class="literal">memcached</code>, you first create the server
          list, and then apply the list of servers to a valid
          <code class="literal">libmemcached</code> object.
        </p><p>
          Because the list of servers, and the list of servers within an
          active <code class="literal">libmemcached</code> object can be
          manipulated separately, you can update and manage server lists
          while an active <code class="literal">libmemcached</code> interface is
          running.
        </p><p>
          The functions for manipulating the list of servers within a
          <code class="literal">memcached_st</code> structure are:
        </p><pre class="programlisting">
memcached_return
   memcached_server_add (memcached_st *ptr,
                         char *hostname,
                         unsigned int port);
</pre><p>
          Adds a server, using the given <code class="literal">hostname</code> and
          <code class="literal">port</code> into the
          <code class="literal">memcached_st</code> structure given in
          <code class="literal">ptr</code>.
        </p><pre class="programlisting">
memcached_return
   memcached_server_add_unix_socket (memcached_st *ptr,
                                     char *socket);
</pre><p>
          Adds a Unix socket to the list of servers configured in the
          <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">
unsigned int memcached_server_count (memcached_st *ptr);
</pre><p>
          Returns a count of the number of configured servers within the
          <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">
memcached_server_st *
   memcached_server_list (memcached_st *ptr);
</pre><p>
          Returns an array of all the defined hosts within a
          <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">
memcached_return
   memcached_server_push (memcached_st *ptr,
                          memcached_server_st *list);
</pre><p>
          Pushes an existing list of servers onto list of servers
          configured for a current <code class="literal">memcached_st</code>
          structure. This adds servers to the end of the existing list,
          and duplicates are not checked.
        </p><p>
          The <code class="literal">memcached_server_st</code> structure can be
          used to create a list of <code class="literal">memcached</code> servers
          which can then be applied individually to
          <code class="literal">memcached_st</code> structures.
        </p><pre class="programlisting">
memcached_server_st *
   memcached_server_list_append (memcached_server_st *ptr,
                                 char *hostname,
                                 unsigned int port,
                                 memcached_return *error);
</pre><p>
          Adds a server, with <code class="literal">hostname</code> and
          <code class="literal">port</code>, to the server list in
          <code class="literal">ptr</code>. The result code is handled by the
          <code class="literal">error</code> argument, which should point to an
          existing <code class="literal">memcached_return</code> variable. The
          function returns a pointer to the returned list.
        </p><pre class="programlisting">
unsigned int memcached_server_list_count (memcached_server_st *ptr);
</pre><p>
          Returns the number of the servers in the server list.
        </p><pre class="programlisting">
void memcached_server_list_free (memcached_server_st *ptr);
</pre><p>
          Frees the memory associated with a server list.
        </p><pre class="programlisting">
memcached_server_st *memcached_servers_parse (char *server_strings);
</pre><p>
          Parses a string containing a list of servers, where individual
          servers are separated by a comma, space, or both, and where
          individual servers are of the form
          <code class="literal"><em class="replaceable"><code>server</code></em>[:<em class="replaceable"><code>port</code></em>]</code>.
          The return value is a server list structure.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h5 class="title"><a name="ha-memcached-interfaces-libmemcached-set"></a>16.6.3.3.3 <code class="literal">libmemcached</code> Set Functions</h5>

</div>

</div>

</div>
<p>
          The set-related functions within
          <code class="literal">libmemcached</code> provide the same functionality
          as the core functions supported by the
          <code class="literal">memcached</code> protocol. The full definition for
          the different functions is the same for all the base functions
          (<code class="literal">add</code>, <code class="literal">replace</code>,
          <code class="literal">prepend</code>, <code class="literal">append</code>). For
          example, the function definition for
          <code class="literal">memcached_set()</code> is:
        </p><pre class="programlisting">
memcached_return
   memcached_set (memcached_st *ptr,
                  const char *key,
                  size_t key_length,
                  const char *value,
                  size_t value_length,
                  time_t expiration,
                  uint32_t flags);
</pre><p>
          The <code class="literal">ptr</code> is the
          <code class="literal">memcached_st</code> structure. The
          <code class="literal">key</code> and <code class="literal">key_length</code>
          define the key name and length, and <code class="literal">value</code>
          and <code class="literal">value_length</code> the corresponding value
          and length. You can also set the expiration and optional
          flags. For more information, see
          <a class="xref" href="ha-overview.html#ha-memcached-interfaces-libmemcached-behaviors" title="16.6.3.3.5 Controlling libmemcached Behaviors">Section 16.6.3.3.5, “Controlling <code class="literal">libmemcached</code> Behaviors”</a>.
        </p><p>
          This table outlines the remainder of the set-related
          <code class="literal">libmemcached</code> functions and the equivalent
          core functions supported by the <span class="command"><strong>memcached</strong></span>
          protocol.
</p>
<div class="informaltable">
<table summary="This table outlines the remainder of the set-related
            libmemcached functions and the equivalent
            core functions supported by the memcached
            protocol." border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col"><code class="literal">libmemcached</code> Function</th><th scope="col">Equivalent Core Function</th></tr></thead><tbody><tr><td scope="row"><code class="literal">memcached_set(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Generic <code class="literal">set()</code> operation.</td></tr><tr><td scope="row"><code class="literal">memcached_add(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Generic <code class="literal">add()</code> function.</td></tr><tr><td scope="row"><code class="literal">memcached_replace(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Generic <code class="literal">replace()</code>.</td></tr><tr><td scope="row"><code class="literal">memcached_prepend(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Prepends the specified <code class="literal">value</code> before the current value
                  of the specified <code class="literal">key</code>.</td></tr><tr><td scope="row"><code class="literal">memcached_append(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Appends the specified <code class="literal">value</code> after the current value
                  of the specified <code class="literal">key</code>.</td></tr><tr><td scope="row"><code class="literal">memcached_cas(memc, key, key_length, value, value_length,
                  expiration, flags, cas)</code></td><td>Overwrites the data for a given key as long as the corresponding
                  <code class="literal">cas</code> value is still the same within
                  the server.</td></tr><tr><td scope="row"><code class="literal">memcached_set_by_key(memc, master_key, master_key_length, key,
                  key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the generic <code class="literal">set()</code>, but has the option of
                  an additional master key that can be used to identify
                  an individual server.</td></tr><tr><td scope="row"><code class="literal">memcached_add_by_key(memc, master_key, master_key_length, key,
                  key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the generic <code class="literal">add()</code>, but has the option of
                  an additional master key that can be used to identify
                  an individual server.</td></tr><tr><td scope="row"><code class="literal">memcached_replace_by_key(memc, master_key, master_key_length,
                  key, key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the generic <code class="literal">replace()</code>, but has the option
                  of an additional master key that can be used to
                  identify an individual server.</td></tr><tr><td scope="row"><code class="literal">memcached_prepend_by_key(memc, master_key, master_key_length,
                  key, key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the <code class="literal">memcached_prepend()</code>, but has the
                  option of an additional master key that can be used to
                  identify an individual server.</td></tr><tr><td scope="row"><code class="literal">memcached_append_by_key(memc, master_key, master_key_length,
                  key, key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the <code class="literal">memcached_append()</code>, but has the option
                  of an additional master key that can be used to
                  identify an individual server.</td></tr><tr><td scope="row"><code class="literal">memcached_cas_by_key(memc, master_key, master_key_length, key,
                  key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the <code class="literal">memcached_cas()</code>, but has the option of
                  an additional master key that can be used to identify
an individual server.</td></tr></tbody></table>
</div>
<p>
          The <code class="literal">by_key</code> methods add two further
          arguments that define the master key, to be used and applied
          during the hashing stage for selecting the servers. You can
          see this in the following definition:
        </p><pre class="programlisting">
memcached_return
   memcached_set_by_key(memcached_st *ptr,
                        const char *master_key,
                        size_t master_key_length,
                        const char *key,
                        size_t key_length,
                        const char *value,
                        size_t value_length,
                        time_t expiration,
                        uint32_t flags);
</pre><p>
          All the functions return a value of type
          <code class="literal">memcached_return</code>, which you can compare
          against the <code class="literal">MEMCACHED_SUCCESS</code> constant.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h5 class="title"><a name="ha-memcached-interfaces-libmemcached-get"></a>16.6.3.3.4 <code class="literal">libmemcached</code> Get Functions</h5>

</div>

</div>

</div>
<p>
          The <code class="literal">libmemcached</code> functions provide both
          direct access to a single item, and a multiple-key request
          mechanism that provides much faster responses when fetching a
          large number of keys simultaneously.
        </p><p>
          The main get-style function, which is equivalent to the
          generic <code class="literal">get()</code> is
          <code class="literal">memcached_get()</code>. This function returns a
          string pointer, pointing to the value associated with the
          specified key.
        </p><pre class="programlisting">
char *memcached_get (memcached_st *ptr,
                     const char *key, size_t key_length,
                     size_t *value_length,
                     uint32_t *flags,
                     memcached_return *error);
</pre><p>
          A multi-key get, <code class="literal">memcached_mget()</code>, is also
          available. Using a multiple key get operation is much quicker
          to do in one block than retrieving the key values with
          individual calls to <code class="literal">memcached_get()</code>. To
          start the multi-key get, call
          <code class="literal">memcached_mget()</code>:
        </p><pre class="programlisting">
memcached_return
    memcached_mget (memcached_st *ptr,
                    char **keys, size_t *key_length,
                    unsigned int number_of_keys);
</pre><p>
          The return value is the success of the operation. The
          <code class="literal">keys</code> parameter should be an array of
          strings containing the keys, and <code class="literal">key_length</code>
          an array containing the length of each corresponding key.
          <code class="literal">number_of_keys</code> is the number of keys
          supplied in the array.
        </p><p>
          To fetch the individual values, use
          <code class="literal">memcached_fetch()</code> to get each corresponding
          value.
        </p><pre class="programlisting">
char *memcached_fetch (memcached_st *ptr,
                       const char *key, size_t *key_length,
                       size_t *value_length,
                       uint32_t *flags,
                       memcached_return *error);
</pre><p>
          The function returns the key value, with the
          <code class="literal">key</code>, <code class="literal">key_length</code> and
          <code class="literal">value_length</code> parameters being populated
          with the corresponding key and length information. The
          function returns <code class="literal">NULL</code> when there are no
          more values to be returned. A full example, including the
          populating of the key data and the return of the information
          is provided here.
        </p><pre class="programlisting">
#include &lt;stdio.h&gt;
#include &lt;sstring.h&gt;
#include &lt;unistd.h&gt;
#include &lt;libmemcached/memcached.h&gt;

int main(int argc, char *argv[])
{
  memcached_server_st *servers = NULL;
  memcached_st *memc;
  memcached_return rc;
  char *keys[]= {"huey", "dewey", "louie"};
  size_t key_length[3];
  char *values[]= {"red", "blue", "green"};
  size_t value_length[3];
  unsigned int x;
  uint32_t flags;

  char return_key[MEMCACHED_MAX_KEY];
  size_t return_key_length;
  char *return_value;
  size_t return_value_length;

  memc= memcached_create(NULL);

  servers= memcached_server_list_append(servers, "localhost", 11211, &amp;rc);
  rc= memcached_server_push(memc, servers);

  if (rc == MEMCACHED_SUCCESS)
    fprintf(stderr,"Added server successfully\n");
  else
    fprintf(stderr,"Couldn't add server: %s\n",memcached_strerror(memc, rc));

  for(x= 0; x &lt; 3; x++)
    {
      key_length[x] = strlen(keys[x]);
      value_length[x] = strlen(values[x]);

      rc= memcached_set(memc, keys[x], key_length[x], values[x],
                        value_length[x], (time_t)0, (uint32_t)0);
      if (rc == MEMCACHED_SUCCESS)
        fprintf(stderr,"Key %s stored successfully\n",keys[x]);
      else
        fprintf(stderr,"Couldn't store key: %s\n",memcached_strerror(memc, rc));
    }

  rc= memcached_mget(memc, keys, key_length, 3);

  if (rc == MEMCACHED_SUCCESS)
    {
      while ((return_value= memcached_fetch(memc, return_key, &amp;return_key_length,
                                            &amp;return_value_length, &amp;flags, &amp;rc)) != NULL)
        {
          if (rc == MEMCACHED_SUCCESS)
            {
              fprintf(stderr,"Key %s returned %s\n",return_key, return_value);
            }
        }
    }

  return 0;
}
</pre><p>
          Running the above application produces the following output:
        </p><pre class="programlisting">
shell&gt; memc_multi_fetch
Added server successfully
Key huey stored successfully
Key dewey stored successfully
Key louie stored successfully
Key huey returned red
Key dewey returned blue
Key louie returned green
</pre>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h5 class="title"><a name="ha-memcached-interfaces-libmemcached-behaviors"></a>16.6.3.3.5 Controlling <code class="literal">libmemcached</code> Behaviors</h5>

</div>

</div>

</div>
<p>
          The behavior of <code class="literal">libmemcached</code> can be
          modified by setting one or more behavior flags. These can
          either be set globally, or they can be applied during the call
          to individual functions. Some behaviors also accept an
          additional setting, such as the hashing mechanism used when
          selecting servers.
        </p><p>
          To set global behaviors:
        </p><pre class="programlisting">
memcached_return
   memcached_behavior_set (memcached_st *ptr,
                           memcached_behavior flag,
                           uint64_t data);
</pre><p>
          To get the current behavior setting:
        </p><pre class="programlisting">
uint64_t
   memcached_behavior_get (memcached_st *ptr,
                           memcached_behavior flag);
</pre><p>
          The following table describes <code class="literal">libmemcached</code>
          behavior flags.
</p>
<div class="informaltable">
<table summary="This table lists libmemcached
            behavior flags and provides a description of each. " border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col">Behavior</th><th scope="col">Description</th></tr></thead><tbody><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_NO_BLOCK</code></td><td>Caused <code class="literal">libmemcached</code> to use asynchronous I/O.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_TCP_NODELAY</code></td><td>Turns on no-delay for network sockets.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_HASH</code></td><td>Without a value, sets the default hashing algorithm for keys to use MD5.
                  Other valid values include
                  <code class="literal">MEMCACHED_HASH_DEFAULT</code>,
                  <code class="literal">MEMCACHED_HASH_MD5</code>,
                  <code class="literal">MEMCACHED_HASH_CRC</code>,
                  <code class="literal">MEMCACHED_HASH_FNV1_64</code>,
                  <code class="literal">MEMCACHED_HASH_FNV1A_64</code>,
                  <code class="literal">MEMCACHED_HASH_FNV1_32</code>, and
                  <code class="literal">MEMCACHED_HASH_FNV1A_32</code>.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_DISTRIBUTION</code></td><td>Changes the method of selecting the server used to store a given value.
                  The default method is
                  <code class="literal">MEMCACHED_DISTRIBUTION_MODULA</code>. You
                  can enable consistent hashing by setting
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT</code>.
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT</code>
                  is an alias for the value
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT_KETAMA</code>.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_CACHE_LOOKUPS</code></td><td>Cache the lookups made to the DNS service. This can improve the
                  performance if you are using names instead of IP
                  addresses for individual hosts.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_SUPPORT_CAS</code></td><td>Support CAS operations. By default, this is disabled because it imposes
                  a performance penalty.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_KETAMA</code></td><td>Sets the default distribution to
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT_KETAMA</code>
                  and the hash to <code class="literal">MEMCACHED_HASH_MD5</code>.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_POLL_TIMEOUT</code></td><td>Modify the timeout value used by <code class="literal">poll()</code>. Supply a
                  <code class="literal">signed int</code> pointer for the timeout
                  value.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_BUFFER_REQUESTS</code></td><td>Buffers IO requests instead of them being sent. A get operation, or
                  closing the connection causes the data to be flushed.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_VERIFY_KEY</code></td><td>Forces <code class="literal">libmemcached</code> to verify that a specified key is
                  valid.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_SORT_HOSTS</code></td><td>If set, hosts added to the list of configured hosts for a
                  <code class="literal">memcached_st</code> structure are placed
                  into the host list in sorted order. This breaks
                  consistent hashing if that behavior has been enabled.</td></tr><tr><td scope="row"><code class="literal">MEMCACHED_BEHAVIOR_CONNECT_TIMEOUT</code></td><td>In nonblocking mode this changes the value of the timeout during socket
connection.</td></tr></tbody></table>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h5 class="title"><a name="ha-memcached-interfaces-libmemcached-utilities"></a>16.6.3.3.6 <span class="command"><strong>libmemcached</strong></span> Command-Line Utilities</h5>

</div>

</div>

</div>
<p>
          In addition to the main C library interface,
          <code class="literal">libmemcached</code> also includes a number of
          command-line utilities that can be useful when working with
          and debugging <span class="command"><strong>memcached</strong></span> applications.
        </p><p>
          All of the command-line tools accept a number of arguments,
          the most critical of which is <code class="literal">servers</code>,
          which specifies the list of servers to connect to when
          returning information.
        </p><p>
          The main tools are:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
              <span class="command"><strong>memcat</strong></span>: Display the value for each ID
              given on the command line:
            </p><pre class="programlisting">
shell&gt; memcat --servers=localhost hwkey
Hello world
</pre></li><li class="listitem"><p>
              <span class="command"><strong>memcp</strong></span>: Copy the contents of a file into
              the cache, using the file name as the key:
            </p><pre class="programlisting">
shell&gt; echo "Hello World" &gt; hwkey
shell&gt; memcp --servers=localhost hwkey
shell&gt; memcat --servers=localhost hwkey
Hello world
</pre></li><li class="listitem"><p>
              <span class="command"><strong>memrm</strong></span>: Remove an item from the cache:
            </p><pre class="programlisting">
shell&gt; memcat --servers=localhost hwkey
Hello world
shell&gt; memrm --servers=localhost hwkey
shell&gt; memcat --servers=localhost hwkey
</pre></li><li class="listitem"><p>
              <span class="command"><strong>memslap</strong></span>: Test the load on one or more
              <span class="command"><strong>memcached</strong></span> servers, simulating get/set
              and multiple client operations. For example, you can
              simulate the load of 100 clients performing get
              operations:
            </p><pre class="programlisting">
shell&gt; memslap --servers=localhost --concurrency=100 --flush --test=get
memslap --servers=localhost --concurrency=100 --flush --test=get	Threads connecting to servers 100
	Took 13.571 seconds to read data
</pre></li><li class="listitem"><p>
              <span class="command"><strong>memflush</strong></span>: Flush (empty) the contents of
              the <span class="command"><strong>memcached</strong></span> cache.
            </p><pre class="programlisting">
shell&gt; memflush --servers=localhost
</pre></li></ul>
</div>

</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-interfaces-perl"></a>16.6.3.4 Using MySQL and <span class="command"><strong>memcached</strong></span> with Perl</h4>

</div>

</div>

</div>
<p>
        The <code class="literal">Cache::Memcached</code> module provides a native
        interface to the Memcache protocol, and provides support for the
        core functions offered by <span class="command"><strong>memcached</strong></span>. Install
        the module using your operating system's package management
        system, or using <code class="literal">CPAN</code>:
      </p><pre class="programlisting">
root-shell&gt; perl -MCPAN -e 'install Cache::Memcached'
</pre><p>
        To use <span class="command"><strong>memcached</strong></span> from Perl through the
        <code class="literal">Cache::Memcached</code> module, first create a new
        <code class="literal">Cache::Memcached</code> object that defines the list
        of servers and other parameters for the connection. The only
        argument is a hash containing the options for the cache
        interface. For example, to create a new instance that uses three
        <span class="command"><strong>memcached</strong></span> servers:
      </p><pre class="programlisting">
use Cache::Memcached;

my $cache = new Cache::Memcached {
    'servers' =&gt; [
        '192.168.0.100:11211',
        '192.168.0.101:11211',
        '192.168.0.102:11211',
	],
};
</pre>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Note
</div>
<p>
          When using the <code class="literal">Cache::Memcached</code> interface
          with multiple servers, the API automatically performs certain
          operations across all the servers in the group. For example,
          getting statistical information through
          <code class="literal">Cache::Memcached</code> returns a hash that
          contains data on a host-by-host basis, as well as generalized
          statistics for all the servers in the group.
</p>
</div>
<p>
        You can set additional properties on the cache object instance
        when it is created by specifying the option as part of the
        option hash. Alternatively, you can use a corresponding method
        on the instance:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <code class="literal">servers</code> or method
            <code class="literal">set_servers()</code>: Specifies the list of the
            servers to be used. The servers list should be a reference
            to an array of servers, with each element as the address and
            port number combination (separated by a colon). You can also
            specify a local connection through a Unix socket (for
            example <code class="filename">/tmp/sock/memcached</code>). To
            specify the server with a weight (indicating how much more
            frequently the server should be used during hashing),
            specify an array reference with the
            <span class="command"><strong>memcached</strong></span> server instance and a weight
            number. Higher numbers give higher priority.
          </p></li><li class="listitem"><p>
            <code class="literal">compress_threshold</code> or method
            <code class="literal">set_compress_threshold()</code>: Specifies the
            threshold when values are compressed. Values larger than the
            specified number are automatically compressed (using
            <code class="literal">zlib</code>) during storage and retrieval.
          </p></li><li class="listitem"><p>
            <code class="literal">no_rehash</code> or method
            <code class="literal">set_norehash()</code>: Disables finding a new
            server if the original choice is unavailable.
          </p></li><li class="listitem"><p>
            <code class="literal">readonly</code> or method
            <code class="literal">set_readonly()</code>: Disables writes to the
            <span class="command"><strong>memcached</strong></span> servers.
</p></li></ul>
</div>
<p>
        Once the <code class="literal">Cache::Memcached</code> object instance has
        been configured, you can use the <code class="literal">set()</code> and
        <code class="literal">get()</code> methods to store and retrieve
        information from the <span class="command"><strong>memcached</strong></span> servers.
        Objects stored in the cache are automatically serialized and
        deserialized using the <code class="literal">Storable</code> module.
      </p><p>
        The <code class="literal">Cache::Memcached</code> interface supports the
        following methods for storing/retrieving data, and relate to the
        generic methods as shown in the table.
</p>
<div class="informaltable">
<table summary="This table lists memcached
          functions used with Perl and the equivalent generic methods in
          the memcached interface specification.
          " border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col"><code class="literal">Cache::Memcached</code> Function</th><th scope="col">Equivalent Generic Method</th></tr></thead><tbody><tr><td scope="row"><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code>.</td></tr><tr><td scope="row"><code class="literal">get_multi(keys)</code></td><td>Gets multiple <code class="literal">keys</code> from memcache using just one
query. Returns a hash reference of key/value pairs.</td></tr><tr><td scope="row"><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code>.</td></tr><tr><td scope="row"><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code>.</td></tr><tr><td scope="row"><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code>.</td></tr><tr><td scope="row"><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code>.</td></tr><tr><td scope="row"><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code>.</td></tr><tr><td scope="row"><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code>.</td></tr></tbody></table>
</div>
<p>
        Below is a complete example for using
        <span class="command"><strong>memcached</strong></span> with Perl and the
        <code class="literal">Cache::Memcached</code> module:
      </p><pre class="programlisting">
#!/usr/bin/perl

use Cache::Memcached;
use DBI;
use Data::Dumper;

# Configure the memcached server

my $cache = new Cache::Memcached {
    'servers' =&gt; [
                   'localhost:11211',
                   ],
    };

# Get the film name from the command line
# memcached keys must not contain spaces, so create
# a key name by replacing spaces with underscores

my $filmname = shift or die "Must specify the film name\n";
my $filmkey = $filmname;
$filmkey =~ s/ /_/;

# Load the data from the cache

my $filmdata = $cache-&gt;get($filmkey);

# If the data wasn't in the cache, then we load it from the database

if (!defined($filmdata))
{
    $filmdata = load_filmdata($filmname);

    if (defined($filmdata))
    {

# Set the data into the cache, using the key

	if ($cache-&gt;set($filmkey,$filmdata))
        {
            print STDERR "Film data loaded from database and cached\n";
        }
        else
        {
            print STDERR "Couldn't store to cache\n";
	}
    }
    else
    {
     	die "Couldn't find $filmname\n";
    }
}
else
{
    print STDERR "Film data loaded from Memcached\n";
}

sub load_filmdata
{
    my ($filmname) = @_;

    my $dsn = "DBI:mysql:database=sakila;host=localhost;port=3306";

    $dbh = DBI-&gt;connect($dsn, 'sakila','password');

    my ($filmbase) = $dbh-&gt;selectrow_hashref(sprintf('select * from film where title = %s',
                                                     $dbh-&gt;quote($filmname)));

    if (!defined($filmname))
    {
     	return (undef);
    }

    $filmbase-&gt;{stars} =
	$dbh-&gt;selectall_arrayref(sprintf('select concat(first_name," ",last_name) ' .
                                         'from film_actor left join (actor) ' .
                                         'on (film_actor.actor_id = actor.actor_id) ' .
                                         ' where film_id=%s',
                                         $dbh-&gt;quote($filmbase-&gt;{film_id})));

    return($filmbase);
}
</pre><p>
        The example uses the Sakila database, obtaining film data from
        the database and writing a composite record of the film and
        actors to <span class="command"><strong>memcached</strong></span>. When calling it for a
        film does not exist, you get this result:
      </p><pre class="programlisting">
shell&gt; memcached-sakila.pl "ROCK INSTINCT"
Film data loaded from database and cached
</pre><p>
        When accessing a film that has already been added to the cache:
      </p><pre class="programlisting">
shell&gt; memcached-sakila.pl "ROCK INSTINCT"
Film data loaded from Memcached
</pre>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-interfaces-python"></a>16.6.3.5 Using MySQL and <span class="command"><strong>memcached</strong></span> with Python</h4>

</div>

</div>

</div>
<p>
        The Python <span class="command"><strong>memcache</strong></span> module interfaces to
        <span class="command"><strong>memcached</strong></span> servers, and is written in pure
        Python (that is, without using one of the C APIs). You can
        download and install a copy from
        <a class="ulink" href="http://www.tummy.com/Community/software/python-memcached/" target="_top">Python
        Memcached</a>.
      </p><p>
        To install, download the package and then run the Python
        installer:
      </p><pre class="programlisting">
python setup.py install
running install
running bdist_egg
running egg_info
creating python_memcached.egg-info
...
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing python_memcached-1.43-py2.4.egg
creating /usr/lib64/python2.4/site-packages/python_memcached-1.43-py2.4.egg
Extracting python_memcached-1.43-py2.4.egg to /usr/lib64/python2.4/site-packages
Adding python-memcached 1.43 to easy-install.pth file

Installed /usr/lib64/python2.4/site-packages/python_memcached-1.43-py2.4.egg
Processing dependencies for python-memcached==1.43
Finished processing dependencies for python-memcached==1.43
</pre><p>
        Once installed, the <code class="literal">memcache</code> module provides
        a class-based interface to your <span class="command"><strong>memcached</strong></span>
        servers. When you store Python data structures as
        <span class="command"><strong>memcached</strong></span> items, they are automatically
        serialized (turned into string values) using the Python
        <code class="literal">cPickle</code> or <code class="literal">pickle</code> modules.
      </p><p>
        To create a new <code class="literal">memcache</code> interface, import
        the <code class="literal">memcache</code> module and create a new instance
        of the <code class="literal">memcache.Client</code> class. For example, if
        the <span class="command"><strong>memcached</strong></span> daemon is running on localhost
        using the default port:
      </p><pre class="programlisting">
import memcache
memc = memcache.Client(['127.0.0.1:11211'])
</pre><p>
        The first argument is an array of strings containing the server
        and port number for each <span class="command"><strong>memcached</strong></span> instance
        to use. To enable debugging, set the optional
        <code class="literal">debug</code> parameter to 1.
      </p><p>
        By default, the hashing mechanism used to divide the items among
        multiple servers is <code class="literal">crc32</code>. To change the
        function used, set the value of
        <code class="literal">memcache.serverHashFunction</code> to the alternate
        function to use. For example:
      </p><pre class="programlisting">
from zlib import adler32
memcache.serverHashFunction = adler32
</pre><p>
        Once you have defined the servers to use within the
        <code class="literal">memcache</code> instance, the core functions provide
        the same functionality as in the generic interface
        specification. The following table provides a summary of the
        supported functions:
</p>
<div class="informaltable">
<table summary="This table lists Python memcached
          functions and the equivalent generic functions in the
          memcached interface specification." border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col">Python <code class="literal">memcache</code> Function</th><th scope="col">Equivalent Generic Function</th></tr></thead><tbody><tr><td scope="row"><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code>.</td></tr><tr><td scope="row"><code class="literal">get_multi(keys)</code></td><td>Gets multiple values from the supplied array of <code class="literal">keys</code>.
                Returns a hash reference of key/value pairs.</td></tr><tr><td scope="row"><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code>.</td></tr><tr><td scope="row"><code class="literal">set_multi(dict [, expiry [, key_prefix]])</code></td><td>Sets multiple key/value pairs from the supplied <code class="literal">dict</code>.</td></tr><tr><td scope="row"><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code>.</td></tr><tr><td scope="row"><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code>.</td></tr><tr><td scope="row"><code class="literal">prepend(key, value [, expiry])</code></td><td>Prepends the supplied <code class="literal">value</code> to the value of the
                existing <code class="literal">key</code>.</td></tr><tr><td scope="row"><code class="literal">append(key, value [, expiry[)</code></td><td>Appends the supplied <code class="literal">value</code> to the value of the
                existing <code class="literal">key</code>.</td></tr><tr><td scope="row"><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code>.</td></tr><tr><td scope="row"><code class="literal">delete_multi(keys [, expiry [, key_prefix]] )</code></td><td>Deletes all the keys from the hash matching each string in the array
<code class="literal">keys</code>.</td></tr><tr><td scope="row"><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code>.</td></tr><tr><td scope="row"><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code>.</td></tr></tbody></table>
</div>
<div class="note" style="margin-left: 0.5in; margin-right: 0.5in;">
<div class="admon-title">
Note
</div>
<p>
          Within the Python <code class="literal">memcache</code> module, all the
          <code class="literal">*_multi()</code>functions support an optional
          <code class="literal">key_prefix</code> parameter. If supplied, then the
          string is used as a prefix to all key lookups. For example, if
          you call:
        </p><pre class="programlisting">
memc.get_multi(['a','b'], key_prefix='users:')
</pre><p>
          The function retrieves the keys <code class="literal">users:a</code> and
          <code class="literal">users:b</code> from the servers.
</p>
</div>
<p>
        Here is an example showing the storage and retrieval of
        information to a <code class="literal">memcache</code> instance, loading
        the raw data from MySQL:
      </p><pre class="programlisting">
import sys
import MySQLdb
import memcache

memc = memcache.Client(['127.0.0.1:11211'], debug=1);

try:
    conn = MySQLdb.connect (host = "localhost",
                            user = "sakila",
                            passwd = "password",
                            db = "sakila")
except MySQLdb.Error, e:
     print "Error %d: %s" % (e.args[0], e.args[1])
     sys.exit (1)

popularfilms = memc.get('top5films')

if not popularfilms:
    cursor = conn.cursor()
    cursor.execute('select film_id,title from film order by rental_rate desc limit 5')
    rows = cursor.fetchall()
    memc.set('top5films',rows,60)
    print "Updated memcached with MySQL data"
else:
    print "Loaded data from memcached"
    for row in popularfilms:
        print "%s, %s" % (row[0], row[1])
</pre><p>
        When executed for the first time, the data is loaded from the
        MySQL database and stored to the <span class="command"><strong>memcached</strong></span>
        server.
      </p><pre class="programlisting">
shell&gt; python memc_python.py
Updated memcached with MySQL data
</pre><p>
        Because the data is automatically serialized using
        <code class="literal">cPickle</code>/<code class="literal">pickle</code>, when you
        load the data back from <span class="command"><strong>memcached</strong></span>, you can
        use the object directly. In the example above, the information
        stored to <code class="literal">memcached</code> is in the form of rows
        from a Python DB cursor. When accessing the information (within
        the 60 second expiry time), the data is loaded from
        <code class="literal">memcached</code> and dumped:
      </p><pre class="programlisting">
shell&gt; python memc_python.py
Loaded data from memcached
2, ACE GOLDFINGER
7, AIRPLANE SIERRA
8, AIRPORT POLLOCK
10, ALADDIN CALENDAR
13, ALI FOREVER
</pre><p>
        The serialization and deserialization happens automatically.
        Because serialization of Python data may be incompatible with
        other interfaces and languages, you can change the serialization
        module used during initialization. For example, you might use
        JSON format when you store complex data structures using a
        script written in one language, and access them in a script
        written in a different language.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-interfaces-php"></a>16.6.3.6 Using MySQL and <span class="command"><strong>memcached</strong></span> with PHP</h4>

</div>

</div>

</div>
<p>
        PHP provides support for the Memcache functions through a PECL
        extension. To enable the PHP <code class="literal">memcache</code>
        extensions, build PHP using the
        <code class="option">--enable-memcache</code> option to
        <span class="command"><strong>configure</strong></span> when building from source.
      </p><p>
        If you are installing on a Red Hat-based server, you can install
        the <code class="literal">php-pecl-memcache</code> RPM:
      </p><pre class="programlisting">
root-shell&gt; yum --install php-pecl-memcache
</pre><p>
        On Debian-based distributions, use the
        <code class="literal">php-memcache</code> package.
      </p><p>
        To set global runtime configuration options, specify the
        configuration option values within your
        <code class="filename">php.ini</code> file. The following table provides
        the name, default value, and a description for each global
        runtime configuration option.
</p>
<div class="informaltable">
<table summary="This table lists global runtime configuration options
          for the PECL Memcache extension. The table
          provides configuration option names, default values, and
          descriptions." border="1"><colgroup><col><col><col></colgroup><thead><tr><th scope="col">Configuration option</th><th scope="col">Default</th><th scope="col">Description</th></tr></thead><tbody><tr><td scope="row"><code class="literal">memcache.allow_failover</code></td><td>1</td><td>Specifies whether another server in the list should be queried if the
                first server selected fails.</td></tr><tr><td scope="row"><code class="literal">memcache.max_failover_attempts</code></td><td>20</td><td>Specifies the number of servers to try before returning a failure.</td></tr><tr><td scope="row"><code class="literal">memcache.chunk_size</code></td><td>8192</td><td>Defines the size of network chunks used to exchange data with the
                <span class="command"><strong>memcached</strong></span> server.</td></tr><tr><td scope="row"><code class="literal">memcache.default_port</code></td><td>11211</td><td>Defines the default port to use when communicating with the
                <span class="command"><strong>memcached</strong></span> servers.</td></tr><tr><td scope="row"><code class="literal">memcache.hash_strategy</code></td><td>standard</td><td>Specifies which hash strategy to use. Set to
                <code class="literal">consistent</code> to enable servers to be
                added or removed from the pool without causing the keys
                to be remapped to other servers. When set to
                <code class="literal">standard</code>, an older (modula) strategy
                is used that potentially uses different servers for
                storage.</td></tr><tr><td scope="row"><code class="literal">memcache.hash_function</code></td><td>crc32</td><td>Specifies which function to use when mapping keys to servers.
                <code class="literal">crc32</code> uses the standard CRC32 hash.
                <code class="literal">fnv</code> uses the FNV-1a hashing
algorithm.</td></tr></tbody></table>
</div>
<p>
        To create a connection to a <span class="command"><strong>memcached</strong></span> server,
        create a new <code class="literal">Memcache</code> object and then specify
        the connection options. For example:
      </p><pre class="programlisting">
&lt;?php

$cache = new Memcache;
$cache-&gt;connect('localhost',11211);
?&gt;
</pre><p>
        This opens an immediate connection to the specified server.
      </p><p>
        To use multiple <span class="command"><strong>memcached</strong></span> servers, you need
        to add servers to the memcache object using
        <code class="literal">addServer()</code>:
      </p><pre class="programlisting">
bool Memcache::addServer ( string $host [, int $port [, bool $persistent
                 [, int $weight [, int $timeout [, int $retry_interval
                 [, bool $status [, callback $failure_callback
                 ]]]]]]] )
</pre><p>
        The server management mechanism within the
        <code class="literal">php-memcache</code> module is a critical part of
        the interface as it controls the main interface to the
        <span class="command"><strong>memcached</strong></span> instances and how the different
        instances are selected through the hashing mechanism.
      </p><p>
        To create a simple connection to two
        <span class="command"><strong>memcached</strong></span> instances:
      </p><pre class="programlisting">
&lt;?php

$cache = new Memcache;
$cache-&gt;addServer('192.168.0.100',11211);
$cache-&gt;addServer('192.168.0.101',11211);
?&gt;
</pre><p>
        In this scenario, the instance connection is not explicitly
        opened, but only opened when you try to store or retrieve a
        value. To enable persistent connections to
        <span class="command"><strong>memcached</strong></span> instances, set the
        <code class="literal">$persistent</code> argument to true. This is the
        default setting, and causes the connections to remain open.
      </p><p>
        To help control the distribution of keys to different instances,
        use the global <code class="literal">memcache.hash_strategy</code>
        setting. This sets the hashing mechanism used to select. You can
        also add another weight to each server, which effectively
        increases the number of times the instance entry appears in the
        instance list, therefore increasing the likelihood of the
        instance being chosen over other instances. To set the weight,
        set the value of the <code class="literal">$weight</code> argument to more
        than one.
      </p><p>
        The functions for setting and retrieving information are
        identical to the generic functional interface offered by
        <code class="literal">memcached</code>, as shown in this table:
</p>
<div class="informaltable">
<table summary="This table lists PECL memcached
          functions and the equivalent generic functions in the
memcached interface specification." border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col">PECL <code class="literal">memcache</code> Function</th><th scope="col">Generic Function</th></tr></thead><tbody><tr><td scope="row"><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code>.</td></tr><tr><td scope="row"><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code>.</td></tr><tr><td scope="row"><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code>.</td></tr><tr><td scope="row"><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code>.</td></tr><tr><td scope="row"><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code>.</td></tr><tr><td scope="row"><code class="literal">increment()</code></td><td>Generic <code class="literal">incr()</code>.</td></tr><tr><td scope="row"><code class="literal">decrement()</code></td><td>Generic <code class="literal">decr()</code>.</td></tr></tbody></table>
</div>
<p>
        A full example of the PECL <code class="literal">memcache</code> interface
        is provided below. The code loads film data from the Sakila
        database when the user provides a film name. The data stored
        into the <code class="literal">memcached</code> instance is recorded as a
        <code class="literal">mysqli</code> result row, and the API automatically
        serializes the information for you.
      </p><pre class="programlisting">

&lt;?php

$memc = new Memcache;
$memc-&gt;addServer('localhost','11211');

if(empty($_POST['film'])) {
?&gt;
  &lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"&gt;
    &lt;head&gt;
      &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
      &lt;title&gt;Simple Memcache Lookup&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
      &lt;form method="post"&gt;
        &lt;p&gt;&lt;b&gt;Film&lt;/b&gt;: &lt;input type="text" size="20" name="film"&gt;&lt;/p&gt;
        &lt;input type="submit"&gt;
      &lt;/form&gt;
      &lt;hr/&gt;
&lt;?php

} else {
    
    echo "Loading data...\n";
    
    $film   = htmlspecialchars($_POST['film'], ENT_QUOTES, 'UTF-8');
    $mfilms = $memc-&gt;get($film);

    if ($mfilms) {

        printf("&lt;p&gt;Film data for %s loaded from memcache&lt;/p&gt;", $mfilms['title']);

        foreach (array_keys($mfilms) as $key) {
            printf("&lt;p&gt;&lt;b&gt;%s&lt;/b&gt;: %s&lt;/p&gt;", $key, $mfilms[$key]);
        }

    } else {

        $mysqli = mysqli('localhost','sakila','password','sakila');
    
        if (mysqli_connect_error()) {
            sprintf("Database error: (%d) %s", mysqli_connect_errno(), mysqli_connect_error());
            exit;
        }
    
        $sql = sprintf('SELECT * FROM film WHERE title="%s"', $mysqli-&gt;real_escape_string($film));

        $result = $mysqli-&gt;query($sql);

        if (!$result) {
            sprintf("Database error: (%d) %s", $mysqli-&gt;errno, $mysqli-&gt;error);
            exit;
        }

        $row = $result-&gt;fetch_assoc();

        $memc-&gt;set($row['title'], $row);

        printf("&lt;p&gt;Loaded (%s) from MySQL&lt;/p&gt;", htmlspecialchars($row['title'], ENT_QUOTES, 'UTF-8');
    }
}
?&gt;
  &lt;/body&gt;
&lt;/html&gt;

</pre><p>
        With PHP, the connections to the <span class="command"><strong>memcached</strong></span>
        instances are kept open as long as the PHP and associated Apache
        instance remain running. When adding or removing servers from
        the list in a running instance (for example, when starting
        another script that mentions additional servers), the
        connections are shared, but the script only selects among the
        instances explicitly configured within the script.
      </p><p>
        To ensure that changes to the server list within a script do not
        cause problems, make sure to use the consistent hashing
        mechanism.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-interfaces-ruby"></a>16.6.3.7 Using MySQL and <span class="command"><strong>memcached</strong></span> with Ruby</h4>

</div>

</div>

</div>
<p>
        There are a number of different modules for interfacing to
        <span class="command"><strong>memcached</strong></span> within Ruby. The
        <code class="literal">Ruby-MemCache</code> client library provides a
        native interface to <span class="command"><strong>memcached</strong></span> that does not
        require any external libraries, such as
        <code class="literal">libmemcached</code>. You can obtain the installer
        package from
        <a class="ulink" href="http://www.deveiate.org/projects/RMemCache" target="_top">http://www.deveiate.org/projects/RMemCache</a>.
      </p><p>
        To install, extract the package and then run
        <span class="command"><strong>install.rb</strong></span>:
      </p><pre class="programlisting">
shell&gt; install.rb
</pre><p>
        If you have RubyGems, you can install the
        <code class="literal">Ruby-MemCache</code> gem:
      </p><pre class="programlisting">
shell&gt; gem install Ruby-MemCache
Bulk updating Gem source index for: http://gems.rubyforge.org
Install required dependency io-reactor? [Yn]  y
Successfully installed Ruby-MemCache-0.0.1
Successfully installed io-reactor-0.05
Installing ri documentation for io-reactor-0.05...
Installing RDoc documentation for io-reactor-0.05...
</pre><p>
        To use a <span class="command"><strong>memcached</strong></span> instance from within Ruby,
        create a new instance of the <code class="literal">MemCache</code> object.
      </p><pre class="programlisting">
require 'memcache'
memc = MemCache::new '192.168.0.100:11211'
</pre><p>
        You can add a weight to each server to increase the likelihood
        of the server being selected during hashing by appending the
        weight count to the server host name/port string:
      </p><pre class="programlisting">
require 'memcache'
memc = MemCache::new '192.168.0.100:11211:3'
</pre><p>
        To add servers to an existing list, you can append them directly
        to the <code class="literal">MemCache</code> object:
      </p><pre class="programlisting">
memc += ["192.168.0.101:11211"]
</pre><p>
        To set data into the cache, you can just assign a value to a key
        within the new cache object, which works just like a standard
        Ruby hash object:
      </p><pre class="programlisting">
memc["key"] = "value"
</pre><p>
        Or to retrieve the value:
      </p><pre class="programlisting">
print memc["key"]
</pre><p>
        For more explicit actions, you can use the method interface,
        which mimics the main <span class="command"><strong>memcached</strong></span> API
        functions, as summarized in the following table:
</p>
<div class="informaltable">
<table summary="This table lists memcached methods
          for Ruby and the equivalent memcached API
          functions." border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col">Ruby <code class="literal">MemCache</code> Method</th><th scope="col">Equivalent <span class="command"><strong>memcached</strong></span> API Functions</th></tr></thead><tbody><tr><td scope="row"><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code>.</td></tr><tr><td scope="row"><code class="literal">get_hash(keys)</code></td><td>Get the values of multiple <code class="literal">keys</code>, returning the
                information as a hash of the keys and their values.</td></tr><tr><td scope="row"><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code>.</td></tr><tr><td scope="row"><code class="literal">set_many(pairs)</code></td><td>Set the values of the keys and values in the hash
<code class="literal">pairs</code>.</td></tr><tr><td scope="row"><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code>.</td></tr><tr><td scope="row"><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code>.</td></tr><tr><td scope="row"><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code>.</td></tr><tr><td scope="row"><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code>.</td></tr><tr><td scope="row"><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code>.</td></tr></tbody></table>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-interfaces-java"></a>16.6.3.8 Using MySQL and <span class="command"><strong>memcached</strong></span> with Java</h4>

</div>

</div>

</div>
<p>
        The <code class="literal">com.danga.MemCached</code> class within Java
        provides a native interface to <span class="command"><strong>memcached</strong></span>
        instances. You can obtain the client from
        <a class="ulink" href="https://github.com/gwhalin/Memcached-Java-Client/downloads" target="_top">https://github.com/gwhalin/Memcached-Java-Client/downloads</a>.
        The Java class uses hashes that are compatible with
        <code class="literal">libmemcached</code>, so you can mix and match Java
        and <code class="literal">libmemcached</code> applications accessing the
        same <span class="command"><strong>memcached</strong></span> instances. The serialization
        between Java and other interfaces are not compatible. If this is
        a problem, use JSON or a similar nonbinary serialization format.
      </p><p>
        On most systems, you can download the package and use the
        <code class="filename">jar</code> directly.
      </p><p>
        To use the <code class="literal">com.danga.MemCached</code> interface, you
        create a <code class="literal">MemCachedClient</code> instance and then
        configure the list of servers by configuring the
        <code class="literal">SockIOPool</code>. Through the pool specification
        you set up the server list, weighting, and the connection
        parameters to optimized the connections between your client and
        the <span class="command"><strong>memcached</strong></span> instances that you configure.
      </p><p>
        Generally, you can configure the <span class="command"><strong>memcached</strong></span>
        interface once within a single class, then use this interface
        throughout the rest of your application.
      </p><p>
        For example, to create a basic interface, first configure the
        <code class="literal">MemCachedClient</code> and base
        <code class="literal">SockIOPool</code> settings:
      </p><pre class="programlisting">
public class MyClass {

    protected static MemCachedClient mcc = new MemCachedClient();

    static {
	
        String[] servers =
            {
                "localhost:11211",
            };
	
        Integer[] weights = { 1 };
	
        SockIOPool pool = SockIOPool.getInstance();
	
        pool.setServers( servers );
        pool.setWeights( weights );

</pre><p>
        In the above sample, the list of servers is configured by
        creating an array of the <span class="command"><strong>memcached</strong></span> instances
        to use. You can then configure individual weights for each
        server.
      </p><p>
        The remainder of the properties for the connection are optional,
        but you can set the connection numbers (initial connections,
        minimum connections, maximum connections, and the idle timeout)
        by setting the pool parameters:
      </p><pre class="programlisting">
pool.setInitConn( 5 );
pool.setMinConn( 5 );
pool.setMaxConn( 250 );
pool.setMaxIdle( 1000 * 60 * 60 * 6 
</pre><p>
        Once the parameters have been configured, initialize the
        connection pool:
      </p><pre class="programlisting">
pool.initialize();
</pre><p>
        The pool, and the connection to your
        <span class="command"><strong>memcached</strong></span> instances should now be ready to
        use.
      </p><p>
        To set the hashing algorithm used to select the server used when
        storing a given key, use
        <code class="literal">pool.setHashingAlg()</code>:
      </p><pre class="programlisting">
pool.setHashingAlg( SockIOPool.NEW_COMPAT_HASH );
</pre><p>
        Valid values are <code class="literal">NEW_COMPAT_HASH</code>,
        <code class="literal">OLD_COMPAT_HASH</code> and
        <code class="literal">NATIVE_HASH</code> are also basic modula hashing
        algorithms. For a consistent hashing algorithm, use
        <code class="literal">CONSISTENT_HASH</code>. These constants are
        equivalent to the corresponding hash settings within
        <code class="literal">libmemcached</code>.
      </p><p>
        The following table outlines the Java
        <code class="literal">com.danga.MemCached</code> methods and the
        equivalent generic methods in the <span class="command"><strong>memcached</strong></span>
        interface specification.
</p>
<div class="informaltable">
<table summary="This table lists Java
          com.danga.MemCached methods and the
          equivalent generic methods in the memcached
          interface specification." border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col">Java <code class="literal">com.danga.MemCached</code> Method</th><th scope="col">Equivalent Generic Method</th></tr></thead><tbody><tr><td scope="row"><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code>.</td></tr><tr><td scope="row"><code class="literal">getMulti(keys)</code></td><td>Get the values of multiple <code class="literal">keys</code>, returning the
                information as Hash map using
                <code class="literal">java.lang.String</code> for the keys and
                <code class="literal">java.lang.Object</code> for the
corresponding values.</td></tr><tr><td scope="row"><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code>.</td></tr><tr><td scope="row"><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code>.</td></tr><tr><td scope="row"><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code>.</td></tr><tr><td scope="row"><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code>.</td></tr><tr><td scope="row"><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code>.</td></tr><tr><td scope="row"><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code>.</td></tr></tbody></table>
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-interfaces-protocol"></a>16.6.3.9 Using the <span class="command"><strong>memcached</strong></span> TCP Text Protocol</h4>

</div>

</div>

</div>
<p>
        Communicating with a <span class="command"><strong>memcached</strong></span> server can be
        achieved through either the TCP or UDP protocols. When using the
        TCP protocol, you can use a simple text based interface for the
        exchange of information.
      </p><p>
        When communicating with <span class="command"><strong>memcached</strong></span>, you can
        connect to the server using the port configured for the server.
        You can open a connection with the server without requiring
        authorization or login. As soon as you have connected, you can
        start to send commands to the server. When you have finished,
        you can terminate the connection without sending any specific
        disconnection command. Clients are encouraged to keep their
        connections open to decrease latency and improve performance.
      </p><p>
        Data is sent to the <code class="literal">memcached</code> server in two
        forms:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            Text lines, which are used to send commands to the server,
            and receive responses from the server.
          </p></li><li class="listitem"><p>
            Unstructured data, which is used to receive or send the
            value information for a given key. Data is returned to the
            client in exactly the format it was provided.
</p></li></ul>
</div>
<p>
        Both text lines (commands and responses) and unstructured data
        are always terminated with the string <code class="literal">\r\n</code>.
        Because the data being stored may contain this sequence, the
        length of the data (returned by the client before the
        unstructured data is transmitted should be used to determine the
        end of the data.
      </p><p>
        Commands to the server are structured according to their
        operation:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <span class="bold"><strong>Storage commands</strong></span>:
            <code class="literal">set</code>, <code class="literal">add</code>,
            <code class="literal">replace</code>, <code class="literal">append</code>,
            <code class="literal">prepend</code>, <code class="literal">cas</code>
          </p><p>
            Storage commands to the server take the form:
          </p><pre class="programlisting">
command key [flags] [exptime] length [noreply]
</pre><p>
            Or when using compare and swap (cas):
          </p><pre class="programlisting">
cas key [flags] [exptime] length [casunique] [noreply]
</pre><p>
            Where:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">command</code>: The command name.
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: square; "><li class="listitem"><p>
                    <code class="literal">set</code>: Store value against key
                  </p></li><li class="listitem"><p>
                    <code class="literal">add</code>: Store this value against key
                    if the key does not already exist
                  </p></li><li class="listitem"><p>
                    <code class="literal">replace</code>: Store this value against
                    key if the key already exists
                  </p></li><li class="listitem"><p>
                    <code class="literal">append</code>: Append the supplied value
                    to the end of the value for the specified key. The
                    <code class="literal">flags</code> and
                    <code class="literal">exptime</code> arguments should not be
                    used.
                  </p></li><li class="listitem"><p>
                    <code class="literal">prepend</code>: Append value currently
                    in the cache to the end of the supplied value for
                    the specified key. The <code class="literal">flags</code> and
                    <code class="literal">exptime</code> arguments should not be
                    used.
                  </p></li><li class="listitem"><p>
                    <code class="literal">cas</code>: Set the specified key to the
                    supplied value, only if the supplied
                    <code class="literal">casunique</code> matches. This is
                    effectively the equivalent of change the information
                    if nobody has updated it since I last fetched it.
</p></li></ul>
</div>
</li><li class="listitem"><p>
                <code class="literal">key</code>: The key. All data is stored
                using a the specific key. The key cannot contain control
                characters or whitespace, and can be up to 250
                characters in size.
              </p></li><li class="listitem"><p>
                <code class="literal">flags</code>: The flags for the operation
                (as an integer). Flags in <span class="command"><strong>memcached</strong></span>
                are transparent. The <span class="command"><strong>memcached</strong></span> server
                ignores the contents of the flags. They can be used by
                the client to indicate any type of information. In
                <span class="command"><strong>memcached</strong></span> 1.2.0 and lower the value
                is a 16-bit integer value. In
                <span class="command"><strong>memcached</strong></span> 1.2.1 and higher the value
                is a 32-bit integer.
              </p></li><li class="listitem"><p>
                <code class="literal">exptime</code>: The expiry time, or zero for
                no expiry.
              </p></li><li class="listitem"><p>
                <code class="literal">length</code>: The length of the supplied
                value block in bytes, excluding the terminating
                <code class="literal">\r\n</code> characters.
              </p></li><li class="listitem"><p>
                <code class="literal">casunique</code>: A unique 64-bit value of
                an existing entry. This is used to compare against the
                existing value. Use the value returned by the
                <code class="literal">gets</code> command when issuing
                <code class="literal">cas</code> updates.
              </p></li><li class="listitem"><p>
                <code class="literal">noreply</code>: Tells the server not to
                reply to the command.
</p></li></ul>
</div>
<p>
            For example, to store the value <code class="literal">abcdef</code>
            into the key <code class="literal">xyzkey</code>, you would use:
          </p><pre class="programlisting">
set xyzkey 0 0 6\r\nabcdef\r\n
</pre><p>
            The return value from the server is one line, specifying the
            status or error information. For more information, see
            <a class="xref" href="ha-overview.html#ha-memcached-interfaces-protocol-responses" title="Table 16.3 memcached Protocol Responses">Table 16.3, “<span class="command">memcached</span> Protocol Responses”</a>.
          </p></li><li class="listitem"><p>
            <span class="bold"><strong>Retrieval commands</strong></span>:
            <code class="literal">get</code>, <code class="literal">gets</code>
          </p><p>
            Retrieval commands take the form:
          </p><pre class="programlisting">
get key1 [key2 .... keyn]
gets key1 [key2 ... keyn]
</pre><p>
            You can supply multiple keys to the commands, with each
            requested key separated by whitespace.
          </p><p>
            The server responds with an information line of the form:
          </p><pre class="programlisting">
VALUE key flags bytes [casunique]
</pre><p>
            Where:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The key name.
              </p></li><li class="listitem"><p>
                <code class="literal">flags</code>: The value of the flag integer
                supplied to the <span class="command"><strong>memcached</strong></span> server when
                the value was stored.
              </p></li><li class="listitem"><p>
                <code class="literal">bytes</code>: The size (excluding the
                terminating <code class="literal">\r\n</code> character sequence)
                of the stored value.
              </p></li><li class="listitem"><p>
                <code class="literal">casunique</code>: The unique 64-bit integer
                that identifies the item.
</p></li></ul>
</div>
<p>
            The information line is immediately followed by the value
            data block. For example:
          </p><pre class="programlisting">
get xyzkey\r\n
VALUE xyzkey 0 6\r\n
abcdef\r\n
</pre><p>
            If you have requested multiple keys, an information line and
            data block is returned for each key found. If a requested
            key does not exist in the cache, no information is returned.
          </p></li><li class="listitem"><p>
            <span class="bold"><strong>Delete commands</strong></span>:
            <code class="literal">delete</code>
          </p><p>
            Deletion commands take the form:
          </p><pre class="programlisting">
delete key [time] [noreply]
</pre><p>
            Where:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The key name.
              </p></li><li class="listitem"><p>
                <code class="literal">time</code>: The time in seconds (or a
                specific Unix time) for which the client wishes the
                server to refuse <code class="literal">add</code> or
                <code class="literal">replace</code> commands on this key. All
                <code class="literal">add</code>, <code class="literal">replace</code>,
                <code class="literal">get</code>, and <code class="literal">gets</code>
                commands fail during this period. <code class="literal">set</code>
                operations succeed. After this period, the key is
                deleted permanently and all commands are accepted.
              </p><p>
                If not supplied, the value is assumed to be zero (delete
                immediately).
              </p></li><li class="listitem"><p>
                <code class="literal">noreply</code>: Tells the server not to
                reply to the command.
</p></li></ul>
</div>
<p>
            Responses to the command are either
            <code class="literal">DELETED</code> to indicate that the key was
            successfully removed, or <code class="literal">NOT_FOUND</code> to
            indicate that the specified key could not be found.
          </p></li><li class="listitem"><p>
            <span class="bold"><strong>Increment/Decrement</strong></span>:
            <code class="literal">incr</code>, <code class="literal">decr</code>
          </p><p>
            The increment and decrement commands change the value of a
            key within the server without performing a separate get/set
            sequence. The operations assume that the currently stored
            value is a 64-bit integer. If the stored value is not a
            64-bit integer, then the value is assumed to be zero before
            the increment or decrement operation is applied.
          </p><p>
            Increment and decrement commands take the form:
          </p><pre class="programlisting">
incr key value [noreply]
decr key value [noreply]
</pre><p>
            Where:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">key</code>: The key name.
              </p></li><li class="listitem"><p>
                <code class="literal">value</code>: An integer to be used as the
                increment or decrement value.
              </p></li><li class="listitem"><p>
                <code class="literal">noreply</code>: Tells the server not to
                reply to the command.
</p></li></ul>
</div>
<p>
            The response is:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">NOT_FOUND</code>: The specified key could
                not be located.
              </p></li><li class="listitem"><p>
                <code class="literal">value</code>: The new value associated with
                the specified key.
</p></li></ul>
</div>
<p>
            Values are assumed to be unsigned. For
            <code class="literal">decr</code> operations, the value is never
            decremented below 0. For <code class="literal">incr</code> operations,
            the value wraps around the 64-bit maximum.
          </p></li><li class="listitem"><p>
            <span class="bold"><strong>Statistics commands</strong></span>:
            <code class="literal">stats</code>
          </p><p>
            The <code class="literal">stats</code> command provides detailed
            statistical information about the current status of the
            <span class="command"><strong>memcached</strong></span> instance and the data it is
            storing.
          </p><p>
            Statistics commands take the form:
          </p><pre class="programlisting">
STAT [name] [value]
</pre><p>
            Where:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>
                <code class="literal">name</code>: The optional name of the
                statistics to return. If not specified, the general
                statistics are returned.
              </p></li><li class="listitem"><p>
                <code class="literal">value</code>: A specific value to be used
                when performing certain statistics operations.
</p></li></ul>
</div>
<p>
            The return value is a list of statistics data, formatted as
            follows:
          </p><pre class="programlisting">
STAT name value
</pre><p>
            The statistics are terminated with a single line,
            <code class="literal">END</code>.
          </p><p>
            For more information, see
            <a class="xref" href="ha-overview.html#ha-memcached-stats" title="16.6.4 Getting memcached Statistics">Section 16.6.4, “Getting <span class="command"><strong>memcached</strong></span> Statistics”</a>.
</p></li></ul>
</div>
<p>
        For reference, a list of the different commands supported and
        their formats is provided below.
</p>
<div class="table">
<a name="idm139737121352816"></a><p class="title"><b>Table 16.2 <span class="command">memcached</span> Command Reference</b></p>
<div class="table-contents">
<table summary="memcached Command Reference" border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col">Command</th><th scope="col">Command Formats</th></tr></thead><tbody><tr><td scope="row"><code class="literal">set</code></td><td><code class="literal">set key flags exptime length</code>, <code class="literal">set key flags
                exptime length noreply</code></td></tr><tr><td scope="row"><code class="literal">add</code></td><td><code class="literal">add key flags exptime length</code>, <code class="literal">add key flags
                exptime length noreply</code></td></tr><tr><td scope="row"><code class="literal">replace</code></td><td><code class="literal">replace key flags exptime length</code>, <code class="literal">replace
                key flags exptime length noreply</code></td></tr><tr><td scope="row"><code class="literal">append</code></td><td><code class="literal">append key length</code>, <code class="literal">append key length
                noreply</code></td></tr><tr><td scope="row"><code class="literal">prepend</code></td><td><code class="literal">prepend key length</code>, <code class="literal">prepend key length
                noreply</code></td></tr><tr><td scope="row"><code class="literal">cas</code></td><td><code class="literal">cas key flags exptime length casunique</code>, <code class="literal">cas
                key flags exptime length casunique noreply</code></td></tr><tr><td scope="row"><code class="literal">get</code></td><td><code class="literal">get key1 [key2 ... keyn]</code></td></tr><tr><td scope="row"><code class="literal">gets</code></td><td><code class="literal"></code></td></tr><tr><td scope="row"><code class="literal">delete</code></td><td><code class="literal">delete key</code>, <code class="literal">delete key noreply</code>,
                <code class="literal">delete key expiry</code>, <code class="literal">delete
                key expiry noreply</code></td></tr><tr><td scope="row"><code class="literal">incr</code></td><td><code class="literal">incr key</code>, <code class="literal">incr key noreply</code>,
                <code class="literal">incr key value</code>, <code class="literal">incr key
                value noreply</code></td></tr><tr><td scope="row"><code class="literal">decr</code></td><td><code class="literal">decr key</code>, <code class="literal">decr key noreply</code>,
                <code class="literal">decr key value</code>, <code class="literal">decr key
                value noreply</code></td></tr><tr><td scope="row"><code class="literal">stat</code></td><td><code class="literal">stat</code>, <code class="literal">stat name</code>, <code class="literal">stat
name value</code></td></tr></tbody></table>
</div>

</div>
<br class="table-break"><p>
        When sending a command to the server, the response from the
        server is one of the settings in the following table. All
        response values from the server are terminated by
        <code class="literal">\r\n</code>:
</p>
<div class="table">
<a name="ha-memcached-interfaces-protocol-responses"></a><p class="title"><b>Table 16.3 <span class="command">memcached</span> Protocol Responses</b></p>
<div class="table-contents">
<table summary="memcached Protocol Responses" border="1"><colgroup><col><col></colgroup><thead><tr><th scope="col">String</th><th scope="col">Description</th></tr></thead><tbody><tr><td scope="row"><code class="literal">STORED</code></td><td>Value has successfully been stored.</td></tr><tr><td scope="row"><code class="literal">NOT_STORED</code></td><td>The value was not stored, but not because of an error. For commands
                where you are adding a or updating a value if it exists
                (such as <code class="literal">add</code> and
                <code class="literal">replace</code>), or where the item has
                already been set to be deleted.</td></tr><tr><td scope="row"><code class="literal">EXISTS</code></td><td>When using a <code class="literal">cas</code> command, the item you are trying to
                store already exists and has been modified since you
                last checked it.</td></tr><tr><td scope="row"><code class="literal">NOT_FOUND</code></td><td>The item you are trying to store, update or delete does not exist or has
                already been deleted.</td></tr><tr><td scope="row"><code class="literal">ERROR</code></td><td>You submitted a nonexistent command name.</td></tr><tr><td scope="row"><code class="literal">CLIENT_ERROR errorstring</code></td><td>There was an error in the input line, the detail is contained in
                <code class="literal">errorstring</code>.</td></tr><tr><td scope="row"><code class="literal">SERVER_ERROR errorstring</code></td><td>There was an error in the server that prevents it from returning the
                information. In extreme conditions, the server may
                disconnect the client after this error occurs.</td></tr><tr><td scope="row"><code class="literal">VALUE keys flags length</code></td><td>The requested key has been found, and the stored <code class="literal">key</code>,
                <code class="literal">flags</code> and data block are returned, of
the specified <code class="literal">length</code>.</td></tr><tr><td scope="row"><code class="literal">DELETED</code></td><td>The requested key was deleted from the server.</td></tr><tr><td scope="row"><code class="literal">STAT name value</code></td><td>A line of statistics data.</td></tr><tr><td scope="row"><code class="literal">END</code></td><td>The end of the statistics data.</td></tr></tbody></table>
</div>

</div>
<br class="table-break">
</div>

</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-memcached-stats"></a>16.6.4 Getting <span class="command"><strong>memcached</strong></span> Statistics</h3>

</div>

</div>

</div>
<div class="toc">
<dl class="toc"><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-general">16.6.4.1 <span class="command"><strong>memcached</strong></span> General Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-slabs">16.6.4.2 <span class="command"><strong>memcached</strong></span> Slabs Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-items">16.6.4.3 <span class="command"><strong>memcached</strong></span> Item Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-sizes">16.6.4.4 <span class="command"><strong>memcached</strong></span> Size Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-detail">16.6.4.5 <code class="literal">memcached</code> Detail Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-memcached-tool">16.6.4.6 Using <span class="command"><strong>memcached-tool</strong></span></a></span></dt></dl>
</div>
<p>
      The <span class="command"><strong>memcached</strong></span> system has a built-in statistics
      system that collects information about the data being stored into
      the cache, cache hit ratios, and detailed information on the
      memory usage and distribution of information through the slab
      allocation used to store individual items. Statistics are provided
      at both a basic level that provide the core statistics, and more
      specific statistics for specific areas of the
      <span class="command"><strong>memcached</strong></span> server.
    </p><p>
      This information can be useful to ensure that you are getting the
      correct level of cache and memory usage, and that your slab
      allocation and configuration properties are set at an optimal
      level.
    </p><p>
      The stats interface is available through the standard
      <span class="command"><strong>memcached</strong></span> protocol, so the reports can be
      accessed by using <span class="command"><strong>telnet</strong></span> to connect to the
      <span class="command"><strong>memcached</strong></span>. The supplied
      <span class="command"><strong>memcached-tool</strong></span> includes support for obtaining
      the <a class="xref" href="ha-overview.html#ha-memcached-stats-slabs" title="16.6.4.2 memcached Slabs Statistics">Section 16.6.4.2, “<span class="command"><strong>memcached</strong></span> Slabs Statistics”</a> and
      <a class="xref" href="ha-overview.html#ha-memcached-stats-general" title="16.6.4.1 memcached General Statistics">Section 16.6.4.1, “<span class="command"><strong>memcached</strong></span> General Statistics”</a> information. For more
      information, see
      <a class="xref" href="ha-overview.html#ha-memcached-stats-memcached-tool" title="16.6.4.6 Using memcached-tool">Section 16.6.4.6, “Using <span class="command"><strong>memcached-tool</strong></span>”</a>.
    </p><p>
      Alternatively, most of the language API interfaces provide a
      function for obtaining the statistics from the server.
    </p><p>
      For example, to get the basic stats using
      <span class="command"><strong>telnet</strong></span>:
    </p><pre class="programlisting">
shell&gt; telnet localhost 11211
Trying ::1...
Connected to localhost.
Escape character is '^]'.
stats
STAT pid 23599
STAT uptime 675
STAT time 1211439587
STAT version 1.2.5
STAT pointer_size 32
STAT rusage_user 1.404992
STAT rusage_system 4.694685
STAT curr_items 32
STAT total_items 56361
STAT bytes 2642
STAT curr_connections 53
STAT total_connections 438
STAT connection_structures 55
STAT cmd_get 113482
STAT cmd_set 80519
STAT get_hits 78926
STAT get_misses 34556
STAT evictions 0
STAT bytes_read 6379783
STAT bytes_written 4860179
STAT limit_maxbytes 67108864
STAT threads 1
END
</pre><p>
      When using Perl and the <code class="literal">Cache::Memcached</code>
      module, the <code class="literal">stats()</code> function returns
      information about all the servers currently configured in the
      connection object, and total statistics for all the
      <span class="command"><strong>memcached</strong></span> servers as a whole.
    </p><p>
      For example, the following Perl script obtains the stats and dumps
      the hash reference that is returned:
    </p><pre class="programlisting">
use Cache::Memcached;
use Data::Dumper;

my $memc = new Cache::Memcached;
$memc-&gt;set_servers(\@ARGV);

print Dumper($memc-&gt;stats());
</pre><p>
      When executed on the same <span class="command"><strong>memcached</strong></span> as used in
      the <span class="command"><strong>Telnet</strong></span> example above we get a hash
      reference with the host by host and total statistics:
    </p><pre class="programlisting">
$VAR1 = {
    'hosts' =&gt; {
           'localhost:11211' =&gt; {
                      'misc' =&gt; {
                            'bytes' =&gt; '2421',
                            'curr_connections' =&gt; '3',
                            'connection_structures' =&gt; '56',
                            'pointer_size' =&gt; '32',
                            'time' =&gt; '1211440166',
                            'total_items' =&gt; '410956',
                            'cmd_set' =&gt; '588167',
                            'bytes_written' =&gt; '35715151',
                            'evictions' =&gt; '0',
                            'curr_items' =&gt; '31',
                            'pid' =&gt; '23599',
                            'limit_maxbytes' =&gt; '67108864',
                            'uptime' =&gt; '1254',
                            'rusage_user' =&gt; '9.857805',
                            'cmd_get' =&gt; '838451',
                            'rusage_system' =&gt; '34.096988',
                            'version' =&gt; '1.2.5',
                            'get_hits' =&gt; '581511',
                            'bytes_read' =&gt; '46665716',
                            'threads' =&gt; '1',
                            'total_connections' =&gt; '3104',
                            'get_misses' =&gt; '256940'
                          },
                      'sizes' =&gt; {
                             '128' =&gt; '16',
                             '64' =&gt; '15'
                           }
                    }
         },
    'self' =&gt; {},
    'total' =&gt; {
           'cmd_get' =&gt; 838451,
           'bytes' =&gt; 2421,
           'get_hits' =&gt; 581511,
           'connection_structures' =&gt; 56,
           'bytes_read' =&gt; 46665716,
           'total_items' =&gt; 410956,
           'total_connections' =&gt; 3104,
           'cmd_set' =&gt; 588167,
           'bytes_written' =&gt; 35715151,
           'curr_items' =&gt; 31,
           'get_misses' =&gt; 256940
         }
        };
</pre><p>
      The statistics are divided up into a number of distinct sections,
      and then can be requested by adding the type to the
      <code class="literal">stats</code> command. Each statistics output is
      covered in more detail in the following sections.
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          General statistics, see
          <a class="xref" href="ha-overview.html#ha-memcached-stats-general" title="16.6.4.1 memcached General Statistics">Section 16.6.4.1, “<span class="command"><strong>memcached</strong></span> General Statistics”</a>.
        </p></li><li class="listitem"><p>
          Slab statistics (<code class="literal">slabs</code>), see
          <a class="xref" href="ha-overview.html#ha-memcached-stats-slabs" title="16.6.4.2 memcached Slabs Statistics">Section 16.6.4.2, “<span class="command"><strong>memcached</strong></span> Slabs Statistics”</a>.
        </p></li><li class="listitem"><p>
          Item statistics (<code class="literal">items</code>), see
          <a class="xref" href="ha-overview.html#ha-memcached-stats-items" title="16.6.4.3 memcached Item Statistics">Section 16.6.4.3, “<span class="command"><strong>memcached</strong></span> Item Statistics”</a>.
        </p></li><li class="listitem"><p>
          Size statistics (<code class="literal">sizes</code>), see
          <a class="xref" href="ha-overview.html#ha-memcached-stats-sizes" title="16.6.4.4 memcached Size Statistics">Section 16.6.4.4, “<span class="command"><strong>memcached</strong></span> Size Statistics”</a>.
        </p></li><li class="listitem"><p>
          Detailed status (<code class="literal">detail</code>), see
          <a class="xref" href="ha-overview.html#ha-memcached-stats-detail" title="16.6.4.5 memcached Detail Statistics">Section 16.6.4.5, “<code class="literal">memcached</code> Detail Statistics”</a>.
</p></li></ul>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-stats-general"></a>16.6.4.1 <span class="command"><strong>memcached</strong></span> General Statistics</h4>

</div>

</div>

</div>
<p>
        The output of the general statistics provides an overview of the
        performance and use of the <span class="command"><strong>memcached</strong></span>
        instance. The statistics returned by the command and their
        meaning is shown in the following table.
      </p><p>
        The following terms are used to define the value type for each
        statistics value:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <code class="literal">32u</code>: 32-bit unsigned integer
          </p></li><li class="listitem"><p>
            <code class="literal">64u</code>: 64-bit unsigned integer
          </p></li><li class="listitem"><p>
            <code class="literal">32u:32u</code>: Two 32-bit unsigned integers
            separated by a colon
          </p></li><li class="listitem"><p>
            <code class="literal">String</code>: Character string
</p></li></ul>
</div>
<div class="informaltable">
<table summary="This table lists memcached general
          statistics and provides the data type and a description for
          each statistic." border="1"><colgroup><col><col><col><col></colgroup><thead><tr><th scope="col">Statistic</th><th scope="col">Data type</th><th scope="col">Description</th><th scope="col">Version</th></tr></thead><tbody><tr><td scope="row"><code class="literal">pid</code></td><td>32u</td><td>Process ID of the <span class="command"><strong>memcached</strong></span> instance.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">uptime</code></td><td>32u</td><td>Uptime (in seconds) for this <span class="command"><strong>memcached</strong></span> instance.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">time</code></td><td>32u</td><td>Current time (as epoch).</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">version</code></td><td>string</td><td>Version string of this instance.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">pointer_size</code></td><td>string</td><td>Size of pointers for this host specified in bits (32 or 64).</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">rusage_user</code></td><td>32u:32u</td><td>Total user time for this instance (seconds:microseconds).</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">rusage_system</code></td><td>32u:32u</td><td>Total system time for this instance (seconds:microseconds).</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">curr_items</code></td><td>32u</td><td>Current number of items stored by this instance.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">total_items</code></td><td>32u</td><td>Total number of items stored during the life of this instance.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">bytes</code></td><td>64u</td><td>Current number of bytes used by this server to store items.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">curr_connections</code></td><td>32u</td><td>Current number of open connections.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">total_connections</code></td><td>32u</td><td>Total number of connections opened since the server started running.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">connection_structures</code></td><td>32u</td><td>Number of connection structures allocated by the server.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">cmd_get</code></td><td>64u</td><td>Total number of retrieval requests (<code class="literal">get</code> operations).</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">cmd_set</code></td><td>64u</td><td>Total number of storage requests (<code class="literal">set</code> operations).</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">get_hits</code></td><td>64u</td><td>Number of keys that have been requested and found present.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">get_misses</code></td><td>64u</td><td>Number of items that have been requested and not found.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">delete_hits</code></td><td>64u</td><td>Number of keys that have been deleted and found present.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">delete_misses</code></td><td>64u</td><td>Number of items that have been delete and not found.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">incr_hits</code></td><td>64u</td><td>Number of keys that have been incremented and found present.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">incr_misses</code></td><td>64u</td><td>Number of items that have been incremented and not found.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">decr_hits</code></td><td>64u</td><td>Number of keys that have been decremented and found present.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">decr_misses</code></td><td>64u</td><td>Number of items that have been decremented and not found.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">cas_hits</code></td><td>64u</td><td>Number of keys that have been compared and swapped and found present.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">cas_misses</code></td><td>64u</td><td>Number of items that have been compared and swapped and not found.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">cas_badvalue</code></td><td>64u</td><td>Number of keys that have been compared and swapped, but the comparison
                (original) value did not match the supplied value.</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">evictions</code></td><td>64u</td><td>Number of valid items removed from cache to free memory for new items.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">bytes_read</code></td><td>64u</td><td>Total number of bytes read by this server from network.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">bytes_written</code></td><td>64u</td><td>Total number of bytes sent by this server to network.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">limit_maxbytes</code></td><td>32u</td><td>Number of bytes this server is permitted to use for storage.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">threads</code></td><td>32u</td><td>Number of worker threads requested.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">conn_yields</code></td><td>64u</td><td>Number of yields for connections (related to the <code class="option">-R</code>
option).</td><td>1.4.0</td></tr></tbody></table>
</div>
<p>
        The most useful statistics from those given here are the number
        of cache hits, misses, and evictions.
      </p><p>
        A large number of <code class="literal">get_misses</code> may just be an
        indication that the cache is still being populated with
        information. The number should, over time, decrease in
        comparison to the number of cache <code class="literal">get_hits</code>.
        If, however, you have a large number of cache misses compared to
        cache hits after an extended period of execution, it may be an
        indication that the size of the cache is too small and you
        either need to increase the total memory size, or increase the
        number of the <span class="command"><strong>memcached</strong></span> instances to improve
        the hit ratio.
      </p><p>
        A large number of <code class="literal">evictions</code> from the cache,
        particularly in comparison to the number of items stored is a
        sign that your cache is too small to hold the amount of
        information that you regularly want to keep cached. Instead of
        items being retained in the cache, items are being evicted to
        make way for new items keeping the turnover of items in the
        cache high, reducing the efficiency of the cache.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-stats-slabs"></a>16.6.4.2 <span class="command"><strong>memcached</strong></span> Slabs Statistics</h4>

</div>

</div>

</div>
<p>
        To get the <code class="literal">slabs</code> statistics, use the
        <code class="literal">stats slabs</code> command, or the API equivalent.
      </p><p>
        The slab statistics provide you with information about the slabs
        that have created and allocated for storing information within
        the cache. You get information both on each individual
        slab-class and total statistics for the whole slab.
      </p><pre class="programlisting">
STAT 1:chunk_size 104
STAT 1:chunks_per_page 10082
STAT 1:total_pages 1
STAT 1:total_chunks 10082
STAT 1:used_chunks 10081
STAT 1:free_chunks 1
STAT 1:free_chunks_end 10079
STAT 9:chunk_size 696
STAT 9:chunks_per_page 1506
STAT 9:total_pages 63
STAT 9:total_chunks 94878
STAT 9:used_chunks 94878
STAT 9:free_chunks 0
STAT 9:free_chunks_end 0
STAT active_slabs 2
STAT total_malloced 67083616
END
</pre><p>
        Individual stats for each slab class are prefixed with the slab
        ID. A unique ID is given to each allocated slab from the
        smallest size up to the largest. The prefix number indicates the
        slab class number in relation to the calculated chunk from the
        specified growth factor. Hence in the example, 1 is the first
        chunk size and 9 is the 9th chunk allocated size.
      </p><p>
        The parameters returned for each chunk size and a description of
        each parameter are provided in the following table.
</p>
<div class="informaltable">
<table summary="This table lists memcached slabs
          statistics parameters that are returned for each chunk size.
          The table provides the statistic name, description, and the
          memcached version in which the statistic
was introduced (if applicable)." border="1"><colgroup><col><col><col></colgroup><thead><tr><th scope="col">Statistic</th><th scope="col">Description</th><th scope="col">Version</th></tr></thead><tbody><tr><td scope="row"><code class="literal">chunk_size</code></td><td>Space allocated to each chunk within this slab class.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">chunks_per_page</code></td><td>Number of chunks within a single page for this slab class.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">total_pages</code></td><td>Number of pages allocated to this slab class.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">total_chunks</code></td><td>Number of chunks allocated to the slab class.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">used_chunks</code></td><td>Number of chunks allocated to an item..</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">free_chunks</code></td><td>Number of chunks not yet allocated to items.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">free_chunks_end</code></td><td>Number of free chunks at the end of the last allocated page.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">get_hits</code></td><td>Number of get hits to this chunk</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">cmd_set</code></td><td>Number of set commands on this chunk</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">delete_hits</code></td><td>Number of delete hits to this chunk</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">incr_hits</code></td><td>Number of increment hits to this chunk</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">decr_hits</code></td><td>Number of decrement hits to this chunk</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">cas_hits</code></td><td>Number of CAS hits to this chunk</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">cas_badval</code></td><td>Number of CAS hits on this chunk where the existing value did not match</td><td>1.3.x</td></tr><tr><td scope="row"><code class="literal">mem_requested</code></td><td>The true amount of memory of memory requested within this chunk</td><td>1.4.1</td></tr></tbody></table>
</div>
<p>
        The following additional statistics cover the information for
        the entire server, rather than on a chunk by chunk basis:
</p>
<div class="informaltable">
<table summary="This table lists memcached slab
          statistics that provide information for the entire server
          rather than for a single chunk. The table provides the
          statistic name, description, and version (if
applicable)." border="1"><colgroup><col><col><col></colgroup><thead><tr><th scope="col">Statistic</th><th scope="col">Description</th><th scope="col">Version</th></tr></thead><tbody><tr><td scope="row"><code class="literal">active_slabs</code></td><td>Total number of slab classes allocated.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">total_malloced</code></td><td>Total amount of memory allocated to slab pages.</td><td class="auto-generated"> </td></tr></tbody></table>
</div>
<p>
        The key values in the slab statistics are the
        <code class="literal">chunk_size</code>, and the corresponding
        <code class="literal">total_chunks</code> and
        <code class="literal">used_chunks</code> parameters. These given an
        indication of the size usage of the chunks within the system.
        Remember that one key/value pair is placed into a chunk of a
        suitable size.
      </p><p>
        From these stats, you can get an idea of your size and chunk
        allocation and distribution. If you store many items with a
        number of largely different sizes, consider adjusting the chunk
        size growth factor to increase in larger steps to prevent chunk
        and memory wastage. A good indication of a bad growth factor is
        a high number of different slab classes, but with relatively few
        chunks actually in use within each slab. Increasing the growth
        factor creates fewer slab classes and therefore makes better use
        of the allocated pages.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-stats-items"></a>16.6.4.3 <span class="command"><strong>memcached</strong></span> Item Statistics</h4>

</div>

</div>

</div>
<p>
        To get the <code class="literal">items</code> statistics, use the
        <code class="literal">stats items</code> command, or the API equivalent.
      </p><p>
        The <code class="literal">items</code> statistics give information about
        the individual items allocated within a given slab class.
      </p><pre class="programlisting">
STAT items:2:number 1
STAT items:2:age 452
STAT items:2:evicted 0
STAT items:2:evicted_nonzero 0
STAT items:2:evicted_time 2
STAT items:2:outofmemory 0
STAT items:2:tailrepairs 0
...
STAT items:27:number 1
STAT items:27:age 452
STAT items:27:evicted 0
STAT items:27:evicted_nonzero 0
STAT items:27:evicted_time 2
STAT items:27:outofmemory 0
STAT items:27:tailrepairs 0
</pre><p>
        The prefix number against each statistics relates to the
        corresponding chunk size, as returned by the <code class="literal">stats
        slabs</code> statistics. The result is a display of the
        number of items stored within each chunk within each slab size,
        and specific statistics about their age, eviction counts, and
        out of memory counts. A summary of the statistics is given in
        the following table.
</p>
<div class="informaltable">
<table summary="This table lists memcached item
          statistics and provides a description of each." border="1"><colgroup><col><col><col></colgroup><thead><tr><th scope="col">Statistic</th><th scope="col">Description</th><td class="auto-generated"> </td></tr></thead><tbody><tr><td scope="row"><code class="literal">number</code></td><td>The number of items currently stored in this slab class.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">age</code></td><td>The age of the oldest item within the slab class, in seconds.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">evicted</code></td><td>The number of items evicted to make way for new entries.</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">evicted_time</code></td><td>The time of the last evicted entry</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">evicted_nonzero</code></td><td>The time of the last evicted non-zero entry</td><td>1.4.0</td></tr><tr><td scope="row"><code class="literal">outofmemory</code></td><td>The number of items for this slab class that have triggered an out of
                memory error (only value when the <code class="literal">-M</code>
command line option is in effect).</td><td class="auto-generated"> </td></tr><tr><td scope="row"><code class="literal">tailrepairs</code></td><td>Number of times the entries for a particular ID need repairing</td><td class="auto-generated"> </td></tr></tbody></table>
</div>
<p>
        Item level statistics can be used to determine how many items
        are stored within a given slab and their freshness and recycle
        rate. You can use this to help identify whether there are
        certain slab classes that are triggering a much larger number of
        evictions that others.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-stats-sizes"></a>16.6.4.4 <span class="command"><strong>memcached</strong></span> Size Statistics</h4>

</div>

</div>

</div>
<p>
        To get size statistics, use the <code class="literal">stats sizes</code>
        command, or the API equivalent.
      </p><p>
        The size statistics provide information about the sizes and
        number of items of each size within the cache. The information
        is returned as two columns, the first column is the size of the
        item (rounded up to the nearest 32 byte boundary), and the
        second column is the count of the number of items of that size
        within the cache:
      </p><pre class="programlisting">
96 35
128 38
160 807
192 804
224 410
256 222
288 83
320 39
352 53
384 33
416 64
448 51
480 30
512 54
544 39
576 10065
</pre>
<div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;">

<div class="admon-title">
Caution
</div>
<p>
          Running this statistic locks up your cache as each item is
          read from the cache and its size calculated. On a large cache,
          this may take some time and prevent any set or get operations
          until the process completes.
</p>
</div>
<p>
        The item size statistics are useful only to determine the sizes
        of the objects you are storing. Since the actual memory
        allocation is relevant only in terms of the chunk size and page
        size, the information is only useful during a careful debugging
        or diagnostic session.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-stats-detail"></a>16.6.4.5 <code class="literal">memcached</code> Detail Statistics</h4>

</div>

</div>

</div>
<p>
        For <span class="command"><strong>memcached</strong></span> 1.3.x and higher, you can
        enable and obtain detailed statistics about the get, set, and
        del operations on theindividual keys stored in the cache, and
        determine whether the attempts hit (found) a particular key.
        These operations are only recorded while the detailed stats
        analysis is turned on.
      </p><p>
        To enable detailed statistics, you must send the <code class="literal">stats
        detail on</code> command to the <span class="command"><strong>memcached</strong></span>
        server:
      </p><pre class="programlisting">
$ telnet localhost 11211
Trying 127.0.0.1...
Connected to tiger.
Escape character is '^]'.
<strong class="userinput"><code>stats detail on</code></strong>
OK
</pre><p>
        Individual statistics are recorded for every
        <code class="literal">get</code>, <code class="literal">set</code> and
        <code class="literal">del</code> operation on a key, including keys that
        are not currently stored in the server. For example, if an
        attempt is made to obtain the value of key
        <code class="literal">abckey</code> and it does not exist, the
        <code class="literal">get</code> operating on the specified key are
        recorded while detailed statistics are in effect, even if the
        key is not currently stored. The <code class="literal">hits</code>, that
        is, the number of <code class="literal">get</code> or
        <code class="literal">del</code> operations for a key that exists in the
        server are also counted.
      </p><p>
        To turn detailed statistics off, send the <code class="literal">stats detail
        off</code> command to the <span class="command"><strong>memcached</strong></span>
        server:
      </p><pre class="programlisting">
$ telnet localhost 11211
Trying 127.0.0.1...
Connected to tiger.
Escape character is '^]'.
<strong class="userinput"><code>stats detail on</code></strong>
OK
</pre><p>
        To obtain the detailed statistics recorded during the process,
        send the <code class="literal">stats detail dump</code> command to the
        <span class="command"><strong>memcached</strong></span> server:
      </p><pre class="programlisting">
stats detail dump
PREFIX hykkey get 0 hit 0 set 1 del 0
PREFIX xyzkey get 0 hit 0 set 1 del 0
PREFIX yukkey get 1 hit 0 set 0 del 0
PREFIX abckey get 3 hit 3 set 1 del 0
END
</pre><p>
        You can use the detailed statistics information to determine
        whether your <span class="command"><strong>memcached</strong></span> clients are using a
        large number of keys that do not exist in the server by
        comparing the <code class="literal">hit</code> and <code class="literal">get</code>
        or <code class="literal">del</code> counts. Because the information is
        recorded by key, you can also determine whether the failures or
        operations are clustered around specific keys.
</p>
</div>
<div class="section">
<div class="titlepage">
<div>
<div>
<h4 class="title"><a name="ha-memcached-stats-memcached-tool"></a>16.6.4.6 Using <span class="command"><strong>memcached-tool</strong></span></h4>

</div>

</div>

</div>
<p>
        The <span class="command"><strong>memcached-tool</strong></span>, located within the
        <code class="filename">scripts</code> directory within the
        <span class="command"><strong>memcached</strong></span> source directory. The tool provides
        convenient access to some reports and statistics from any
        <span class="command"><strong>memcached</strong></span> instance.
      </p><p>
        The basic format of the command is:
      </p><pre class="programlisting">
shell&gt; ./memcached-tool hostname:port [command]
</pre><p>
        The default output produces a list of the slab allocations and
        usage. For example:
      </p><pre class="programlisting">
shell&gt; memcached-tool localhost:11211 display
  #  Item_Size  Max_age   Pages   Count   Full?  Evicted Evict_Time OOM
  1      80B        93s       1      20      no        0        0    0
  2     104B        93s       1      16      no        0        0    0
  3     136B      1335s       1      28      no        0        0    0
  4     176B      1335s       1      24      no        0        0    0
  5     224B      1335s       1      32      no        0        0    0
  6     280B      1335s       1      34      no        0        0    0
  7     352B      1335s       1      36      no        0        0    0
  8     440B      1335s       1      46      no        0        0    0
  9     552B      1335s       1      58      no        0        0    0
 10     696B      1335s       1      66      no        0        0    0
 11     872B      1335s       1      89      no        0        0    0
 12     1.1K      1335s       1     112      no        0        0    0
 13     1.3K      1335s       1     145      no        0        0    0
 14     1.7K      1335s       1     123      no        0        0    0
 15     2.1K      1335s       1     198      no        0        0    0
 16     2.6K      1335s       1     199      no        0        0    0
 17     3.3K      1335s       1     229      no        0        0    0
 18     4.1K      1335s       1     248     yes       36        2    0
 19     5.2K      1335s       2     328      no        0        0    0
 20     6.4K      1335s       2     316     yes      387        1    0
 21     8.1K      1335s       3     381     yes      492        1    0
 22    10.1K      1335s       3     303     yes      598        2    0
 23    12.6K      1335s       5     405     yes      605        1    0
 24    15.8K      1335s       6     384     yes      766        2    0
 25    19.7K      1335s       7     357     yes      908      170    0
 26    24.6K      1336s       7     287     yes     1012        1    0
 27    30.8K      1336s       7     231     yes     1193      169    0
 28    38.5K      1336s       4     104     yes     1323      169    0
 29    48.1K      1336s       1      21     yes     1287        1    0
 30    60.2K      1336s       1      17     yes     1093      169    0
 31    75.2K      1337s       1      13     yes      713      168    0
 32    94.0K      1337s       1      10     yes      278      168    0
 33   117.5K      1336s       1       3      no        0        0    0

</pre><p>
        This output is the same if you specify the
        <code class="literal">command</code> as <code class="literal">display</code>:
      </p><pre class="programlisting">
shell&gt; memcached-tool localhost:11211 display
  #  Item_Size  Max_age   Pages   Count   Full?  Evicted Evict_Time OOM
  1      80B        93s       1      20      no        0        0    0
  2     104B        93s       1      16      no        0        0    0
...
</pre><p>
        The output shows a summarized version of the output from the
        <code class="literal">slabs</code> statistics. The columns provided in the
        output are shown below:
</p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
            <code class="literal">#</code>: The slab number
          </p></li><li class="listitem"><p>
            <code class="literal">Item_Size</code>: The size of the slab
          </p></li><li class="listitem"><p>
            <code class="literal">Max_age</code>: The age of the oldest item in
            the slab
          </p></li><li class="listitem"><p>
            <code class="literal">Pages</code>: The number of pages allocated to
            the slab
          </p></li><li class="listitem"><p>
            <code class="literal">Count</code>: The number of items in this slab
          </p></li><li class="listitem"><p>
            <code class="literal">Full?</code>: Whether the slab is fully
            populated
          </p></li><li class="listitem"><p>
            <code class="literal">Evicted</code>: The number of objects evicted
            from this slab
          </p></li><li class="listitem"><p>
            <code class="literal">Evict_Time</code>: The time (in seconds) since
            the last eviction
          </p></li><li class="listitem"><p>
            <code class="literal">OOM</code>: The number of items that have
            triggered an out of memory error
</p></li></ul>
</div>
<p>
        You can also obtain a dump of the general statistics for the
        server using the <code class="literal">stats</code> command:
      </p><pre class="programlisting">
shell&gt; memcached-tool localhost:11211 stats  
#localhost:11211   Field       Value
         accepting_conns           1
                   bytes         162
              bytes_read         485
           bytes_written        6820
              cas_badval           0
                cas_hits           0
              cas_misses           0
               cmd_flush           0
                 cmd_get           4
                 cmd_set           2
             conn_yields           0
   connection_structures          11
        curr_connections          10
              curr_items           2
               decr_hits           0
             decr_misses           1
             delete_hits           0
           delete_misses           0
               evictions           0
                get_hits           4
              get_misses           0
               incr_hits           0
             incr_misses           2
          limit_maxbytes    67108864
     listen_disabled_num           0
                     pid       12981
            pointer_size          32
           rusage_system    0.013911
             rusage_user    0.011876
                 threads           4
                    time  1255518565
       total_connections          20
             total_items           2
                  uptime         880
                 version       1.4.2
</pre>
</div>

</div>

<div class="section">

<div class="titlepage">
<div>
<div>
<h3 class="title"><a name="ha-memcached-faq"></a>16.6.5 <span class="command"><strong>memcached</strong></span> FAQ</h3>

</div>

</div>

</div>
<p><span class="bold"><strong>Questions</strong></span></p>
<div class="itemizedlist">
<ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-1">17.6.5.1: </a>
        Can memcached be run on a Windows environment?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-2">17.6.5.2: </a>
        What is the maximum size of an object you can store in
        memcached? Is that configurable?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-3">17.6.5.3: </a>
        Is it true <code class="literal">memcached</code> will be much more
        effective with db-read-intensive applications than with
        db-write-intensive applications?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-4">17.6.5.4: </a>
        Is there any overhead in not using persistent connections? If
        persistent is always recommended, what are the downsides (for
        example, locking up)?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-5">17.6.5.5: </a>
        How is an event such as a crash of one of the
        <span class="command"><strong>memcached</strong></span> servers handled by the
        <span class="command"><strong>memcached</strong></span> client?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-6">17.6.5.6: </a>
        What is a recommended hardware configuration for a memcached
        server?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-7">17.6.5.7: </a>
        Is memcached more effective for video and audio as opposed to
        textual read/writes?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-8">17.6.5.8: </a>
        Can <span class="command"><strong>memcached</strong></span> work with ASPX?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-9">17.6.5.9: </a>
        How expensive is it to establish a memcache connection? Should
        those connections be pooled?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-10">17.6.5.10: </a>
        How is the data handled when the <span class="command"><strong>memcached</strong></span>
        server is down?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-11">17.6.5.11: </a>
        How are auto-increment columns in the MySQL database coordinated
        across multiple instances of memcached?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-12">17.6.5.12: </a>
        Is compression available?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-13">17.6.5.13: </a>
        Can we implement different types of <span class="command"><strong>memcached</strong></span>
        as different nodes in the same server, so can there be
        deterministic and non-deterministic in the same server?
      </p></li><li class="listitem"><p><a class="link" href="ha-overview.html#qandaitem-17-6-5-1-14">17.6.5.14: </a>
        What are best practices for testing an implementation, to ensure
        that it improves performance, and to measure the impact of
        <span class="command"><strong>memcached</strong></span> configuration changes? And would
        you recommend keeping the configuration very simple to start?
</p></li></ul>
</div>
<p><span class="bold"><strong>Questions and Answers</strong></span></p><p><a name="qandaitem-17-6-5-1-1"></a><span class="bold"><strong>17.6.5.1: </strong></span><span class="bold"><strong>
        Can memcached be run on a Windows environment?
      </strong></span></p><p>
        No. Currently <span class="command"><strong>memcached</strong></span> is available only on
        the Unix/Linux platform. There is an unofficial port available,
        see <a class="ulink" href="http://www.codeplex.com/memcachedproviders" target="_top">http://www.codeplex.com/memcachedproviders</a>.
      </p><p><a name="qandaitem-17-6-5-1-2"></a><span class="bold"><strong>17.6.5.2: </strong></span><span class="bold"><strong>
        What is the maximum size of an object you can store in
        memcached? Is that configurable?
      </strong></span></p><p>
        The default maximum object size is 1MB. In
        <span class="command"><strong>memcached</strong></span> 1.4.2 and later, you can change the
        maximum size of an object using the <code class="option">-I</code> command
        line option.
      </p><p>
        For versions before this, to increase this size, you have to
        re-compile <span class="command"><strong>memcached</strong></span>. You can modify the
        value of the <code class="literal">POWER_BLOCK</code> within the
        <code class="filename">slabs.c</code> file within the source.
      </p><p>
        In <span class="command"><strong>memcached</strong></span> 1.4.2 and higher, you can
        configure the maximum supported object size by using the
        <code class="literal">-I</code> command-line option. For example, to
        increase the maximum object size to 5MB:
      </p><pre class="programlisting">
$ memcached -I 5m
</pre><p>
        If an object is larger than the maximum object size, you must
        manually split it. <span class="command"><strong>memcached</strong></span> is very simple:
        you give it a key and some data, it tries to cache it in RAM. If
        you try to store more than the default maximum size, the value
        is just truncated for speed reasons.
      </p><p><a name="qandaitem-17-6-5-1-3"></a><span class="bold"><strong>17.6.5.3: </strong></span><span class="bold"><strong>
        Is it true <code class="literal">memcached</code> will be much more
        effective with db-read-intensive applications than with
        db-write-intensive applications?
      </strong></span></p><p>
        Yes. <span class="command"><strong>memcached</strong></span> plays no role in database
        writes, it is a method of caching data already read from the
        database in RAM.
      </p><p><a name="qandaitem-17-6-5-1-4"></a><span class="bold"><strong>17.6.5.4: </strong></span><span class="bold"><strong>
        Is there any overhead in not using persistent connections? If
        persistent is always recommended, what are the downsides (for
        example, locking up)?
      </strong></span></p><p>
        If you don't use persistent connections when communicating with
        <span class="command"><strong>memcached</strong></span>, there will be a small increase in
        the latency of opening the connection each time. The effect is
        comparable to use nonpersistent connections with MySQL.
      </p><p>
        In general, the chance of locking or other issues with
        persistent connections is minimal, because there is very little
        locking within <span class="command"><strong>memcached</strong></span>. If there is a
        problem, eventually your request will time out and return no
        result, so your application will need to load from MySQL again.
      </p><p><a name="qandaitem-17-6-5-1-5"></a><span class="bold"><strong>17.6.5.5: </strong></span><span class="bold"><strong>
        How is an event such as a crash of one of the
        <span class="command"><strong>memcached</strong></span> servers handled by the
        <span class="command"><strong>memcached</strong></span> client?
      </strong></span></p><p>
        There is no automatic handling of this. If your client fails to
        get a response from a server, code a fallback mechanism to load
        the data from the MySQL database.
      </p><p>
        The client APIs all provide the ability to add and remove
        <span class="command"><strong>memcached</strong></span> instances on the fly. If within
        your application you notice that <span class="command"><strong>memcached</strong></span>
        server is no longer responding, you can remove the server from
        the list of servers, and keys will automatically be
        redistributed to another <span class="command"><strong>memcached</strong></span> server in
        the list. If retaining the cache content on all your servers is
        important, make sure you use an API that supports a consistent
        hashing algorithm. For more information, see
        <a class="xref" href="ha-overview.html#ha-memcached-using-hashtypes" title="16.6.2.4 memcached Hashing/Distribution Types">Section 16.6.2.4, “<span class="command"><strong>memcached</strong></span> Hashing/Distribution Types”</a>.
      </p><p><a name="qandaitem-17-6-5-1-6"></a><span class="bold"><strong>17.6.5.6: </strong></span><span class="bold"><strong>
        What is a recommended hardware configuration for a memcached
        server?
      </strong></span></p><p>
        <span class="command"><strong>memcached</strong></span> has a very low processing overhead.
        All that is required is spare physical RAM capacity. A
        <span class="command"><strong>memcached</strong></span> server does not require a dedicated
        machine. If you have web, application, or database servers that
        have spare RAM capacity, then use them with
        <span class="command"><strong>memcached</strong></span>.
      </p><p>
        To build and deploy a dedicated <span class="command"><strong>memcached</strong></span>
        server, use a relatively low-power CPU, lots of RAM, and one or
        more Gigabit Ethernet interfaces.
      </p><p><a name="qandaitem-17-6-5-1-7"></a><span class="bold"><strong>17.6.5.7: </strong></span><span class="bold"><strong>
        Is memcached more effective for video and audio as opposed to
        textual read/writes?
      </strong></span></p><p>
        <span class="command"><strong>memcached</strong></span> works equally well for all kinds of
        data. To <span class="command"><strong>memcached</strong></span>, any value you store is
        just a stream of data. Remember, though, that the maximum size
        of an object you can store in <span class="command"><strong>memcached</strong></span> is
        1MB, but can be configured to be larger by using the
        <code class="option">-I</code> option in <span class="command"><strong>memcached</strong></span> 1.4.2
        and later, or by modifying the source in versions before 1.4.2.
        If you plan on using <span class="command"><strong>memcached</strong></span> with audio and
        video content, you will probably want to increase the maximum
        object size. Also remember that <span class="command"><strong>memcached</strong></span> is
        a solution for caching information for reading. It shouldn't be
        used for writes, except when updating the information in the
        cache.
      </p><p><a name="qandaitem-17-6-5-1-8"></a><span class="bold"><strong>17.6.5.8: </strong></span><span class="bold"><strong>
        Can <span class="command"><strong>memcached</strong></span> work with ASPX?
      </strong></span></p><p>
        There are ports and interfaces for many languages and
        environments. ASPX relies on an underlying language such as C#
        or VisualBasic, and if you are using ASP.NET then there is a C#
        <span class="command"><strong>memcached</strong></span> library. For more information, see
        <a class="ulink" href="https://sourceforge.net/projects/memcacheddotnet/" target="_top">https://sourceforge.net/projects/memcacheddotnet/</a>.
      </p><p><a name="qandaitem-17-6-5-1-9"></a><span class="bold"><strong>17.6.5.9: </strong></span><span class="bold"><strong>
        How expensive is it to establish a memcache connection? Should
        those connections be pooled?
      </strong></span></p><p>
        Opening the connection is relatively inexpensive, because there
        is no security, authentication or other handshake taking place
        before you can start sending requests and getting results. Most
        APIs support a persistent connection to a
        <span class="command"><strong>memcached</strong></span> instance to reduce the latency.
        Connection pooling would depend on the API you are using, but if
        you are communicating directly over TCP/IP, then connection
        pooling would provide some small performance benefit.
      </p><p><a name="qandaitem-17-6-5-1-10"></a><span class="bold"><strong>17.6.5.10: </strong></span><span class="bold"><strong>
        How is the data handled when the <span class="command"><strong>memcached</strong></span>
        server is down?
      </strong></span></p><p>
        The behavior is entirely application dependent. Most
        applications fall back to loading the data from the database
        (just as if they were updating the <span class="command"><strong>memcached</strong></span>
        information). If you are using multiple
        <span class="command"><strong>memcached</strong></span> servers, you might also remove a
        downed server from the list to prevent it from affecting
        performance. Otherwise, the client will still attempt to
        communicate with the <span class="command"><strong>memcached</strong></span> server that
        corresponds to the key you are trying to load.
      </p><p><a name="qandaitem-17-6-5-1-11"></a><span class="bold"><strong>17.6.5.11: </strong></span><span class="bold"><strong>
        How are auto-increment columns in the MySQL database coordinated
        across multiple instances of memcached?
      </strong></span></p><p>
        They aren't. There is no relationship between MySQL and
        <span class="command"><strong>memcached</strong></span> unless your application (or, if you
        are using the MySQL UDFs for <span class="command"><strong>memcached</strong></span>, your
        database definition) creates one.
      </p><p>
        If you are storing information based on an auto-increment key
        into multiple instances of <span class="command"><strong>memcached</strong></span>, the
        information is only stored on one of the
        <span class="command"><strong>memcached</strong></span> instances anyway. The client uses
        the key value to determine which <span class="command"><strong>memcached</strong></span>
        instance to store the information. It doesn't store the same
        information across all the instances, as that would be a waste
        of cache memory.
      </p><p><a name="qandaitem-17-6-5-1-12"></a><span class="bold"><strong>17.6.5.12: </strong></span><span class="bold"><strong>
        Is compression available?
      </strong></span></p><p>
        Yes. Most of the client APIs support some sort of compression,
        and some even allow you to specify the threshold at which a
        value is deemed appropriate for compression during storage.
      </p><p><a name="qandaitem-17-6-5-1-13"></a><span class="bold"><strong>17.6.5.13: </strong></span><span class="bold"><strong>
        Can we implement different types of <span class="command"><strong>memcached</strong></span>
        as different nodes in the same server, so can there be
        deterministic and non-deterministic in the same server?
      </strong></span></p><p>
        Yes. You can run multiple instances of
        <span class="command"><strong>memcached</strong></span> on a single server, and in your
        client configuration you choose the list of servers you want to
        use.
      </p><p><a name="qandaitem-17-6-5-1-14"></a><span class="bold"><strong>17.6.5.14: </strong></span><span class="bold"><strong>
        What are best practices for testing an implementation, to ensure
        that it improves performance, and to measure the impact of
        <span class="command"><strong>memcached</strong></span> configuration changes? And would
        you recommend keeping the configuration very simple to start?
      </strong></span></p><p>
        The best way to test the performance is to start up a
        <span class="command"><strong>memcached</strong></span> instance. First, modify your
        application so that it stores the data just before the data is
        about to be used or displayed into <span class="command"><strong>memcached</strong></span>.
        Since the APIs handle the serialization of the data, it should
        just be a one-line modification to your code. Then, modify the
        start of the process that would normally load that information
        from MySQL with the code that requests the data from
        <span class="command"><strong>memcached</strong></span>. If the data cannot be loaded from
        <span class="command"><strong>memcached</strong></span>, default to the MySQL process.
      </p><p>
        All of the changes required will probably amount to just a few
        lines of code. To get the best benefit, make sure you cache
        entire objects (for example, all the components of a web page,
        blog post, discussion thread, and so on), rather than using
        <span class="command"><strong>memcached</strong></span> as a simple cache of individual
        rows of MySQL tables.
      </p><p>
        Keeping the configuration simple at the start, or even over the
        long term, is easy with <span class="command"><strong>memcached</strong></span>. Once you
        have the basic structure up and running, often the only ongoing
        change is to add more servers into the list of servers used by
        your applications. You don't need to manage the
        <span class="command"><strong>memcached</strong></span> servers, and there is no complex
        configuration; just add more servers to the list and let the
        client API and the <span class="command"><strong>memcached</strong></span> servers make the
        decisions.
</p>
</div>

</div>

</div>
<div class="copyright-footer">

</div>
<div class="navfooter">
<hr>
<table width="100%" summary="Navigation footer">
<tr>
<td width="40%" align="left"><a accesskey="p" href="storage-engines.html">Prev</a></td>
<td width="20%" align="center"><a accesskey="u" href="">Up</a></td>
<td width="40%" align="right"> <a accesskey="n" href="replication.html">Next</a></td>
</tr>
<tr>
<td width="40%" align="left" valign="top">Chapter 15 Alternative Storage Engines</td>
<td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td>
<td width="40%" align="right" valign="top">Chapter 17 Replication</td>
</tr>
</table>
</div>
</body>
</html>
